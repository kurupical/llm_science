{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../apikey/apikey.txt\", \"r\") as f:\n",
    "    openai.api_key = f.readline().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prompt(prompt, max_tokens=4000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professor at a science university and creating a exam for your students.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(fname):\n",
    "    def f(categories):\n",
    "        for cat in categories:\n",
    "            for word in [\n",
    "                \"geology\",\n",
    "                \"physics\",\n",
    "                \"chemistry\",\n",
    "                \"mathematical\",\n",
    "                \"biology\",\n",
    "                \"astronomy\",\n",
    "                \"ecology\",\n",
    "                \"genetics\",\n",
    "                \"statistics\",\n",
    "                \"theoretical\"\n",
    "            ]:\n",
    "                if word.lower() in cat.lower():\n",
    "                    return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def text_preprocess(text):\n",
    "        return text.replace(\"===\", \"\\n\").replace(\"==\", \"\\n\")\n",
    "\n",
    "    df = pd.read_parquet(fname)\n",
    "    df_science = df[df[\"categories\"].apply(f)]\n",
    "    df_science[\"text\"] = \"title: \" + df_science[\"title\"] + \"\\n\" + df_science[\"text\"].apply(text_preprocess)\n",
    "    return df_science.sample(len(df_science)//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/wikipedia/a.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:   0%|▍                                                                                                                     | 1/252 [00:03<14:22,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'Who is the theoretical physicist that expounded the thought experiment of Astrochicken?', 'A': 'John von Neumann', 'B': 'Rodney Brooks', 'C': 'Michio Kaku', 'D': 'Freeman Dyson', 'E': 'None of the above', 'answer': 'D'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\r",
      "../data/wikipedia/a.parquet:   1%|▉                                                                                                                     | 2/252 [00:06<13:24,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which player holds the record for the most appearances for the Albania national football team? \n",
      "\n",
      "A) Erjon Bogdani\n",
      "B) Lorik Cana\n",
      "C) Etrit Berisha\n",
      "D) Ansi Agolli\n",
      "E) Altin Lala\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:   1%|█▍                                                                                                                    | 3/252 [00:10<15:06,  3.64s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:   2%|█▊                                                                                                                    | 4/252 [00:13<13:12,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a feature of an armillary sphere?\n",
      "\n",
      "A) Representation of lines of celestial longitude and latitude\n",
      "B) Mapping of constellations\n",
      "C) Representation of the ecliptic\n",
      "D) Representation of the equinoctial and solstitial colures\n",
      "E) Measurement of the distance between celestial objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  31%|███████████████████████████████████▊                                                                                 | 77/252 [05:10<10:22,  3.56s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  31%|████████████████████████████████████▏                                                                                | 78/252 [05:13<10:19,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about abyssal channels?\n",
      "\n",
      "A) They are formed by slow-flowing floods of clear water.\n",
      "B) They are responsible for the accumulation of most sandstone deposits found on continental slopes.\n",
      "C) They are the least understood sedimentary processes.\n",
      "D) They do not have any significant impact on the transfer of carbon from the continental shelf to the deeper parts of the continental margins.\n",
      "E) They are commonly referred to as channel levee systems.\n",
      "\n",
      "Answer: B) They are responsible for the accumulation of most sandstone deposits found on continental slopes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\r",
      "../data/wikipedia/a.parquet:  31%|████████████████████████████████████▋                                                                                | 79/252 [05:15<09:02,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a department within the African Wildlife Defence Force (AWDF)?\n",
      "\n",
      "A) Rangers\n",
      "B) Advanced Force Rangers\n",
      "C) Special Force Rangers\n",
      "D) Special Operations Affiliate Ranger Group\n",
      "E) Aviation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  32%|█████████████████████████████████████▏                                                                               | 80/252 [05:18<08:52,  3.10s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_54387/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 17753 tokens (13753 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/a.parquet:  32%|█████████████████████████████████████▌                                                                               | 81/252 [05:19<06:48,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 17753 tokens (13753 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is the purpose of astronomical surveys?\",\n",
      "    \"A\": \"To observe specific celestial objects\",\n",
      "    \"B\": \"To catalog celestial objects and perform statistical analyses\",\n",
      "    \"C\": \"To search for transient astronomical events\",\n",
      "    \"D\": \"To detect potentially hazardous objects\",\n",
      "    \"E\": \"All of the above\",\n",
      "    \"answer\": \"E\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  38%|████████████████████████████████████████████                                                                         | 95/252 [06:08<10:04,  3.85s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  38%|████████████████████████████████████████████▌                                                                        | 96/252 [06:13<10:21,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about the Ancestral Thames is true?\n",
      "\n",
      "A) The river originated from the emergence of Britain from a Cretaceous sea.\n",
      "B) The river's course was modified by the Anglian glaciation.\n",
      "C) The river's deposits have been extensively studied in the field of archaeology.\n",
      "D) The river flowed from the south-east towards what later became southern England.\n",
      "E) The river's course remained unchanged throughout the Pleistocene period.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  46%|█████████████████████████████████████████████████████▍                                                              | 116/252 [07:32<09:55,  4.38s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  46%|█████████████████████████████████████████████████████▊                                                              | 117/252 [07:36<09:45,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about the ARGUS distribution is true?\n",
      "\n",
      "A. The ARGUS distribution is named after a famous physicist.\n",
      "B. The probability density function of the ARGUS distribution is given by f(x; χ, c).\n",
      "C. The cumulative distribution function of the ARGUS distribution is given by F(x).\n",
      "D. The parameter c in the ARGUS distribution is estimated using the maximum likelihood approach.\n",
      "E. The generalized ARGUS distribution is used to describe a more peaking-like distribution.\n",
      "\n",
      "Answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  55%|███████████████████████████████████████████████████████████████▉                                                    | 139/252 [09:04<06:13,  3.30s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_54387/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 16406 tokens (12406 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/a.parquet:  56%|████████████████████████████████████████████████████████████████▍                                                   | 140/252 [09:04<04:33,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 16406 tokens (12406 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Arnold Kosevich was known for his contributions to which fields?\",\n",
      "    \"A\": \"Quantum mechanics and astrophysics\",\n",
      "    \"B\": \"The electron theory of metals and the theory of crystals\",\n",
      "    \"C\": \"Nuclear physics and particle physics\",\n",
      "    \"D\": \"Thermodynamics and fluid dynamics\",\n",
      "    \"E\": \"Optics and electromagnetism\",\n",
      "    \"answer\": \"B\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  64%|██████████████████████████████████████████████████████████████████████████▌                                         | 162/252 [10:29<05:12,  3.48s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  65%|███████████████████████████████████████████████████████████████████████████                                         | 163/252 [10:32<05:06,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about Arthur Eddington is true?\n",
      "\n",
      "A. He was a mathematician and philosopher of science.\n",
      "B. He discovered the theory of general relativity.\n",
      "C. He conducted an expedition to observe a solar eclipse in 1919.\n",
      "D. He was the first to correctly speculate on the source of stellar energy.\n",
      "E. He was born in Weston-super-Mare, England.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  75%|███████████████████████████████████████████████████████████████████████████████████████▍                            | 190/252 [12:16<03:52,  3.75s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  76%|███████████████████████████████████████████████████████████████████████████████████████▉                            | 191/252 [12:18<03:28,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which airport is the third largest civilian airport by traffic in Pakistan?\n",
      "\n",
      "A) Jinnah International Airport, Karachi\n",
      "B) Islamabad International Airport\n",
      "C) Allama Iqbal International Airport\n",
      "D) Walton Airport\n",
      "E) Lahore International Airport\n",
      "\n",
      "Answer: C) Allama Iqbal International Airport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  78%|██████████████████████████████████████████████████████████████████████████████████████████▋                         | 197/252 [12:40<03:10,  3.47s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  79%|███████████████████████████████████████████████████████████████████████████████████████████▏                        | 198/252 [12:43<03:03,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about the AIDA diabetes simulator?\n",
      "\n",
      "A) It can be used for individual patient simulation and glycemic prediction.\n",
      "B) It is only intended for insulin therapy planning.\n",
      "C) It is primarily used for research purposes.\n",
      "D) It is not suitable for teaching or self-learning.\n",
      "E) It is available for download on the AIDA website.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  79%|███████████████████████████████████████████████████████████████████████████████████████████▌                        | 199/252 [12:47<03:04,  3.49s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_54387/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  79%|████████████████████████████████████████████████████████████████████████████████████████████                        | 200/252 [12:49<02:48,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a type of assay based on the nature of the assay process?\n",
      "\n",
      "A) End point assay\n",
      "B) Kinetic assay\n",
      "C) High throughput assay\n",
      "D) Multiplex assay\n",
      "E) Ligand binding assay\n",
      "\n",
      "Answer: E) Ligand binding assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 252/252 [15:40<00:00,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import traceback \n",
    "batch_size = 1\n",
    "\n",
    "def make_prompt(series):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI assistant who specializes in answering multiple-choice questions. You may use the context below if it helps you to answer the following multiple-choice question.\n",
    "The output should be an array of json format, with \"prompt\" as the question statement, \"A,\" \"B,\" \"C,\" \"D,\" and \"E\" as choices, \"answer\" as the answer choice (one of A through E).\n",
    "\n",
    "Context:\n",
    "{series['text']}\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def f(series):\n",
    "    if series[\"A\"] != series[\"A\"]:\n",
    "        if type(series[\"choices\"]) == dict:\n",
    "            for key in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "                series[key] = series[\"choices\"][key]\n",
    "        elif type(series[\"choices\"] == list):\n",
    "            for i, key in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\"]):\n",
    "                series[key] = series[\"choices\"][i]\n",
    "    return series\n",
    "\n",
    "now_date = dt.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "first = True\n",
    "for file in files:\n",
    "    if os.path.basename(file) in [\"all.parquet\"]:\n",
    "        print(f\"pass: {file}\")\n",
    "        continue\n",
    "    df_science = get_df(file)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(df_science)), desc=file):\n",
    "        try:\n",
    "            series = df_science.iloc[i]\n",
    "            prompt = make_prompt(series)\n",
    "            text = query_prompt(prompt)\n",
    "            texts_json = json.loads(text)\n",
    "            if first:\n",
    "                print(texts_json)\n",
    "                first = False\n",
    "            if type(texts_json) == dict:\n",
    "                text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                text_json[\"original_text\"] = series[\"text\"]\n",
    "                texts.append(text_json)\n",
    "            else:\n",
    "                for text_json in texts_json:\n",
    "                    text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                    text_json[\"original_text\"] = series[\"text\"]\n",
    "                    texts.append(text_json)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "            print(text)\n",
    "        if i % 20 == 0:\n",
    "            df_texts = pd.DataFrame(texts)\n",
    "            df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "            df_texts.to_csv(f\"output_gpt3.5_generate/{now_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_texts.to_csv(f\"output_gpt3.5_generate/{now_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                                    113\n",
       "B                                     44\n",
       "D                                     34\n",
       "C                                     31\n",
       "E                                     20\n",
       "Aurora Max                             2\n",
       "寶瓶座 (bǎo píng zuò)                     1\n",
       "Voronezh University                    1\n",
       "Stanley Autler and Charles Townes      1\n",
       "0.4-1.5 million years                  1\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_texts[\"answer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
