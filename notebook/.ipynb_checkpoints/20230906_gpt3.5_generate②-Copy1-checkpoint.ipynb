{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../apikey/apikey.txt\", \"r\") as f:\n",
    "    openai.api_key = f.readline().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prompt(prompt, max_tokens=4000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professor at a science university and creating a exam for your students.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(fname):\n",
    "    def f(categories):\n",
    "        for cat in categories:\n",
    "            for word in [\n",
    "                \"geology\",\n",
    "                \"physics\",\n",
    "                \"chemistry\",\n",
    "                \"mathematical\",\n",
    "                \"biology\",\n",
    "                \"astronomy\",\n",
    "                \"ecology\",\n",
    "                \"genetics\",\n",
    "                \"statistics\",\n",
    "                \"theoretical\"\n",
    "            ]:\n",
    "                if word.lower() in cat.lower():\n",
    "                    return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def text_preprocess(text):\n",
    "        return text.replace(\"===\", \"\\n\").replace(\"==\", \"\\n\")\n",
    "\n",
    "    df = pd.read_parquet(fname)\n",
    "    df_science = df[df[\"categories\"].apply(f)]\n",
    "    df_science[\"text\"] = \"title: \" + df_science[\"title\"] + \"\\n\" + df_science[\"text\"].apply(text_preprocess)\n",
    "    return df_science.sample(len(df_science)//40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/wikipedia/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:   2%|███▎                                                                                                                                                                                                              | 1/63 [00:09<09:55,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'What is an albedo feature in planetary geology?', 'A': 'A large area on the surface of a planet that shows a contrast in brightness or darkness with adjacent areas', 'B': 'A small area on the surface of a planet that shows a contrast in brightness or darkness with adjacent areas', 'C': 'A feature on the surface of a planet that is only visible through space probes', 'D': 'A feature on the surface of a planet that is only visible through optical telescopes', 'E': 'A feature on the surface of a planet that is only visible through ground-based telescopes using adaptive optics', 'answer': 'A'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  22%|██████████████████████████████████████████████▍                                                                                                                                                                  | 14/63 [01:32<05:08,  6.30s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  24%|█████████████████████████████████████████████████▊                                                                                                                                                               | 15/63 [01:37<04:42,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a type of assay based on the nature of the assay process?\n",
      "\n",
      "A) End point assay\n",
      "B) Kinetic assay\n",
      "C) High throughput assay\n",
      "D) Multiplex assay\n",
      "E) Ligand binding assay\n",
      "\n",
      "Answer: E) Ligand binding assay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet:  32%|██████████████████████████████████████████████████████████████████▎                                                                                                                                              | 20/63 [02:13<04:57,  6.93s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/a.parquet:  33%|█████████████████████████████████████████████████████████████████████▋                                                                                                                                           | 21/63 [02:20<04:56,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about gene synthesis is true?\n",
      "\n",
      "A. Gene synthesis requires template DNA for the construction and assembly of genes.\n",
      "B. Artificial gene synthesis allows for the synthesis of DNA molecules with no limits on the nucleotide sequence or size.\n",
      "C. Oligonucleotide synthesis can produce DNA sequences longer than a few hundred base pairs.\n",
      "D. The error frequency in gene synthesis decreases with longer oligonucleotides.\n",
      "E. Gene synthesis methods do not require the usage of chemically synthesized oligonucleotides.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/a.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [07:11<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass: ../data/wikipedia/all.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/b.parquet:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 33/45 [03:53<01:22,  6.86s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/b.parquet:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                   | 34/45 [03:57<01:05,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which team holds the record for the longest winning streak in NCAA Division I women's basketball? \n",
      "\n",
      "A) UConn\n",
      "B) Stanford\n",
      "C) Baylor\n",
      "D) Tennessee\n",
      "E) Notre Dame\n",
      "\n",
      "Answer: A) UConn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/b.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [05:08<00:00,  6.85s/it]\n",
      "../data/wikipedia/c.parquet:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 63/77 [08:36<01:43,  7.40s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/c.parquet:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                   | 64/77 [08:46<01:46,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about the Central Asian Orogenic Belt is true?\n",
      "\n",
      "A) The Central Asian Orogenic Belt is primarily composed of sedimentary rocks.\n",
      "B) The Central Asian Orogenic Belt is located between the East European Craton and the South China Craton.\n",
      "C) The Central Asian Orogenic Belt is one of the smallest orogenic belts in the world.\n",
      "D) The Central Asian Orogenic Belt is not known for its mineral resources.\n",
      "E) The formation history of the Central Asian Orogenic Belt is well understood and agreed upon by scientists.\n",
      "\n",
      "Answer: B) The Central Asian Orogenic Belt is located between the East European Craton and the South China Craton.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/c.parquet:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 70/77 [09:31<00:52,  7.47s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 16473 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/c.parquet:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 71/77 [09:32<00:32,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 16473 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is callus in plant biology?\",\n",
      "    \"A\": \"A mass of organized plant parenchyma cells\",\n",
      "    \"B\": \"A type of plant hormone\",\n",
      "    \"C\": \"A type of plant tissue culture medium\",\n",
      "    \"D\": \"A type of plant growth regulator\",\n",
      "    \"E\": \"A type of plant cell death\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/c.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [10:19<00:00,  8.05s/it]\n",
      "../data/wikipedia/d.parquet:  52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 21/40 [02:27<02:29,  7.89s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/d.parquet:  55%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 22/40 [02:36<02:28,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a simplifying assumption of dynamic discrete choice models?\n",
      "\n",
      "A) Flow utility is additively separable and linear in parameters\n",
      "B) The optimization problem can be written as a Bellman equation\n",
      "C) The states follow a Markov chain\n",
      "D) The distribution of unobserved factors is assumed to be Type I extreme value\n",
      "E) The decision process is uncertain about future transitions in the states and realizations of unobserved factors\n",
      "\n",
      "Answer: D) The distribution of unobserved factors is assumed to be Type I extreme value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/d.parquet:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 38/40 [05:13<00:30, 15.19s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 16866 tokens (12866 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/d.parquet:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 39/40 [05:14<00:10, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 16866 tokens (12866 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is the Debye model?\",\n",
      "    \"A\": \"A method for estimating the phonon contribution to the specific heat in a solid\",\n",
      "    \"B\": \"A method for estimating the electron contribution to the specific heat in a solid\",\n",
      "    \"C\": \"A method for estimating the photon contribution to the specific heat in a solid\",\n",
      "    \"D\": \"A method for estimating the phonon contribution to the specific heat in a liquid\",\n",
      "    \"E\": \"None of the above\",\n",
      "    \"answer\": \"A\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"What does the Debye model correctly predict?\",\n",
      "    \"A\": \"The low-temperature dependence of the heat capacity of solids\",\n",
      "    \"B\": \"The high-temperature dependence of the heat capacity of solids\",\n",
      "    \"C\": \"The heat capacity of liquids\",\n",
      "    \"D\": \"The heat capacity of gases\",\n",
      "    \"E\": \"None of the above\",\n",
      "    \"answer\": \"A\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"What is the Debye temperature?\",\n",
      "    \"A\": \"A measure of the hardness of a crystal\",\n",
      "    \"B\": \"The temperature at which the highest-frequency mode is excited\",\n",
      "    \"C\": \"The temperature at which the lowest-frequency mode is excited\",\n",
      "    \"D\": \"The temperature at which the heat capacity of a solid becomes constant\",\n",
      "    \"E\": \"None of the above\",\n",
      "    \"answer\": \"B\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"What is the relationship between the Debye frequency and the Debye temperature?\",\n",
      "    \"A\": \"The Debye frequency is equal to the Debye temperature\",\n",
      "    \"B\": \"The Debye frequency is proportional to the Debye temperature\",\n",
      "    \"C\": \"The Debye frequency is the reciprocal of the Debye temperature\",\n",
      "    \"D\": \"The Debye frequency is the square of the Debye temperature\",\n",
      "    \"E\": \"None of the above\",\n",
      "    \"answer\": \"B\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"What is the Debye model used to estimate?\",\n",
      "    \"A\": \"The phonon contribution to the specific heat in a solid\",\n",
      "    \"B\": \"The electron contribution to the specific heat in a solid\",\n",
      "    \"C\": \"The photon contribution to the specific heat in a solid\",\n",
      "    \"D\": \"The phonon contribution to the specific heat in a liquid\",\n",
      "    \"E\": \"None of the above\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/d.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [05:40<00:00,  8.51s/it]\n",
      "../data/wikipedia/e.parquet:  24%|███████████████████████████████████████████████████                                                                                                                                                              | 11/45 [01:22<04:21,  7.69s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/e.parquet:  27%|███████████████████████████████████████████████████████▋                                                                                                                                                         | 12/45 [01:29<04:09,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about eukaryotic initiation factor 3 (eIF3) is true?\n",
      "\n",
      "A) eIF3 is composed of 13 identical subunits.\n",
      "B) eIF3 is only involved in cap-dependent translation initiation.\n",
      "C) eIF3 does not interact with other initiation factors.\n",
      "D) eIF3 plays a role in programmed stop codon readthrough.\n",
      "E) eIF3 is not conserved across eukaryotes.\n",
      "\n",
      "Answer: D) eIF3 plays a role in programmed stop codon readthrough.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/e.parquet:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 32/45 [03:41<01:13,  5.68s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/e.parquet:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                       | 33/45 [03:50<01:19,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about epigenetic priming?\n",
      "\n",
      "A) Epigenetic priming refers to the modification of a cell's epigenome triggered by external biological triggers or pathways.\n",
      "B) Epigenetic priming is a reversible process that converts chromatin from euchromatin to heterochromatin.\n",
      "C) Epigenetic priming has only been investigated in neuroscience research.\n",
      "D) Epigenetic priming is a permanent modification to a cell's epigenome.\n",
      "E) Epigenetic priming is a targeted process that affects specific chromatin sites within a cell.\n",
      "\n",
      "Answer: A) Epigenetic priming refers to the modification of a cell's epigenome triggered by external biological triggers or pathways.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/e.parquet:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 40/45 [04:49<00:41,  8.24s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/e.parquet:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                  | 41/45 [04:53<00:27,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a mechanism involved in epigenetic modifications?\n",
      "\n",
      "A) DNA methylation\n",
      "B) Histone modifications\n",
      "C) MicroRNA expression\n",
      "D) Telomere shortening\n",
      "E) Transcription factor binding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/e.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [05:41<00:00,  7.59s/it]\n",
      "../data/wikipedia/f.parquet:  69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                | 20/29 [01:55<00:53,  6.00s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/f.parquet:  72%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 21/29 [01:59<00:42,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Prompt: Which of the following topics is NOT covered in Fluctuation and Noise Letters?\n",
      "\n",
      "A) Noise-enhanced phenomena including stochastic resonance\n",
      "B) Cardiovascular dynamics\n",
      "C) Quantum fluctuations\n",
      "D) Statistical physics\n",
      "E) Artificial intelligence and machine learning\n",
      "\n",
      "Answer: E) Artificial intelligence and machine learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/f.parquet:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 24/29 [02:16<00:28,  5.71s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia/f.parquet:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 25/29 [07:20<06:21, 95.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is a fermionic condensate?\",\n",
      "    \"A\": \"A superfluid phase formed by fermionic particles at low temperatures\",\n",
      "    \"B\": \"A superfluid phase formed by bosonic particles at low temperatures\",\n",
      "    \"C\": \"A state of electrons in a superconductor\",\n",
      "    \"D\": \"A state of helium-3 atoms at very low temperatures\",\n",
      "    \"E\": \"A state of rubidium atoms at very low temperatures\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/f.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [07:46<00:00, 16.10s/it]\n",
      "../data/wikipedia/g.parquet:   7%|██████████████▋                                                                                                                                                                                                   | 3/43 [00:18<04:01,  6.05s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/g.parquet:   9%|███████████████████▌                                                                                                                                                                                              | 4/43 [00:21<03:09,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Prompt: Which region in Victoria is primarily made up of Palaeozoic rocks?\n",
      "\n",
      "A) Northwest\n",
      "B) Northeast\n",
      "C) Southwest\n",
      "D) Southeast\n",
      "E) Central\n",
      "\n",
      "Answer: D) Southeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/g.parquet:  30%|███████████████████████████████████████████████████████████████▏                                                                                                                                                 | 13/43 [01:16<03:01,  6.04s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/g.parquet:  33%|████████████████████████████████████████████████████████████████████                                                                                                                                             | 14/43 [01:24<03:06,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about the Green-Kubo relations?\n",
      "\n",
      "A. The Green-Kubo relations give the exact mathematical expression for transport coefficients in terms of integrals of time correlation functions.\n",
      "B. The Green-Kubo relations are only valid for systems at equilibrium.\n",
      "C. The Green-Kubo relations are derived from the fluctuation theorem.\n",
      "D. The Green-Kubo relations are only applicable to linear transport coefficients.\n",
      "E. The Green-Kubo relations are not applicable to fluctuations far from equilibrium.\n",
      "\n",
      "Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/g.parquet:  65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 28/43 [02:48<01:27,  5.83s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/g.parquet:  67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 29/43 [02:53<01:21,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which gene is proposed to be associated with spirituality according to the God Gene hypothesis?\n",
      "\n",
      "A) Vesicular monoamine transporter 2 (VMAT2)\n",
      "B) Serotonin transporter (SERT)\n",
      "C) Dopamine receptor D4 (DRD4)\n",
      "D) Monoamine oxidase A (MAOA)\n",
      "E) Oxytocin receptor (OXTR)\n",
      "\n",
      "Answer: A) Vesicular monoamine transporter 2 (VMAT2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/g.parquet:  95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 41/43 [04:07<00:13,  6.57s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/g.parquet:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 42/43 [04:13<00:06,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about Gisela Dulko's career statistics?\n",
      "\n",
      "A) She won a total of 8 singles titles.\n",
      "B) She won a total of 17 doubles titles.\n",
      "C) She won a total of 4 mixed doubles titles.\n",
      "D) She won a total of 30 career titles.\n",
      "E) She won a total of 185 tournaments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/g.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 43/43 [04:19<00:00,  6.04s/it]\n",
      "../data/wikipedia/h.parquet:  16%|█████████████████████████████████▏                                                                                                                                                                                | 6/38 [00:51<05:44, 10.78s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 28795 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/h.parquet:  18%|██████████████████████████████████████▋                                                                                                                                                                           | 7/38 [00:52<03:58,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 28795 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Where did Hugh Osborn obtain his PhD?\",\n",
      "    \"A\": \"University of Cambridge\",\n",
      "    \"B\": \"University College London\",\n",
      "    \"C\": \"University of Sussex\",\n",
      "    \"D\": \"Queen Mary University of London\",\n",
      "    \"E\": \"University of Glasgow\",\n",
      "    \"answer\": \"B\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"In which year did Hugh Osborn obtain the first proof of the four-dimensional C-theorem?\",\n",
      "    \"A\": \"1989\",\n",
      "    \"B\": \"1990\",\n",
      "    \"C\": \"2001\",\n",
      "    \"D\": \"2004\",\n",
      "    \"E\": \"2011\",\n",
      "    \"answer\": \"A\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"Who found the nonperturbative proof of the four-dimensional C-theorem?\",\n",
      "    \"A\": \"Hugh Osborn\",\n",
      "    \"B\": \"John Cardy\",\n",
      "    \"C\": \"Zohar Komargodski\",\n",
      "    \"D\": \"Adam Schwimmer\",\n",
      "    \"E\": \"Sigurd Zienau\",\n",
      "    \"answer\": \"C\"\n",
      "  },\n",
      "  {\n",
      "    \"prompt\": \"In collaboration with whom did Hugh Osborn obtain explicit expressions for the conformal blocks in four-dimensional conformal field theories?\",\n",
      "    \"A\": \"Francis Dolan\",\n",
      "    \"B\": \"Johanna Erdmenger\",\n",
      "    \"C\": \"Ian Jack\",\n",
      "    \"D\": \"Tassos Petkou\",\n",
      "    \"E\": \"Jeong-Hyuck Park\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/h.parquet:  29%|████████████████████████████████████████████████████████████▌                                                                                                                                                    | 11/38 [01:21<03:35,  7.97s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 21572 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/h.parquet:  32%|██████████████████████████████████████████████████████████████████                                                                                                                                               | 12/38 [01:22<02:31,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 21572 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is the traditional ecological knowledge of the Bisa people?\",\n",
      "    \"A\": \"The Bisa people believe that caterpillars have been with them since time immemorial, as gifts from god.\",\n",
      "    \"B\": \"The Bisa people believe that caterpillars are dangerous and should not be consumed.\",\n",
      "    \"C\": \"The Bisa people believe that caterpillars are sacred and should only be consumed during specific rituals.\",\n",
      "    \"D\": \"The Bisa people believe that caterpillars are a valuable source of nutrition and should be consumed regularly.\",\n",
      "    \"E\": \"The Bisa people do not have any traditional ecological knowledge regarding caterpillars.\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/h.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [04:03<00:00,  6.40s/it]\n",
      "../data/wikipedia/i.parquet:  11%|████████████████████████                                                                                                                                                                                          | 4/35 [00:22<02:56,  5.68s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/i.parquet:  14%|██████████████████████████████                                                                                                                                                                                    | 5/35 [00:32<03:35,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about Interatomic Coulombic Decay (ICD)?\n",
      "\n",
      "A. ICD is a relaxation process that can only occur in atomic clusters.\n",
      "B. ICD is a process that occurs when an atom or molecule is in a state energetically higher than the ionization threshold of other atoms or molecules in the neighborhood.\n",
      "C. ICD is a process that competes with slow radiative decay and autoionization.\n",
      "D. ICD is a process that can only occur after core-electron excitations.\n",
      "E. ICD is a process that typically takes place on the picosecond time scale.\n",
      "\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/i.parquet:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 25/35 [03:01<01:17,  7.73s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/i.parquet:  74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 26/35 [03:08<01:07,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a goal of the International Mammalian Genome Society (IMGS)?\n",
      "\n",
      "A) Facilitating the creation of databases of genetic information\n",
      "B) Organizing meetings for mammalian geneticists to share expertise\n",
      "C) Coordinating the mapping and sequencing of model organisms\n",
      "D) Promoting and coordinating the genetic and genomic study of mammals\n",
      "E) Supervising the organization of genetic data into genetic maps and reference genomes\n",
      "\n",
      "Answer: D) Promoting and coordinating the genetic and genomic study of mammals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/i.parquet:  77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                               | 27/35 [03:16<01:00,  7.59s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/i.parquet:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 28/35 [03:21<00:48,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which organization has been the flagship conference of the APBioNet?\n",
      "\n",
      "A. Thailand National Center for Genetic Engineering and Biotechnology (BIOTEC)\n",
      "B. Asia Pacific Bioinformatics Network (APBioNet)\n",
      "C. International Conference on Bioinformatics (InCoB)\n",
      "D. Bioinformation journal\n",
      "E. BMC Bioinformatics\n",
      "\n",
      "Answer: C. International Conference on Bioinformatics (InCoB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/i.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [04:04<00:00,  6.98s/it]\n",
      "../data/wikipedia/j.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [03:27<00:00,  6.90s/it]\n",
      "../data/wikipedia/k.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:21<00:00,  8.30s/it]\n",
      "../data/wikipedia/l.parquet:   9%|██████████████████▍                                                                                                                                                                                               | 5/57 [00:32<05:10,  5.97s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 33154 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/l.parquet:  11%|██████████████████████                                                                                                                                                                                            | 6/57 [00:33<03:36,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 33154 tokens. Please reduce the length of the messages.\n",
      "{\n",
      "  \"prompt\": \"Which organization is responsible for statistics in the United States?\",\n",
      "  \"A\": \"United Nations Secretariat\",\n",
      "  \"B\": \"United States Census Bureau\",\n",
      "  \"C\": \"Central Bureau of Statistics\",\n",
      "  \"D\": \"National Bureau of Statistics\",\n",
      "  \"E\": \"Statistics Division\",\n",
      "  \"answer\": \"B\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  28%|██████████████████████████████████████████████████████████▋                                                                                                                                                      | 16/57 [01:28<03:31,  5.17s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 20352 tokens (16352 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/l.parquet:  30%|██████████████████████████████████████████████████████████████▎                                                                                                                                                  | 17/57 [01:28<02:29,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 20352 tokens (16352 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"When was the Lincolnshire Naturalists' Union founded?\",\n",
      "    \"A\": \"1893\",\n",
      "    \"B\": \"1894\",\n",
      "    \"C\": \"1895\",\n",
      "    \"D\": \"1896\",\n",
      "    \"E\": \"1897\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  35%|█████████████████████████████████████████████████████████████████████████▎                                                                                                                                       | 20/57 [01:46<03:12,  5.21s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 33591 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/l.parquet:  37%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 21/57 [01:47<02:23,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 33591 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is the largest league victory for Austin FC?\",\n",
      "    \"A\": \"5-0 v FC Cincinnati\",\n",
      "    \"B\": \"0-4 @ San Jose Earthquakes\",\n",
      "    \"C\": \"2-1 @ FC Dallas\",\n",
      "    \"D\": \"0-3 @ LAFC\",\n",
      "    \"E\": \"2-0 v Violette AC\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  53%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 30/57 [04:17<13:40, 30.40s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/l.parquet:  54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 31/57 [04:26<10:17, 23.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true based on the given context?\n",
      "\n",
      "A) There were a total of 94 AFL debuts in 2017.\n",
      "B) There were a total of 50 players who changed clubs in 2017.\n",
      "C) The youngest player to debut in 2017 was 18 years and 255 days old.\n",
      "D) There were a total of 23 players who were traded in 2016.\n",
      "E) There were a total of 15 players who were free agents in 2016.\n",
      "\n",
      "Answer: A) There were a total of 94 AFL debuts in 2017.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                     | 38/57 [05:22<02:48,  8.89s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 16576 tokens (12576 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/l.parquet:  68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 39/57 [05:23<01:55,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 16576 tokens (12576 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Laura Mersini-Houghton is a proponent of which hypothesis?\",\n",
      "    \"A\": \"Quantum mechanics\",\n",
      "    \"B\": \"Multiverse\",\n",
      "    \"C\": \"Black hole formation\",\n",
      "    \"D\": \"Gravitational dynamics\",\n",
      "    \"E\": \"Hawking radiation\",\n",
      "    \"answer\": \"B\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 41/57 [05:34<01:38,  6.13s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/l.parquet:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 42/57 [05:41<01:35,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about the La Tène culture is true?\n",
      "\n",
      "A) The La Tène culture developed and flourished during the late Iron Age.\n",
      "B) The La Tène culture succeeded the Hallstatt culture without any cultural break.\n",
      "C) The La Tène culture was influenced by Mediterranean cultures.\n",
      "D) The La Tène culture was present in France, Belgium, Switzerland, Austria, England, and other regions.\n",
      "E) All of the above.\n",
      "\n",
      "Answer: E) All of the above.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 51/57 [06:35<00:36,  6.01s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/l.parquet:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                  | 52/57 [06:40<00:28,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which player holds the current world record for the most goals scored in an international football match?\n",
      "\n",
      "A) Archie Thompson\n",
      "B) David Zdrilic\n",
      "C) Shokhan Nooraldin Salihi\n",
      "D) Hacène Lalmas\n",
      "E) Malika-e-Noor\n",
      "\n",
      "Answer: C) Shokhan Nooraldin Salihi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 53/57 [06:45<00:22,  5.64s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/l.parquet:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████           | 54/57 [06:49<00:15,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT a use case for lattice models in finance?\n",
      "\n",
      "A. Valuing American options\n",
      "B. Valuing European options\n",
      "C. Valuing interest rate derivatives\n",
      "D. Valuing exotic options\n",
      "E. Valuing equity options\n",
      "\n",
      "Answer: B. Valuing European options\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/l.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [07:09<00:00,  7.54s/it]\n",
      "../data/wikipedia/m.parquet:   9%|██████████████████▊                                                                                                                                                                                               | 6/67 [00:39<06:37,  6.52s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 4 column 79 (char 179)\n",
      "../data/wikipedia/m.parquet:  10%|█████████████████████▉                                                                                                                                                                                            | 7/67 [00:49<07:29,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 4 column 79 (char 179)\n",
      "{\n",
      "  \"prompt\": \"Which of the following statements about matter collineation is true?\",\n",
      "  \"choices\": [\n",
      "    \"A. A matter collineation is a vector field that satisfies the condition, \\(\\mathcal{L}_X T_{ab}=0\\)\",\n",
      "    \"B. A matter collineation is a vector field that preserves the metric\",\n",
      "    \"C. A matter collineation is a vector field that preserves the electric and magnetic fields\",\n",
      "    \"D. A matter collineation is a vector field that preserves the energy density, pressure, and fluid flow vector field\",\n",
      "    \"E. A matter collineation is a vector field that satisfies the Einstein field equations (EFE)\"\n",
      "  ],\n",
      "  \"answer\": \"A\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/m.parquet:  25%|█████████████████████████████████████████████████████                                                                                                                                                            | 17/67 [02:19<06:51,  8.22s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/m.parquet:  27%|████████████████████████████████████████████████████████▏                                                                                                                                                        | 18/67 [02:27<06:36,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about Metamath?\n",
      "\n",
      "A. Metamath is a programming language used for formalizing mathematical proofs.\n",
      "B. Metamath is a database of proved theorems in various branches of mathematics.\n",
      "C. Metamath is a proof checker program written in C.\n",
      "D. Metamath is a formal language used for archiving, verifying, and studying mathematical proofs.\n",
      "E. Metamath is a theorem prover program used for interactive browsing of formalized theorems.\n",
      "\n",
      "Answer: D. Metamath is a formal language used for archiving, verifying, and studying mathematical proofs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/m.parquet:  54%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                | 36/67 [04:25<03:36,  6.98s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia/m.parquet:  55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 37/67 [09:39<49:30, 99.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Mei-Cheng Wang earned a bachelor's degree in mathematics from which university?\",\n",
      "    \"choices\": {\n",
      "      \"A\": \"Johns Hopkins University\",\n",
      "      \"B\": \"University of California, Berkeley\",\n",
      "      \"C\": \"National Tsing Hua University\",\n",
      "      \"D\": \"Stanford University\",\n",
      "      \"E\": \"Harvard University\"\n",
      "    },\n",
      "    \"answer\": \"C\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/m.parquet:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                          | 43/67 [10:17<06:52, 17.20s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/m.parquet:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 44/67 [10:22<05:10, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT an advantage of using mixed oxidant solution for water disinfection compared to other methods?\n",
      "\n",
      "A) Higher disinfecting power\n",
      "B) Stable residual chlorine in water\n",
      "C) Improved taste and smell\n",
      "D) Elimination of biofilm\n",
      "E) Lower cost of production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/m.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [12:31<00:00, 11.22s/it]\n",
      "../data/wikipedia/n.parquet:   6%|█████████████▏                                                                                                                                                                                                    | 2/32 [00:12<03:08,  6.28s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/n.parquet:   9%|███████████████████▋                                                                                                                                                                                              | 3/32 [00:19<03:12,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about Nordström's theory of gravitation is true?\n",
      "\n",
      "A. Nordström's theory is a predecessor of general relativity.\n",
      "B. Nordström's theory is in agreement with observation and experiment.\n",
      "C. Nordström's theory is a tensor theory of gravitation.\n",
      "D. Nordström's theory does not consider the effects of gravitation on the geometry of spacetime.\n",
      "E. Nordström's theory is a self-consistent relativistic theory of gravitation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/n.parquet:  28%|███████████████████████████████████████████████████████████                                                                                                                                                       | 9/32 [00:50<01:55,  5.04s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, you requested 17842 tokens (13842 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia/n.parquet:  31%|█████████████████████████████████████████████████████████████████▎                                                                                                                                               | 10/32 [00:50<01:18,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, you requested 17842 tokens (13842 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Which period does the Nanaimo Formation preserve fossils from?\",\n",
      "    \"A\": \"Jurassic\",\n",
      "    \"B\": \"Cretaceous\",\n",
      "    \"C\": \"Triassic\",\n",
      "    \"D\": \"Permian\",\n",
      "    \"E\": \"Cambrian\",\n",
      "    \"answer\": \"B\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/n.parquet:  59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 19/32 [01:46<01:19,  6.11s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/n.parquet:  62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 20/32 [01:51<01:08,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Prompt: Which of the following is NOT a team level statistic in network science based basketball analytics?\n",
      "\n",
      "A) Team entropy\n",
      "B) Uphill downhill flux\n",
      "C) Success/Failure Ratio\n",
      "D) Team clustering coefficient\n",
      "E) Average path length\n",
      "\n",
      "Answer: C) Success/Failure Ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/n.parquet:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 23/32 [02:18<01:07,  7.49s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/n.parquet:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 24/32 [02:25<01:00,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements accurately describes the \"no free lunch\" theorem?\n",
      "\n",
      "A. The theorem states that there is no universal optimization strategy that outperforms all other strategies on every possible problem.\n",
      "B. The theorem states that all search algorithms are equivalent when their performance is averaged across all possible problems.\n",
      "C. The theorem states that the computational cost of finding a solution is the same for all solution methods.\n",
      "D. The theorem states that there is no advantage to specializing an algorithm to a specific problem.\n",
      "E. The theorem states that the performance of search algorithms depends on the randomness of the objective function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/n.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [03:06<00:00,  5.83s/it]\n",
      "../data/wikipedia/number.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:33<00:00,  6.66s/it]\n",
      "../data/wikipedia/o.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [01:52<00:00,  6.27s/it]\n",
      "../data/wikipedia/other.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:10<00:00, 10.72s/it]\n",
      "../data/wikipedia/p.parquet:  10%|████████████████████                                                                                                                                                                                              | 6/63 [00:42<06:41,  7.05s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/p.parquet:  11%|███████████████████████▎                                                                                                                                                                                          | 7/63 [00:52<07:33,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Question:\n",
      "Which of the following is the main goal of the Protein Common Interface Database (ProtCID)?\n",
      "\n",
      "A) To identify and cluster homodimeric and heterodimeric interfaces observed in crystal structures of homologous proteins.\n",
      "B) To provide PyMol scripts for each cluster to produce similar images.\n",
      "C) To compare homodimeric interfaces in all crystals that contain particular domain or chain architectures.\n",
      "D) To report the number of crystal forms that contain a common interface.\n",
      "E) To provide an independent check on publicly available annotations of biological interactions for PDB entries.\n",
      "\n",
      "Answer: A) To identify and cluster homodimeric and heterodimeric interfaces observed in crystal structures of homologous proteins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/p.parquet:  43%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 27/63 [03:25<03:50,  6.40s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/p.parquet:  44%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 28/63 [03:33<03:58,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about persistent carbenes is true?\n",
      "\n",
      "A. Persistent carbenes are highly reactive and cannot be isolated as pure substances.\n",
      "B. The stability of persistent carbenes is solely due to steric hindrance by bulky groups.\n",
      "C. Triplet state carbenes have longer half-lives compared to singlet state carbenes.\n",
      "D. Persistent carbenes can be prepared by deprotonation of precursor salts with strong bases.\n",
      "E. Stable carbenes are not suitable for use as ligands in organometallic chemistry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/p.parquet:  71%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 45/63 [05:32<02:00,  6.71s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/p.parquet:  73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 46/63 [05:38<01:52,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about polyploidy is true?\n",
      "\n",
      "A. Polyploidy is a condition in which the cells of an organism have more than one pair of chromosomes.\n",
      "B. Polyploidy is only common in animals, not in plants.\n",
      "C. Polyploidy can only occur due to abnormal cell division during mitosis.\n",
      "D. Polyploidy is a rare occurrence in humans.\n",
      "E. Polyploidy is a result of fusion of reduced gametes during meiosis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/p.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [07:27<00:00,  7.11s/it]\n",
      "../data/wikipedia/q.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:32<00:00,  6.41s/it]\n",
      "../data/wikipedia/r.parquet:  33%|█████████████████████████████████████████████████████████████████████▋                                                                                                                                           | 14/42 [01:29<02:38,  5.66s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/r.parquet:  36%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 15/42 [01:35<02:36,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements accurately describes the Rhenohercynian Zone?\n",
      "\n",
      "A) It is a fold belt formed during the Hercynian orogeny.\n",
      "B) It consists of folded and thrust sedimentary rocks.\n",
      "C) It was deposited in a back-arc basin along the southern margin of Laurussia.\n",
      "D) It extends from Cornwall and Ireland in the west to the Harz mountains in central Germany.\n",
      "E) All of the above.\n",
      "\n",
      "Answer: E) All of the above.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/r.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [04:15<00:00,  6.09s/it]\n",
      "../data/wikipedia/s.parquet:  43%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 33/77 [03:26<04:39,  6.35s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/s.parquet:  44%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                    | 34/77 [03:30<04:07,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following markers is NOT used by the SGM Plus DNA profiling system?\n",
      "\n",
      "A) D2S1338\n",
      "B) D3S1358\n",
      "C) D16S539\n",
      "D) D19S433\n",
      "E) D21S11\n",
      "\n",
      "Answer: A) D2S1338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet:  58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 45/77 [05:02<03:58,  7.45s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/s.parquet:  60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 46/77 [05:08<03:41,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements about the special unitary group is true?\n",
      "\n",
      "A. The special unitary group is a subgroup of the unitary group.\n",
      "B. The special unitary group is a complex Lie group.\n",
      "C. The special unitary group is isomorphic to the group of quaternions of norm 1.\n",
      "D. The special unitary group is a simply-connected Lie group.\n",
      "E. The special unitary group is a subgroup of the general linear group.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet:  68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                   | 52/77 [05:41<02:18,  5.53s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/s.parquet:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 53/77 [05:45<02:05,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following fields has Salvatore Torquato made significant contributions to?\n",
      "\n",
      "A) Physics\n",
      "B) Chemistry\n",
      "C) Mathematics\n",
      "D) Materials Science\n",
      "E) All of the above\n",
      "\n",
      "Answer: E) All of the above\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet:  74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 57/77 [06:08<01:56,  5.83s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 23368 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/s.parquet:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 58/77 [06:09<01:23,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 23368 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What does the SWEAT hypothesis propose?\",\n",
      "    \"A\": \"The Southwestern United States was once connected to East Antarctica.\",\n",
      "    \"B\": \"The Southwestern United States was once connected to Australia.\",\n",
      "    \"C\": \"The Southwestern United States was once connected to India.\",\n",
      "    \"D\": \"The Southwestern United States was once connected to Canada.\",\n",
      "    \"E\": \"The Southwestern United States was never connected to any other landmass.\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet:  81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 62/77 [06:33<01:29,  5.94s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 29785 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/s.parquet:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 63/77 [06:34<01:01,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 29785 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"What is a stenotherm?\",\n",
      "    \"A\": \"An organism that can function at a wide range of different body temperatures\",\n",
      "    \"B\": \"An organism that can only live or survive within a narrow temperature range\",\n",
      "    \"C\": \"An organism that lives in deep sea environments\",\n",
      "    \"D\": \"An organism that lives in polar regions\",\n",
      "    \"E\": \"An organism that has a stable internal temperature\",\n",
      "    \"answer\": \"B\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet:  96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊        | 74/77 [07:42<00:17,  5.82s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/s.parquet:  97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌     | 75/77 [07:50<00:12,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Prompt: Which of the following statements about Sphenacodon is true?\n",
      "\n",
      "A) Sphenacodon had a tall dorsal sail similar to Dimetrodon.\n",
      "B) Sphenacodon is known from New Mexico and the Utah–Arizona border region.\n",
      "C) Sphenacodon ferox is larger in overall size compared to Sphenacodon ferocior.\n",
      "D) Sphenacodon and Dimetrodon have the same type of neural spines along their back.\n",
      "E) Sphenacodon is classified as a therapsid.\n",
      "\n",
      "Answer: B) Sphenacodon is known from New Mexico and the Utah–Arizona border region.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/s.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77/77 [08:01<00:00,  6.25s/it]\n",
      "../data/wikipedia/t.parquet:   4%|█████████▎                                                                                                                                                                                                        | 2/45 [00:09<03:30,  4.90s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia/t.parquet:   7%|██████████████                                                                                                                                                                                                    | 3/45 [02:01<37:41, 53.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Who introduced the three-domain system of biological classification?\",\n",
      "    \"A\": \"Carl Woese\",\n",
      "    \"B\": \"Otto Kandler\",\n",
      "    \"C\": \"Mark Wheelis\",\n",
      "    \"D\": \"Salvador Luria\",\n",
      "    \"E\": \"Ernst Mayr\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/t.parquet:  20%|██████████████████████████████████████████                                                                                                                                                                        | 9/45 [02:36<05:51,  9.75s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/t.parquet:  22%|██████████████████████████████████████████████▍                                                                                                                                                                  | 10/45 [03:28<13:22, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements accurately describes the book \"The Genesis Flood: The Biblical Record and its Scientific Implications\"?\n",
      "\n",
      "A) The book argues that the age of the Earth is well over 20 million years.\n",
      "B) The book defends the theory of evolution and criticizes young Earth creationism.\n",
      "C) The book was published in the late nineteenth century and had a significant impact on Christian views of the Flood.\n",
      "D) The book received positive reviews from mainstream scientists and geologists.\n",
      "E) The book was written by John C. Whitcomb and Henry M. Morris and elevated young Earth creationism to a position of fundamentalist orthodoxy.\n",
      "\n",
      "Answer: E) The book was written by John C. Whitcomb and Henry M. Morris and elevated young Earth creationism to a position of fundamentalist orthodoxy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/t.parquet:  31%|█████████████████████████████████████████████████████████████████                                                                                                                                                | 14/45 [04:00<05:39, 10.94s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/t.parquet:  33%|█████████████████████████████████████████████████████████████████████▋                                                                                                                                           | 15/45 [04:03<04:23,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which experiment directly observed the transverse Doppler effect and time dilation for the first time?\n",
      "\n",
      "A) Michelson-Morley experiment\n",
      "B) Kennedy-Thorndike experiment\n",
      "C) Ives-Stilwell experiment\n",
      "D) Hughes-Drever experiment\n",
      "E) Sagnac effect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/t.parquet:  44%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 20/45 [04:35<02:45,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following is NOT one of Tinbergen's four questions?\n",
      "\n",
      "A) Function (adaptation)\n",
      "B) Phylogeny (evolution)\n",
      "C) Mechanism (causation)\n",
      "D) Ontogeny (development)\n",
      "E) Ecology (environment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/t.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [06:59<00:00,  9.33s/it]\n",
      "../data/wikipedia/u.parquet:  12%|██████████████████████████▍                                                                                                                                                                                        | 1/8 [00:07<00:51,  7.29s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/u.parquet:  25%|████████████████████████████████████████████████████▊                                                                                                                                                              | 2/8 [00:11<00:31,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which player has the most caps for the Uruguay national football team?\n",
      "\n",
      "A) Diego Godín\n",
      "B) Luis Suárez\n",
      "C) Edinson Cavani\n",
      "D) Fernando Muslera\n",
      "E) Maxi Pereira\n",
      "\n",
      "Answer: A) Diego Godín\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/u.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:46<00:00,  5.81s/it]\n",
      "../data/wikipedia/v.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [01:31<00:00,  6.12s/it]\n",
      "../data/wikipedia/w.parquet:  10%|█████████████████████                                                                                                                                                                                             | 2/20 [00:10<01:36,  5.36s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 38, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_29328/1456674105.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 16385 tokens. However, your messages resulted in 19129 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia/w.parquet:  15%|███████████████████████████████▌                                                                                                                                                                                  | 3/20 [00:12<00:58,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 16385 tokens. However, your messages resulted in 19129 tokens. Please reduce the length of the messages.\n",
      "[\n",
      "  {\n",
      "    \"prompt\": \"Who is William Kruskal?\",\n",
      "    \"A\": \"An American mathematician and statistician\",\n",
      "    \"B\": \"A British physicist\",\n",
      "    \"C\": \"A German chemist\",\n",
      "    \"D\": \"A French biologist\",\n",
      "    \"E\": \"A Russian engineer\",\n",
      "    \"answer\": \"A\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/w.parquet:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                               | 17/20 [01:29<00:16,  5.59s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/w.parquet:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 18/20 [01:32<00:09,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Prompt: Who delivered the Witherby Memorial Lecture in 2019?\n",
      "\n",
      "A) Arthur Landsborough Thomson\n",
      "B) David Lack\n",
      "C) H. N. Southern\n",
      "D) Bob Furness\n",
      "E) Claire Spottiswoode\n",
      "\n",
      "Answer: D) Bob Furness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia/w.parquet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [01:42<00:00,  5.12s/it]\n",
      "../data/wikipedia/x.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.74s/it]\n",
      "../data/wikipedia/y.parquet:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3/4 [00:15<00:05,  5.25s/it]Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_29328/324541624.py\", line 39, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "../data/wikipedia/y.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n",
      "Which of the following statements is true about the Yukawa Institute for Theoretical Physics?\n",
      "\n",
      "A) The institute was founded in 1944 by Yoshitaka Mimura.\n",
      "B) The institute was named after the first Japanese citizen to receive the Nobel Prize in Physics.\n",
      "C) The institute is located in Hiroshima, Japan.\n",
      "D) The institute's research areas include non-equilibrium statistical physics and non-linear physics.\n",
      "E) The institute has had 13 academic positions since its inception in 1952.\n",
      "\n",
      "Answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "../data/wikipedia/z.parquet: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import traceback \n",
    "batch_size = 1\n",
    "\n",
    "def make_prompt(series):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI assistant who specializes in answering multiple-choice questions. You may use the context below if it helps you to answer the following multiple-choice question.\n",
    "The output should be an array of json format, with \"prompt\" as the question statement, \"A,\" \"B,\" \"C,\" \"D,\" and \"E\" as choices, \"answer\" as the answer choice (one of A through E).\n",
    "\n",
    "Context:\n",
    "{series['text']}\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def f(series):\n",
    "    if series[\"A\"] != series[\"A\"]:\n",
    "        if type(series[\"choices\"]) == dict:\n",
    "            for key in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "                series[key] = series[\"choices\"][key]\n",
    "        elif type(series[\"choices\"] == list):\n",
    "            for i, key in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\"]):\n",
    "                series[key] = series[\"choices\"][i]\n",
    "    return series\n",
    "\n",
    "now_date = dt.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "first = True\n",
    "for file in files:\n",
    "    if os.path.basename(file) in [\"all.parquet\"]:\n",
    "        print(f\"pass: {file}\")\n",
    "        continue\n",
    "    df_science = get_df(file)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(df_science)), desc=file):\n",
    "        try:\n",
    "            series = df_science.iloc[i]\n",
    "            prompt = make_prompt(series)\n",
    "            text = query_prompt(prompt)\n",
    "            texts_json = json.loads(text)\n",
    "            if first:\n",
    "                print(texts_json)\n",
    "                first = False\n",
    "            if type(texts_json) == dict:\n",
    "                text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                text_json[\"original_text\"] = series[\"text\"]\n",
    "                texts.append(text_json)\n",
    "            else:\n",
    "                for text_json in texts_json:\n",
    "                    text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                    text_json[\"original_text\"] = series[\"text\"]\n",
    "                    texts.append(text_json)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "            print(text)\n",
    "        if i % 20 == 0:\n",
    "            df_texts = pd.DataFrame(texts)\n",
    "            df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "            df_texts.to_csv(f\"output_gpt3.5_generate/{now_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_texts.to_csv(f\"output_gpt3.5_generate/{now_date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                                                                                              435\n",
       "B                                                                                              167\n",
       "C                                                                                              144\n",
       "D                                                                                               93\n",
       "E                                                                                               84\n",
       "Arturo Zychlinsky                                                                                3\n",
       "It must have been published within the past 6 calendar years of the year of its nomination.      2\n",
       "James Ivory                                                                                      2\n",
       "Discovery of the autoimmune regulator and the AIRE gene (1997)                                   2\n",
       "A and B                                                                                          1\n",
       "Theodore Clinton McIlvaine                                                                       1\n",
       "232                                                                                              1\n",
       "Charl Pietersen                                                                                  1\n",
       "Paul Taylor                                                                                      1\n",
       "George Sharp                                                                                     1\n",
       "Toby Bailey                                                                                      1\n",
       "A, B                                                                                             1\n",
       "Martyn Cundy and A. P. Rollett                                                                   1\n",
       "Wayne Larkins                                                                                    1\n",
       "Russell Johnson                                                                                  1\n",
       "15 April 1185                                                                                    1\n",
       "Ak(m)                                                                                            1\n",
       "Moscow State University                                                                          1\n",
       "Shiraz, Pahlavi Iran                                                                             1\n",
       "1206                                                                                             1\n",
       "Alan Fordham                                                                                     1\n",
       "41                                                                                               1\n",
       "Director of Technical and Quality                                                                1\n",
       "Probabilistic Theory of Mean Field Games with Applications                                       1\n",
       "Sunset Red                                                                                       1\n",
       "Michael van Gerwen                                                                               1\n",
       "H                                                                                                1\n",
       "Above sea-level                                                                                  1\n",
       "Lionel Messi                                                                                     1\n",
       "William P. Thurston                                                                              1\n",
       "Paul and Virginia Halmos                                                                         1\n",
       "425                                                                                              1\n",
       "Paul Sax                                                                                         1\n",
       "Adolf Korte                                                                                      1\n",
       "1828                                                                                             1\n",
       "August 25, 1960                                                                                  1\n",
       "Rob Bailey                                                                                       1\n",
       "David Capel                                                                                      1\n",
       "Leonard Johnston Wills                                                                           1\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_texts[\"answer\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
