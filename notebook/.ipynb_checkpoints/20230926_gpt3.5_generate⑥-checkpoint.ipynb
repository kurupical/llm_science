{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../apikey/apikey.txt\", \"r\") as f:\n",
    "    openai.api_key = f.readline().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prompt(prompt, max_tokens=1000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(fname):\n",
    "    def f(categories):\n",
    "        for cat in categories:\n",
    "            for word in [\n",
    "                \"geology\",\n",
    "                \"physics\",\n",
    "                \"chemistry\",\n",
    "                \"mathematical\",\n",
    "                \"biology\",\n",
    "                \"astronomy\",\n",
    "                \"ecology\",\n",
    "                \"genetics\",\n",
    "                \"statistics\",\n",
    "                \"theoretical\"\n",
    "            ]:\n",
    "                if word.lower() in cat.lower():\n",
    "                    return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def text_preprocess(text):\n",
    "        return text.replace(\"====\", \"\\n\\n\").replace(\"===\", \"\\n\\n\").replace(\"==\", \"\\n\\n\")\n",
    "\n",
    "    def sep_n(text, n=60):\n",
    "        try:\n",
    "            text = text.split(\".\")\n",
    "            start_index = random.randint(0, len(text) - n)\n",
    "            return \".\".join(text[start_index:start_index+n])\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    df = pd.read_parquet(fname)\n",
    "    df_science = df[df[\"category\"].apply(f)]\n",
    "    df_science[\"text\"] = df_science[\"text\"].apply(text_preprocess)\n",
    "    df_science[\"text\"] = df_science[\"text\"].apply(sep_n)\n",
    "    df_science = df_science[df_science[\"text\"].notnull()]\n",
    "    return df_science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/wikipedia_fixed/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/a.parquet:   0%|                                        | 1/1552 [00:04<1:53:59,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Which book discusses the generation of datasets with varied appearance and identical statistics?', 'answer': 'E', 'A': 'Data Analysis with Open Source Tools', 'B': 'Regression Analysis by Example', 'C': 'Statistical Methods: The geometric approach', 'D': 'The Visual Display of Quantitative Information', 'E': 'Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/a.parquet:   1%|▌                                      | 20/1552 [01:53<2:26:12,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 10347 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"According to the research cited in the provided text, which statement accurately describes the evolution of colony size in ants?\", \"answer\": \"C\", \"A\": \"Ant colonies have consistently increased in size over time.\", \"B\": \"The size of ant colonies has remained relatively stable throughout evolutionary history.\", \"C\": \"There is a wide range of colony sizes among different ant species.\", \"D\": \"Ant colonies have decreased in size over time.\", \"E\": \"The size of ant colonies is primarily determined by environmental factors.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 10347 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:   4%|█▋                                     | 69/1552 [06:17<2:14:53,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 501 (char 500)\n",
      "{\"prompt\": \"Which values quoted in barycentric dynamical time (TDB) or equivalent time scales represent the mean values that would be measured by an observer on the Earth's surface over a long period of time?\", \"answer\": \"A\", \"A\": \"Values quoted in barycentric dynamical time (TDB) or equivalent time scales such as the Teph of the Jet Propulsion Laboratory ephemerides\", \"B\": \"Values in SI units\", \"C\": \"Values obtained by the following transformations: τ A ( S I ) = ( 1 + L B ) 1 3 τ A ( T D B ) {\\displaystyle \\tau _{A}({\\rm {SI}})=(1+L_{\\rm {B}})^{\\frac {1}{3}}\\tau _{A}({\\rm {TDB}})\\,} G E ( S I ) = ( 1 + L B ) G E ( T D B ) {\\displaystyle GE({\\rm {SI}})=(1+L_{\\rm {B}})GE({\\rm {TDB}})\\,} G S ( S I ) = ( 1 + L B ) G S ( T D B ) {\\displaystyle GS({\\rm {SI}})=(1+L_{\\rm {B}})GS({\\rm {TDB}})\\,}\", \"D\": \"Values recommended by the IAU\", \"E\": \"Values measured by an observer at the barycentre of the Solar System\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 501 (char 500)\n",
      "../data/wikipedia_fixed/a.parquet:   7%|██▊                                   | 114/1552 [10:16<2:44:11,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5268 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the stereochemical labels given to enantiomers of axially chiral compounds?\", \"answer\": \"C\", \"A\": \"The stereochemical labels for enantiomers of axially chiral compounds are based on the Cahn–Ingold–Prelog priority rules used for tetrahedral stereocenters.\", \"B\": \"The stereochemical labels for enantiomers of axially chiral compounds are (Ra) and (Sa), which are sometimes abbreviated as (R) and (S).\", \"C\": \"The stereochemical labels for enantiomers of axially chiral compounds are (Ra) and (Sa), which are sometimes abbreviated as (R) and (S), and are based on the Cahn–Ingold–Prelog priority rules used for tetrahedral stereocenters.\", \"D\": \"The stereochemical labels for enantiomers of axially chiral compounds are (P) and (M) for a right-handed helix, and (Λ) and (Δ) for a left-handed helix.\", \"E\": \"The stereochemical labels for enantiomers of axially chiral compounds are (P) and (M) for a right-handed helix, and (Λ) and (Δ) for a left-handed helix, and are based on the Cahn–Ingold–Prelog priority rules used for tetrahedral stereocenters.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5268 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  11%|████▏                                 | 170/1552 [15:34<2:11:03,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 610 (char 609)\n",
      "{\"prompt\": \"Which statement accurately describes Johannes Kepler's discovery about the orbits of planets?\", \"answer\": \"C\", \"A\": \"Kepler presented evidence that all planets travel in elliptical orbits in his Astronomia nova.\", \"B\": \"Kepler rejected circular and oval orbits and concluded that Mars' orbit must be elliptical.\", \"C\": \"Kepler's geometric proof that Mars' orbit is an ellipse appears in Protheorema XI on pages 289-290.\", \"D\": \"Kepler presented his second law in his Epitome of 1621, which states that a radius from the Sun to a planet passes through equal areas in equal times.\", \"E\": \"Kepler's \"distance law\" states that the force that moves a planet circularly weakens with distance from the source.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 610 (char 609)\n",
      "../data/wikipedia_fixed/a.parquet:  12%|████▋                                 | 193/1552 [17:58<1:58:38,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5933 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What are some benefits of Assisted Natural Regeneration (ANR)?\", \"answer\": \"C\", \"A\": \"ANR focuses on reducing ecological barriers in order to accelerate natural regeneration and growth, rather than the planting of seedlings.\", \"B\": \"ANR requires high maintenance and can be labor-intensive, and involve methods of weeding, grass pressing, establishing and maintaining firebreaks, etc.\", \"C\": \"Carbon sequestration, biodiversity enrichment and recovery are just a few environmental benefits ANR provides, which can help improve ecosystems and mitigate climate change.\", \"D\": \"ANR focuses on native species and natural succession of existing vegetation, which ensures that plant communities and inhabiting wildlife are maintained and are not disturbed.\", \"E\": \"ANR is gaining popularity as global climate change becomes a growing concern.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5933 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  15%|█████▊                                | 239/1552 [21:43<1:49:09,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4591 tokens (3591 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of alanine scanning in the studies mentioned in the text?\", \"answer\": \"C\", \"A\": \"To determine the structure of cyclotides kalata B1\", \"B\": \"To test the activities of Cry4Aa mutants in Culex pipiens\", \"C\": \"To identify the functional motifs of Cry4Aa and determine their contribution to mosquitocidal activity\", \"D\": \"To map protein functional epitopes by combinatorial alanine scanning\", \"E\": \"To exchange most canonical amino acids with alanine by point mutations\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4591 tokens (3591 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  15%|█████▉                                | 240/1552 [21:53<2:23:43,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4410 tokens (3410 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of alanine scanning in the studies mentioned in the text?\", \"answer\": \"C\", \"A\": \"To determine the structure of cyclotides kalata B1\", \"B\": \"To test the activities of Cry4Aa mutants in Culex pipiens\", \"C\": \"To identify the functional motifs of Cry4Aa and determine their contribution to mosquitocidal activity\", \"D\": \"To map protein functional epitopes by combinatorial alanine scanning\", \"E\": \"To exchange most canonical amino acids with alanine by point mutations\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4410 tokens (3410 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  19%|███████▏                              | 295/1552 [26:35<1:48:53,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4459 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes Andrew Knyazev's research?\", \"answer\": \"C\", \"A\": \"Andrew Knyazev won the Excellence in Research and Creative Activities Award in 2008.\", \"B\": \"Andrew Knyazev is a Professor Emeritus at the University of Colorado Denver.\", \"C\": \"Andrew Knyazev has published papers on preconditioned eigensolvers and large scale ab initio calculations.\", \"D\": \"Andrew Knyazev is a Fellow of the American Mathematical Society.\", \"E\": \"Andrew Knyazev has received the President's Faculty Excellence Award for Advancing Teaching and Learning through Technology.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4459 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  21%|████████                              | 330/1552 [29:40<1:54:17,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4671 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"When was APS founded and what was its significance in the scientific community?\", \"answer\": \"B\", \"A\": \"APS was founded in December 1909 and it was the first scientific organization in the world to be devoted exclusively to phytopathology.\", \"B\": \"APS was founded in December 1908 and it was the first scientific organization in the world to be devoted exclusively to phytopathology.\", \"C\": \"APS was founded in December 1908 and it was the first scientific organization in the world to be devoted exclusively to botany.\", \"D\": \"APS was founded in December 1909 and it was the first scientific organization in the world to be devoted exclusively to botany.\", \"E\": \"APS was founded in December 1909 and it was the first scientific organization in the world to be devoted exclusively to mycology.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4671 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  24%|█████████▏                            | 375/1552 [34:00<1:25:27,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4853 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which publication provides information on the single-cell tracking of A549 lung cancer cells exposed to a marine toxin?\", \"answer\": \"C\", \"A\": \"Public Health England\", \"B\": \"MiBioresearch\", \"C\": \"Frontiers in Oncology\", \"D\": \"Cancer Innovation\", \"E\": \"Drug Resistance Updates\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4853 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  25%|█████████▍                            | 383/1552 [34:39<1:26:59,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 7241 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Why is the sky bluer on top than at the horizon?\", \"answer\": \"C\", \"A\": \"The Moon illusion is a phenomenon that affects the perception of the Moon's size when it is near the horizon.\", \"B\": \"African dust has been found to be a major factor affecting air quality in the Southeast U.S.\", \"C\": \"The sky appears bluer on top than at the horizon due to the scattering of shorter-wavelength blue light by the Earth's atmosphere.\", \"D\": \"Clouds have been found to absorb more solar radiation than previously thought.\", \"E\": \"Theoretical fundamentals of atmospheric optics provide insights into the behavior of light in the atmosphere.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 7241 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  28%|██████████▌                           | 431/1552 [39:40<1:28:06,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4816 tokens (3816 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which study investigated the genotoxic effects on human spermatozoa among pesticide factory workers exposed to fenvalerate?\", \"answer\": \"B\", \"A\": \"The study on the relation between occupational fenvalerate exposure and spermatozoa DNA damage of pesticide factory workers\", \"B\": \"The study on genotoxic effects on human spermatozoa among pesticide factory workers exposed to fenvalerate\", \"C\": \"The study on genotoxic effects on spermatozoa of carbaryl-exposed workers\", \"D\": \"The study on chromosomal aneuploidies and DNA fragmentation of human spermatozoa from patients exposed to perfluorinated compounds\", \"E\": \"The study on fetal loss in Down syndrome pregnancies\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4816 tokens (3816 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  28%|██████████▋                           | 437/1552 [40:23<1:44:11,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4460 tokens (3460 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"According to Plato, in order for knowledge to be possible, what must be true about the second level of reality?\", \"answer\": \"C\", \"A\": \"The second level of reality must be constantly changing\", \"B\": \"The second level of reality must be based on direct perception\", \"C\": \"The second level of reality must be unchanging\", \"D\": \"The second level of reality must be based on expertise\", \"E\": \"The second level of reality must be based on true belief\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4460 tokens (3460 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  31%|███████████▊                          | 484/1552 [44:33<1:25:33,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5276 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"According to the text, what did Karl G. Jansky conclude about the steady hiss type static he discovered?\", \"answer\": \"B\", \"A\": \"It was caused by radio frequency interference from thunderstorms.\", \"B\": \"It had an extraterrestrial origin.\", \"C\": \"It was a result of pulsars and quasars.\", \"D\": \"It was a by-product of the search for physical phenomena.\", \"E\": \"It was a form of narrow-band signals.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5276 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  34%|████████████▉                         | 527/1552 [48:43<1:21:58,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements accurately describes Aaron Pixton's achievements in the field of mathematics?\", \"answer\": \"D\", \"A\": \"Aaron Pixton won the US Junior Chess Championship in 2002.\", \"B\": \"Aaron Pixton is a professor at a science university.\", \"C\": \"Aaron Pixton has published multiple papers on the moduli spaces of curves.\", \"D\": \"Aaron Pixton had a win against former US Champion Joel Benjamin in 2003.\", \"E\": \"Aaron Pixton has won the Putnam Competition and the Morgan Prize.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  38%|██████████████▎                       | 584/1552 [59:20<2:04:57,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4625 tokens (3625 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the relationship between the half-life of a radioisotope and the probability of escape at each collision with the repulsive potential barrier of the electromagnetic force?\", \"answer\": \"B\", \"A\": \"The half-life of a radioisotope is directly proportional to the probability of escape at each collision.\", \"B\": \"If the probability of escape at each collision is very small, the half-life of the radioisotope will be very long.\", \"C\": \"The half-life of a radioisotope is inversely proportional to the probability of escape at each collision.\", \"D\": \"The half-life of a radioisotope is not affected by the probability of escape at each collision.\", \"E\": \"The half-life of a radioisotope is equal to the probability of escape at each collision.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4625 tokens (3625 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  40%|██████████████▍                     | 622/1552 [1:02:22<1:15:53,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4854 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What did Professor Reddi and his colleagues discover about bone induction?\", \"answer\": \"C\", \"A\": \"Bone induction is a random process that does not involve chemotaxis, mitosis, and differentiation.\", \"B\": \"Bone induction is a single-step process that does not involve chemotaxis, mitosis, and differentiation.\", \"C\": \"Bone induction is a sequential multistep cascade involving chemotaxis, mitosis, and differentiation.\", \"D\": \"Bone induction is a concentration-independent process that does not involve chemotaxis, mitosis, and differentiation.\", \"E\": \"Bone induction is a process that does not involve chemotaxis, mitosis, and differentiation.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4854 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  48%|█████████████████▏                  | 740/1552 [1:13:23<1:15:27,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is one of the processes that require ammonia as a reactant?\", \"answer\": \"D\", \"A\": \"Replacement of a halogen in an alkyl group by an amine\", \"B\": \"Reaction of a primary amine or secondary amine with a carboxylic acid or with a carboxylic acid derivative to form an amide\", \"C\": \"Conversion of carboxylic acids to ammonium salts\", \"D\": \"PET degradation with polyamines through aminolysis route\", \"E\": \"Reaction of a carboxylic acid with ammonium carbonate to produce ammonium acetate\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  48%|████████████████▊                  | 743/1552 [1:18:47<11:20:24, 50.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4461 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following methods is NOT used to quantify aromaticity with respect to the observed ring current?\", \"answer\": \"E\", \"A\": \"Diamagnetic susceptibility exaltation\", \"B\": \"Chemical shift of lithium ions\", \"C\": \"Nucleus-independent chemical shift (NICS)\", \"D\": \"Harmonic oscillator model of aromaticity (HOMA)\", \"E\": \"Induced magnetic field in cyclic molecules\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4461 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet:  49%|█████████████████▌                  | 755/1552 [1:19:42<1:00:14,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 416 (char 415)\n",
      "{\"prompt\": \"Which of the following statements is true regarding the notion of 'almost everywhere' in measure theory?\", \"answer\": \"C\", \"A\": \"If property P holds almost everywhere and implies property Q, then property Q holds almost everywhere.\", \"B\": \"If (P_n) is a finite or countable sequence of properties, each of which holds almost everywhere, then their conjunction holds almost everywhere.\", \"C\": \"If (P_x)_{x\\in R} is an uncountable family of properties, each of which holds almost everywhere, then their conjunction does not necessarily hold almost everywhere.\", \"D\": \"If f: R → R is a Lebesgue integrable function and f(x) ≥ 0 almost everywhere, then the integral of f(x) over any interval [a, b] is greater than or equal to zero.\", \"E\": \"If f: R → R is Lebesgue measurable and the integral of |f(x)| over any interval [a, b] is finite, then there exists a set E such that the Lebesgue mean of f converges to f(x) as ε decreases to zero for all x in E.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 416 (char 415)\n",
      "../data/wikipedia_fixed/a.parquet:  51%|███████████████████▎                  | 787/1552 [1:22:26<55:55,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"In 1906, there were several international lawn tennis tournaments held in different locations. Which of the following statements accurately describes one of these tournaments?\", \"answer\": \"C\", \"A\": \"The Marienbader Lawn Tennis-Turnier took place in New Zealand.\", \"B\": \"The Franzensbader Lawn–Tennis Turnier was held in Karlsbad.\", \"C\": \"The Homburg Lawn Tennis tournament occurred in September.\", \"D\": \"The Karlsbad tournament was the second international lawn tennis tournament.\", \"E\": \"The Auckland Star reported on the Marienbader Lawn Tennis-Turnier.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  62%|███████████████████████▋              | 967/1552 [1:41:57<41:21,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 5077 tokens (4077 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is Aziz Sancar's religious affiliation and how does he feel about openly expressing it?\", \"answer\": \"C\", \"A\": \"Aziz Sancar is an atheist and does not believe in any religion.\", \"B\": \"Aziz Sancar is a Christian and actively promotes his faith.\", \"C\": \"Aziz Sancar is a Muslim but feels hesitant to openly express his religious affiliation, especially in the United States.\", \"D\": \"Aziz Sancar is a Buddhist and practices his religion openly.\", \"E\": \"Aziz Sancar is agnostic and is unsure about his religious beliefs.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 5077 tokens (4077 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  73%|██████████████████████████▉          | 1131/1552 [1:57:12<42:22,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4250 tokens (3250 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which group of α-nucleophiles in SN2 reactions with ethyl chloride (C2H5Cl) shows a higher reactivity compared to the Brønsted-type correlation and is classified as nucleophiles showing the α-effect?\", \"answer\": \"A\", \"A\": \"The α-nucleophiles with downward deviation from the Brønsted-type correlation\", \"B\": \"The α-nucleophiles with small or no deviation from the line plotted by six normal nucleophiles\", \"C\": \"The α-nucleophiles with upward deviation from the Brønsted-type correlation\", \"D\": \"The α-nucleophiles with higher basicity but lower reactivity\", \"E\": \"The α-nucleophiles with larger HOMO lobes than the parent normal nucleophile\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4250 tokens (3250 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  73%|███████████████████████████          | 1135/1552 [1:57:38<40:20,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 786 (char 785)\n",
      "{\"prompt\": \"According to scientific evidence and current debate, the concept of the Anthropocene as a geological time unit has been supported by various researchers, including Paul Crutzen and Eugene Stoermer, who introduced the term in 2000, and William Ruddiman, who argued that the Anthropocene began thousands of years ago due to human-induced changes in greenhouse gas concentrations. Simon Lewis and Mark Maslin further discussed the definition of the Anthropocene in their 2015 publication, emphasizing the importance of human impact on the Earth's systems. Zoe Todd and Heather Davis highlighted the significance of establishing a specific date for the Anthropocene, aiming to decolonize the concept and acknowledge Indigenous perspectives. Kyle Keeler explored the notion of \"kleptocene,\" highlighting the colonial theft and Indigenous resistance within the context of the Anthropocene. Additionally, Paul Crutzen, Will Steffen, and John McNeill examined the overwhelming influence of human activities on the Earth's natural processes in their 2007 publication, questioning whether humans have become the dominant force in shaping the planet's future.\", \"answer\": \"C\", \"A\": \"The Anthropocene concept was first introduced by Simon Lewis and Mark Maslin in 2015.\", \"B\": \"William Ruddiman argued that the Anthropocene began due to human-induced changes in greenhouse gas concentrations.\", \"C\": \"Zoe Todd and Heather Davis emphasized the importance of establishing a specific date for the Anthropocene to decolonize the concept and acknowledge Indigenous perspectives.\", \"D\": \"Kyle Keeler explored the notion of \"kleptocene,\" highlighting the colonial theft and Indigenous resistance within the context of the Anthropocene.\", \"E\": \"Paul Crutzen, Will Steffen, and John McNeill questioned whether humans have become the dominant force in shaping the planet's future in their 2007 publication.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 786 (char 785)\n",
      "../data/wikipedia_fixed/a.parquet:  76%|████████████████████████████         | 1178/1552 [2:02:05<27:21,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4190 tokens (3190 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the experimental design for observing the occurrence of autogamy depression?\", \"answer\": \"C\", \"A\": \"An inbreeding depression test\", \"B\": \"A somatic mutation test\", \"C\": \"An autogamy depression test\", \"D\": \"A mitotic division test\", \"E\": \"A meiotic division test\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4190 tokens (3190 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  80%|█████████████████████████████▍       | 1234/1552 [2:06:35<27:21,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 985 (char 984)\n",
      "{\"prompt\": \"Which publication discusses the Y chromosome gene family with RNA-binding protein homology as candidates for the azoospermia factor AZF controlling human spermatogenesis?\", \"answer\": \"B\", \"A\": \"S2CID 4268089\", \"B\": \"Ma, Kun; Inglis, John D.; Sharkey, Andrew; Bickmore, Wendy A.; Hill, Robert E.; Prosser, E. Jane; Speed, Robert M.; Thomson, Eric J.; Jobling, Mark; Taylor, Kay; Wolfe, Jonathan (31 December 1993). \\\"A Y chromosome gene family with RNA-binding protein homology: Candidates for the azoospermia factor AZF controlling human spermatogenesis\\\". Cell. 75 (7): 1287–1295. doi:10.1016/0092-8674(93)90616-X. ISSN 0092-8674. PMID 8269511. S2CID 24678568.\", \"C\": \"Chandley, A. (1 March 1988). \\\"Meiosis in man\\\". Trends in Genetics. 4 (3): 79–84. doi:10.1016/0168-9525(88)90045-5. ISSN 0168-9525. PMID 3076296.\", \"D\": \"'Ann Chester Chandley DSc, F.I. Biol., F.R.S.E. - a tribute and appreciation on the occasion of her retirement' in Chromosome Research 5.1, (1997)\". Wellcome Collection. 23 January 1996. p. Letter to Prof Nick Hastie from M.A.Ferguson. Retrieved 30 July 2021.{{cite web}}: CS1 maint: url-status (link)\", \"E\": \"The Scotsman. 9 March 2020. \\\"Letters\\\". Edinburgh Evening News\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 985 (char 984)\n",
      "../data/wikipedia_fixed/a.parquet:  83%|██████████████████████████████▊      | 1293/1552 [2:12:31<32:33,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4708 tokens (3708 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which publication discusses the discovery of Luolishania, an animal that is considered an intermediate between arthropods and annelids?\", \"answer\": \"C\", \"A\": \"Ramsköld, L.; Xianguang, Hou (1991). \\\"New early Cambrian animal and onychophoran affinities of enigmatic metazoans\\\"\", \"B\": \"Ramsköld, L.; Chen, J–Y (1998). \\\"Cambrian lobopodians, morphology and phylogeny\\\"\", \"C\": \"Hou, Xian-Guang; Chen, Jun-Yuan (1989). \\\"Luolishania gen. nov. : Un animal marin intermédiaire entre arthropode et annélidé du Cambrien inférieur de Chengjiang dans le Yunnan\\\"\", \"D\": \"Caron, Jean‐Bernard; Aria, Cédric (2020). \\\"The Collins' monster, a spinous suspension‐feeding lobopodian from the Cambrian Burgess Shale of British Columbia\\\"\", \"E\": \"Yang, Jie; Ortega-Hernández, Javier; Gerber, Sylvain; Butterfield, Nicholas J.; Hou, Jin-bo; Lan, Tian; Zhang, Xi-guang (2015). \\\"A superarmored lobopodian from the Cambrian of China and early disparity in the evolution of Onychophora\\\"\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4708 tokens (3708 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  84%|███████████████████████████████▏     | 1310/1552 [2:13:55<18:41,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4650 tokens (3650 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the relationship between affinity constant (Ka) and dissociation constant (Kd)?\", \"answer\": \"C\", \"A\": \"Ka and Kd are unrelated to each other.\", \"B\": \"Ka and Kd are equal to each other.\", \"C\": \"Ka is the inverse of Kd.\", \"D\": \"Ka is always greater than Kd.\", \"E\": \"Ka is always smaller than Kd.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4650 tokens (3650 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet:  93%|██████████████████████████████████▎  | 1439/1552 [2:24:49<12:21,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which method measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample?\", \"answer\": \"C\", \"A\": \"Electron energy loss spectroscopy (EELS) measures the energy gain of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\", \"B\": \"Scanning electron microscopy (SEM) measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\", \"C\": \"Electron energy loss spectroscopy (EELS) measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\", \"D\": \"X-ray diffraction measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\", \"E\": \"Atomic force microscopy measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  97%|███████████████████████████████████▉ | 1506/1552 [2:36:03<02:39,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4446 tokens (3446 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"According to the research articles, what is the main factor that controls the global airborne microbial communities?\", \"answer\": \"C\", \"A\": \"Surrounding landscapes\", \"B\": \"Wind conditions\", \"C\": \"Both surrounding landscapes and wind conditions\", \"D\": \"Atmospheric conditions\", \"E\": \"Human activities\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4446 tokens (3446 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/a.parquet: 100%|█████████████████████████████████████| 1552/1552 [2:40:00<00:00,  6.19s/it]\n",
      "../data/wikipedia_fixed/b.parquet:   1%|    | 16/1091 [01:29<1:27:38,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4178 tokens (3178 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which journal published a study on the social networks in guppies?\", \"answer\": \"B\", \"A\": \"Proceedings. Biological Sciences\", \"B\": \"Frontiers in Cell and Developmental Biology\", \"C\": \"International Journal of Molecular Sciences\", \"D\": \"Database\", \"E\": \"Computer Networks and ISDN Systems\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4178 tokens (3178 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:   6%|▏   | 67/1091 [06:12<1:26:26,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 306 (char 305)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the Banks–Zaks fixed point?\", \"answer\": \"C\", \"A\": \"The Banks–Zaks fixed point was first reported in 1974 by Belavin and Migdal.\", \"B\": \"The beta function of a theory up to two loops has the form β ( g ) = − b 0 g 3 + b 1 g 5 + O ( g 7 ) {\\displaystyle \\beta (g)=-b_{0}g^{3}+b_{1}g^{5}+{\\mathcal {O}}(g^{7})\\,} where b 0 {\\displaystyle b_{0}} and b 1 {\\displaystyle b_{1}} are positive constants.\", \"C\": \"If the value of the coupling at that point is less than one (i.e. one can perform perturbation theory in weak coupling), then the fixed point is called a Banks–Zaks fixed point.\", \"D\": \"The Caswell–Banks–Zaks fixed point is a conformal, weakly coupled theory with coupling g ∗ {\\displaystyle g_{\\ast }} when the theory flows to the IR.\", \"E\": \"The Banks–Zaks fixed point only occurs if the number of flavors N f {\\displaystyle N_{f}} satisfies the condition 11 2 N c > N f > 34 N c 3 ( 13 N c 2 − 3 ) {\\displaystyle {\\frac {11}{2}}N_{c}>N_{f}>{\\frac {34N_{c}^{3}}{(13N_{c}^{2}-3)}}}.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 306 (char 305)\n",
      "../data/wikipedia_fixed/b.parquet:  15%|▍  | 168/1091 [15:45<1:30:18,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 175 (char 174)\n",
      "{\"prompt\": \"What is one of the honors and awards that Basilis Xanthopoulos received in recognition of his contributions to science and education?\", \"answer\": \"C\", \"A\": \"The \"Basilis Xanthopoulos - Stefanos Pnevmatikos\" Award for Excellence in Academic Teaching\", \"B\": \"The \"Xanthopoulos Award\" by the Society on General Relativity and Gravitation\", \"C\": \"The \"Basilis Xanthopoulos\" Competition in Physics and Mathematics for high school students in the prefecture of Drama\", \"D\": \"The \"Basilis Xanthopoulos Amphitheater\" at the 1st General Lyceum of Drama\", \"E\": \"The \"Basilis Xanthopoulos Hall\" at the Observatory of the Aristotle University of Thessaloniki\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 175 (char 174)\n",
      "../data/wikipedia_fixed/b.parquet:  20%|▉    | 216/1091 [20:21<50:42,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which simulation approach is recommended for handling many-body collisions of arbitrarily many atoms at very low ion energies?\", \"answer\": \"E\", \"A\": \"MARLOWE\", \"B\": \"BCA simulations\", \"C\": \"MD simulations\", \"D\": \"SRIM\", \"E\": \"Molecular dynamics\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  23%|▋  | 253/1091 [29:31<1:40:10,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4288 tokens (3288 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the research findings mentioned in the provided text?\", \"answer\": \"C\", \"A\": \"The researchers observed the decay B → K l + l − and concluded that it violates the conservation of charge-parity (CP) symmetry.\", \"B\": \"The researchers observed the decay B → K * ℓ + ℓ − and concluded that it violates the conservation of charge-parity (CP) symmetry.\", \"C\": \"The researchers observed large CP violation and provided evidence for direct CP violation in the decay B 0 → π + π −.\", \"D\": \"The researchers observed the decay B → K l + l − and concluded that it violates the conservation of lepton number.\", \"E\": \"The researchers observed the decay B → K * ℓ + ℓ − and concluded that it violates the conservation of lepton number.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4288 tokens (3288 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:  25%|▊  | 273/1091 [31:56<1:38:38,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5799 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"Protein kinase C (PKC) inhibitors staurosporine and bisindolylmaleimide I (GF109203X) have similar effects on bone resorption.\", \"B\": \"Rab2 interacts directly with atypical protein kinase C (aPKC) iota/lambda and inhibits aPKCiota/lambda-dependent glyceraldehyde-3-phosphate dehydrogenase phosphorylation.\", \"C\": \"Combining protein-based IMAC, peptide-based IMAC, and MudPIT is an efficient method for phosphoproteomic analysis.\", \"D\": \"Indolocarbazole natural products have no biological activity.\", \"E\": \"The structure of wild-type Plk-1 kinase domain has not been determined.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5799 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/b.parquet:  27%|▊  | 291/1091 [33:49<1:16:31,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What caused a controversy within the Behavior Genetics Association and resulted in several resignations from the association's executive committee?\", \"answer\": \"A\", \"A\": \"Glayde Whitney's presidential address at the 1995 annual meeting in Richmond, Virginia, claiming genetic roots of the relationship between race and crime\", \"B\": \"The association's declaration that the presidential address does not represent official policy of the association\", \"C\": \"The encouragement for members to express their personal political and moral views in presentations given at the meeting\", \"D\": \"The yearly awards given for accomplishments in the field of behavioral genetics\", \"E\": \"The Dobzhansky Award for lifetime accomplishments chosen by the three most recent past presidents\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  32%|█▌   | 350/1091 [45:07<57:42,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 251 (char 250)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the relationship between TCB and other relativistic time scales?\", \"answer\": \"C\", \"A\": \"TCB and TCG have a transformation that can be approximated with an uncertainty of 5 × 10 − 18 {\\displaystyle 5\\times 10^{-18}} in rate.\", \"B\": \"The transformation between TCB and TCG is defined with fully general relativistic metrics.\", \"C\": \"TCB ticks faster than clocks on the surface of the Earth by 1.550505 × 10−8 (about 490 milliseconds per year).\", \"D\": \"The values of physical constants used with TCB differ from the traditional values used with other time scales.\", \"E\": \"Many calculations still use TDB instead of TCB as of 2002.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 251 (char 250)\n",
      "../data/wikipedia_fixed/b.parquet:  33%|▉  | 361/1091 [46:34<1:44:00,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "{\"prompt\": \"Which publication provides information on the measurement of ionization quenching in plastic scintillators?\", \"answer\": \"C\", \"A\": \"The Theory and Practice of Scintillation Counting by J.B. Birks\", \"B\": \"A Tribute to Professor John B Birks - LSC International Home\", \"C\": \"Measurement of ionization quenching in plastic scintillators by T. Pöschl\", \"D\": \"A 1 mm Scintillating Fibre Tracker Readout by a Multi-anode Photomultiplier by B.L. Leverington, Anelli, Campana, Rosellini\", \"E\": \"Plastic scintillator investigations for relative dosimetry in proton-therapy by L. Torrisi\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia_fixed/b.parquet:  34%|█  | 368/1091 [47:19<1:13:02,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4555 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which equation is analogous to the de Broglie wave type of approximation First order semi-classical equation of motion for electron in a band?\", \"answer\": \"C\", \"A\": \"d2y/dt2 + f(t)y = 0\", \"B\": \"ℏk˙ = −e(E + v × B)\", \"C\": \"d2y/dt2 + f(t)y = 0\", \"D\": \"d2y/dt2 + f(t)y = 0\", \"E\": \"d2y/dt2 + f(t)y = 0\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4555 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/b.parquet:  38%|█▏ | 420/1091 [53:02<1:20:21,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 5032 tokens (4032 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the distribution of stars around a massive black hole?\", \"answer\": \"D\", \"A\": \"The distribution of stars around a massive black hole is random and uniform.\", \"B\": \"The distribution of stars around a massive black hole is determined solely by the mass of the black hole.\", \"C\": \"The distribution of stars around a massive black hole is influenced by the presence of other nearby black holes.\", \"D\": \"The distribution of stars around a massive black hole exhibits strong mass segregation.\", \"E\": \"The distribution of stars around a massive black hole is evenly spread across all distances from the black hole.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 5032 tokens (4032 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:  44%|█▎ | 476/1091 [59:44<1:30:54,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which publication discusses the bioleaching of ultramafic tailings by Acidithiobacillus spp. for CO2 sequestration?\", \"answer\": \"A\", \"A\": \"Southam, Gordon (2010). \\\"Bioleaching of Ultramafic Tailings by Acidithiobacillusspp. For CO2Sequestration\\\". Environmental Science & Technology. 44 (1): 456–462.\", \"B\": \"Natarajan, K.A. (2018). \\\"Experimental and Research Methods in Metals Biotechnology\\\". Biotechnology of Metals. pp. 433–468.\", \"C\": \"\\\"Use in Mining | International Cyanide Management Code (ICMI) For The Manufacture, Transport and Use of Cyanide In The Production of Gold(ICMI)\\\". www.cyanidecode.org.\", \"D\": \"Dusengemungu, Leonce; Kasali, George; Gwanama, Cousins; Mubemba, Benjamin (27 June 2021). \\\"Overview of fungal bioleaching of metals\\\". Environmental Advances. Elsevier Ltd. 5 (2021): 100083.\", \"E\": \"\\\"Enterprise Europe Network\\\". een.ec.europa.eu.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  48%|▍| 522/1091 [1:11:04<1:08:34,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which publication discusses the Permian Bone Spring Formation and its sandstone play in the Delaware Basin?\", \"answer\": \"D\", \"A\": \"The late Paleozoic Ancestral Rocky Mountain system in New Mexico\", \"B\": \"Permian Stratigraphy and Facies, Permian Basin (Texas—New Mexico) and Adjoining Areas in the Midcontinent United States\", \"C\": \"The Avalon Shale: Tying Geologic Variability to Productivity in a Burgeoning Shale Play in the Delaware Basin of Southeast New Mexico\", \"D\": \"Permian Bone Spring Formation: Sandstone Play in the Delaware Basin, Part II-Basin\", \"E\": \"Review of the First Bone Spring Hybrid Play in the Delaware Basin, West Texas and Southeast New Mexico\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  53%|█▌ | 579/1091 [1:23:52<53:40,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Based on the provided text, which season of the Bundesliga had the highest spectator figures?\", \"answer\": \"C\", \"A\": \"Bundesliga 1987/1988\", \"B\": \"Bundesliga 1992/1993\", \"C\": \"Bundesliga 2003/2004\", \"D\": \"Bundesliga 2010/2011\", \"E\": \"Bundesliga 2015/2016\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  63%|█▉ | 688/1091 [1:42:03<51:07,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"According to the provided text, which book provides a diagrammatic history of the London Underground?\", \"answer\": \"C\", \"A\": \"The Directory of Railway Stations\", \"B\": \"The London Brighton and South Coast Railway 2: Establishment and Growth\", \"C\": \"The London Underground, A Diagrammatic History\", \"D\": \"Underground Overground\", \"E\": \"Underground Journeys: Charles Holden's designs for London Transport\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  64%|▋| 703/1091 [1:48:51<1:02:04,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 189 (char 188)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the research mentioned in the provided text?\", \"answer\": \"D\", \"A\": \"The research focuses on the superglass phase of $^{4}\\mathrm{He}$.\", \"B\": \"The research explores the polynomial complexity of strongly correlated fermions.\", \"C\": \"The research compares Feynman diagrams with the Fermi-gas Feynman emulator.\", \"D\": \"The research simulates strongly correlated fermions.\", \"E\": \"The research investigates the behavior of $^{4}\\mathrm{He}$ in a superglass phase.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 189 (char 188)\n",
      "../data/wikipedia_fixed/b.parquet:  69%|▋| 749/1091 [1:54:40<1:25:23, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (3166 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which journal article investigates the failure thresholds of high burnup BWR fuel rods under RIA conditions?\", \"answer\": \"A\", \"A\": \"T. Nakamura; T. Fuketa; T. Sugiyama; H. Sasajima (2004). \\\"Failure Thresholds of High Burnup BWR Fuel Rods under RIA Conditions\\\". Journal of Nuclear Science and Technology. 41 (1): 37. doi:10.3327/jnst.41.37.\", \"B\": \"F. Nagase & T. Fuketa (2005). \\\"Investigation of Hydride Rim Effect on Failure of Zircaloy-4 Cladding with Tube Burst Test\\\". Journal of Nuclear Science and Technology. 42: 58–65. doi:10.3327/jnst.42.58.\", \"C\": \"Simplified analysis of nuclear fuel pin swelling. (PDF) . Retrieved on 2011-03-17.\", \"D\": \"J.Y. Colle; J.P. Hiernaut; D. Papaioannou; C. Ronchi; A. Sasahara (2006). \\\"Fission product release in high-burn-up UO2 oxidized to U3O8\\\". Journal of Nuclear Materials. 348 (3): 229. Bibcode:2006JNuM..348..229C. doi:10.1016/j.jnucmat.2005.09.024.\", \"E\": \"P. Wood and G.H. Bannister, CEGB report Archived 2006-06-13 at the Wayback Machine V. Bessiron (2007). \\\"Modelling of Clad-to-Coolant Heat Transfer for RIA Applications\\\". Journal of Nuclear Science and Technology. 44 (2): 211–221. doi:10.3327/jnst.44.211.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4166 tokens (3166 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:  75%|██▏| 818/1091 [2:02:33<26:26,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "{\"prompt\": \"What is the purpose of BALLView?\", \"answer\": \"C\", \"A\": \"To develop molecular visualization functions\", \"B\": \"To create Python classes for C++ classes in the BALL library\", \"C\": \"To serve as a standalone molecule modeling and visualization application\", \"D\": \"To support force fields for scoring and energy minimization\", \"E\": \"To generate molecules from and match SMILES- and SMARTS expressions to molecules\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia_fixed/b.parquet:  81%|██▍| 887/1091 [2:10:46<21:56,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which method is commonly used for scanning electron microscopy of biological specimens?\", \"answer\": \"C\", \"A\": \"Microwave-assisted ring closure reactions\", \"B\": \"Gas chromatographic–mass spectrometric analysis of products arising from pyrolysis of amino acids in the presence of hexamethyldisilazane\", \"C\": \"Comparison of hexamethyldisilazane (HMDS), Peldri II, and critical-point drying methods\", \"D\": \"Synthesis of 8-substituted xanthine derivatives and related pyrimido- and diazepinopurinediones\", \"E\": \"Mechanical and optical properties of hard SiCN coatings prepared by PECVD\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/b.parquet:  82%|██▍| 895/1091 [2:17:05<47:29, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4144 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Who established the Béla Szőkefalvi-Nagy Medal to recognize distinguished mathematicians who have published significant work in Acta Scientiarum Mathematicarum?\", \"answer\": \"E\", \"A\": \"Frederic Riesz\", \"B\": \"Ciprian Foiaş\", \"C\": \"Béla Szőkefalvi-Nagy\", \"D\": \"Erzsébet Szőkefalvi-Nagy\", \"E\": \"Erzsébet Szőkefalvi-Nagy\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4144 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/b.parquet:  86%|██▌| 937/1091 [2:21:59<17:13,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4149 tokens (3149 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Who was Beatrice Hill Tinsley?\", \"answer\": \"B\", \"A\": \"Beatrice Hill Tinsley was a professor of astronomy at the University of Texas at Austin.\", \"B\": \"Beatrice Hill Tinsley was an astronomer and a pioneer in the field of cosmology.\", \"C\": \"Beatrice Hill Tinsley was a historian and mountain climber.\", \"D\": \"Beatrice Hill Tinsley was a recipient of the Hill Tinsley Medal from the New Zealand Association of Scientists.\", \"E\": \"Beatrice Hill Tinsley was a member of the Royal Society Te Apārangi.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4149 tokens (3149 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:  97%|█▉| 1058/1091 [2:35:01<03:33,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4202 tokens (3202 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which journal article discusses the psychosomatic aspects of Cushing's disease?\", \"answer\": \"B\", \"A\": \"Emotional aspects of hyperprolactinemia\", \"B\": \"Psychosomatic aspects of Cushing's disease\", \"C\": \"Depression and anxiety in different thyroid function states\", \"D\": \"Androgen actions on central serotonin neurotransmission: relevance for mood, mental state and memory\", \"E\": \"Monoaminergic Neurotransmission: The History of the Discovery of Antidepressants from 1950s Until Today\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4202 tokens (3202 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet:  99%|█▉| 1077/1091 [2:37:14<01:31,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4408 tokens (3408 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the scope of environmental studies?\", \"answer\": \"C\", \"A\": \"The study of human-induced effects on the environment\", \"B\": \"The investigation of the effect of human activity on the environment\", \"C\": \"The systematic study of the interaction of humans with their environment\", \"D\": \"The study of the interactions within the biophysical environment\", \"E\": \"The study of biological phenomena using systems from physics\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4408 tokens (3408 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/b.parquet: 100%|██| 1091/1091 [2:38:46<00:00,  8.73s/it]\n",
      "../data/wikipedia_fixed/c.parquet:   1%|    | 24/1840 [03:13<4:31:11,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the publication history of the author in the provided text?\", \"answer\": \"C\", \"A\": \"The author published a paper titled 'Functorial Semantics of Algebraic Theories' in November 1963.\", \"B\": \"The author published a paper titled 'Elementary Theory of the Category of Sets' in December 1964.\", \"C\": \"The author published a paper titled 'Quantifiers and Sheaves' in a conference held in September 1970.\", \"D\": \"The author published a book titled 'First order categorical logic' in 1977.\", \"E\": \"The author published a book titled 'Lecture Notes in Mathematics' in 1988.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia_fixed/c.parquet:   3%|    | 49/1840 [06:15<5:03:22, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4942 tokens (3942 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is condosity and how is it measured?\", \"answer\": \"C\", \"A\": \"Condosity is the molar concentration of a sodium chloride (NaCl) solution that has the same specific electrical conductance as the solution under test. It is measured by comparing the conductance of the solution under test to that of a known concentration of NaCl solution.\", \"B\": \"Condosity is the specific electrical conductance of a solution, and it is measured by comparing the molar concentration of the solution under test to that of a known concentration of NaCl solution.\", \"C\": \"Condosity is the molar concentration of a sodium chloride (NaCl) solution that has the same specific electrical conductance as the solution under test. It is measured by comparing the conductance of the solution under test to that of a known concentration of NaCl solution.\", \"D\": \"Condosity is the specific electrical conductance of a solution, and it is measured by comparing the molar concentration of the solution under test to that of a known concentration of KCl solution.\", \"E\": \"Condosity is the molar concentration of a potassium chloride (KCl) solution that has the same specific electrical conductance as the solution under test. It is measured by comparing the conductance of the solution under test to that of a known concentration of KCl solution.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4942 tokens (3942 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:   7%|▏  | 122/1840 [16:05<4:05:36,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4245 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text? Poly(ADP-ribose) polymerase turnover alterations contribute to PARP overexpression in Ewing's sarcoma cells. Overexpression and hypomethylation of flap endonuclease 1 gene is observed in breast and other cancers. Flap endonuclease 1 is overexpressed in prostate cancer and is associated with a high Gleason score. Gastric cancer-related genes have been identified using a cDNA microarray containing novel expressed sequence tags expressed in gastric cancer cells. Flap endonuclease 1 is a promising candidate biomarker in gastric cancer and is involved in cell proliferation and apoptosis. \", \"answer\": \"C\", \"A\": \"Poly(ADP-ribose) polymerase turnover alterations contribute to PARP overexpression in Ewing's sarcoma cells.\", \"B\": \"Overexpression and hypomethylation of flap endonuclease 1 gene is observed in breast and other cancers.\", \"C\": \"Flap endonuclease 1 is overexpressed in prostate cancer and is associated with a high Gleason score.\", \"D\": \"Gastric cancer-related genes have been identified using a cDNA microarray containing novel expressed sequence tags expressed in gastric cancer cells.\", \"E\": \"Flap endonuclease 1 is a promising candidate biomarker in gastric cancer and is involved in cell proliferation and apoptosis.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4245 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:   7%|▏  | 137/1840 [17:49<3:33:38,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5004 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What is the descriptor term for crater chains and who specified it?\", \"answer\": \"B\", \"A\": \"Crater chains are formed by the impact of a body that was broken up by tidal forces into a string of smaller objects following roughly the same orbit.\", \"B\": \"The descriptor term for crater chains is catena, as specified by the International Astronomical Union's rules on planetary nomenclature.\", \"C\": \"Crater chains on Callisto and Ganymede were confirmed to be primary chains as of 1996.\", \"D\": \"Crater chains on Mars represent chains of collapse pits associated with grabens.\", \"E\": \"Crater chains on the Moon often radiate from larger craters, caused by secondary impacts or volcanic venting activity along a rift.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5004 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:   9%|▎  | 174/1840 [22:06<2:34:12,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4591 tokens (3591 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Who were the recipients of the Nobel Prize in Chemistry in 2020?\", \"answer\": \"B\", \"A\": \"Emmanuelle Charpentier and Jennifer A. Doudna developed the Crispr tool\", \"B\": \"Emmanuelle Charpentier and Jennifer A. Doudna\", \"C\": \"The New York Times\", \"D\": \"The Nobel Foundation\", \"E\": \"Wu KJ and Peltier E\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4591 tokens (3591 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  11%|▎  | 196/1840 [24:51<3:40:23,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4913 tokens (3913 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"According to the provided text, which article discusses the age and deformation of the Longtown Metagranite in the South Carolina Piedmont?\", \"answer\": \"C\", \"A\": \"Nance, R.D.; et al. (2010). \\\"Evolution of the Rheic Ocean\\\"\", \"B\": \"Butler, J.R. (1991). \\\"Metamorphism\\\"\", \"C\": \"Barker, C.A.; et al. (1998). \\\"Age and deformation of the Longtown Metagranite, South Carolina Piedmont: A possible constraint on the origin of the Carolina terrane\\\"\", \"D\": \"Hibbard, J (2002). \\\"The Carolina Zone: overview of Neoproterozoic to Early Paleozoic peri-Gondwanan terranes along the eastern Flank of the southern Appalachians\\\"\", \"E\": \"CiteSeerX 10.1.1.570.1894\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4913 tokens (3913 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  12%|▎  | 213/1840 [27:01<4:10:17,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4529 tokens (3529 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements is true about oligosaccharide synthesis?\", \"answer\": \"C\", \"A\": \"Oligosaccharide synthesis consists of three parts: preparation of the glycosyl donors, preparation of the glycosyl acceptors, and the coupling of them.\", \"B\": \"Glycosyl halides are the most commonly used donors in oligosaccharide synthesis.\", \"C\": \"Thioglycoside and trichloroacetimidate donors are used more frequently than other donors in contemporary glycosylation methods.\", \"D\": \"The structures of acceptors have no effect on the rate and stereoselectivity of glycosylations.\", \"E\": \"1, 2-trans glycosidic linkages can be easily achieved by using 2-O-acylated glycosyl donors.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4529 tokens (3529 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  15%|▍  | 277/1840 [34:39<4:36:10, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4650 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What is Community Supported Agriculture (CSA) and why is it considered a sustainable alternative to industrial agriculture?\", \"answer\": \"C\", \"A\": \"Community Supported Agriculture (CSA) is a farming model where consumers purchase shares of a farm's harvest in advance and receive a portion of the produce throughout the growing season, which helps to create a direct connection between farmers and consumers.\", \"B\": \"Community Supported Agriculture (CSA) is a farming model where consumers purchase shares of a farm's harvest in advance and receive a portion of the produce throughout the growing season, which helps to create a direct connection between farmers and consumers. It is considered a sustainable alternative to industrial agriculture because it promotes local food production, reduces the reliance on fossil fuels for transportation, and supports small-scale farmers.\", \"C\": \"Community Supported Agriculture (CSA) is a farming model where consumers purchase shares of a farm's harvest in advance and receive a portion of the produce throughout the growing season, which helps to create a direct connection between farmers and consumers. It is considered a sustainable alternative to industrial agriculture because it promotes local food production, reduces the reliance on fossil fuels for transportation, supports small-scale farmers, and encourages ecological farming practices.\", \"D\": \"Community Supported Agriculture (CSA) is a farming model where consumers purchase shares of a farm's harvest in advance and receive a portion of the produce throughout the growing season, which helps to create a direct connection between farmers and consumers. It is considered a sustainable alternative to industrial agriculture because it promotes local food production, reduces the reliance on fossil fuels for transportation, supports small-scale farmers, encourages ecological farming practices, and fosters community resilience.\", \"E\": \"Community Supported Agriculture (CSA) is a farming model where consumers purchase shares of a farm's harvest in advance and receive a portion of the produce throughout the growing season, which helps to create a direct connection between farmers and consumers. It is considered a sustainable alternative to industrial agriculture because it promotes local food production, reduces the reliance on fossil fuels for transportation, supports small-scale farmers, encourages ecological farming practices, fosters community resilience, and enhances food security.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4650 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  17%|▌  | 318/1840 [39:26<2:25:36,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 8851 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Based on the analysis of Cheddar Man's nuclear DNA, it can be concluded that he most likely had which of the following physical characteristics?\", \"answer\": \"C\", \"A\": \"Blonde hair and blue eyes\", \"B\": \"Green eyes and light brown hair\", \"C\": \"Blue-green eyes, dark brown or black hair, and dark or dark-to-black skin\", \"D\": \"Brown eyes, blonde hair, and light skin\", \"E\": \"Hazel eyes, red hair, and medium skin\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 8851 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  18%|▌  | 324/1840 [40:08<2:53:13,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 161 (char 160)\n",
      "{\"prompt\": \"Which of the following statements accurately describes Cousin's lemma?\", \"answer\": \"Cousin's lemma states that for every gauge δ : [ a , b ] → R + {\\displaystyle \\delta :[a,b]\\to \\mathbb {R} ^{+}} , there exists a δ {\\displaystyle \\delta } -fine partition of [ a , b ] {\\displaystyle [a,b]} .\", \"A\": \"Cousin's lemma states that for every x ∈ [a, b], there exists a δ>0 so that C {\\displaystyle {\\mathcal {C}}} contains all subintervals of [a, b] which contains x and length smaller than δ.\", \"B\": \"Cousin's lemma states that every gauge δ : [ a , b ] → R + {\\displaystyle \\delta :[a,b]\\to \\mathbb {R} ^{+}} has a δ {\\displaystyle \\delta } -fine partition.\", \"C\": \"Cousin's lemma states that every tagged partition P {\\displaystyle P} of [ a , b ] {\\displaystyle [a,b]} is δ {\\displaystyle \\delta } -fine if for all 1 ≤ j ≤ ℓ {\\displaystyle 1\\leq j\\leq \\ell } , we have ( x j − 1 , x j ) ⊆ B ( t j , δ ( t j ) ) {\\displaystyle (x_{j-1},x_{j})\\subseteq B{\\big (}t_{j},\\delta (t_{j}){\\big )}}.\", \"D\": \"Cousin's lemma states that every full cover of [a, b] contains a partition {I1, I2, …, In} of non-overlapping intervals for [a, b], where I i = [ x i − 1 , x i ] ∈ C {\\displaystyle I_{i}=[x_{i-1},x_{i}]\\in {\\mathcal {C}}} and a=x0 < x1 < ⋯ < xn=b for all 1≤i≤n.\", \"E\": \"Cousin's lemma states that any inductive subset S {\\displaystyle S} of [ a , b ] {\\displaystyle [a,b]} must be the entire set.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 161 (char 160)\n",
      "../data/wikipedia_fixed/c.parquet:  19%|▌  | 355/1840 [43:48<1:54:27,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4946 tokens (3946 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which scientific journal published the article titled 'Molecular Mechanisms of Plant Regeneration'?\", \"answer\": \"C\", \"A\": \"Development\", \"B\": \"Proceedings of the National Academy of Sciences of the United States of America\", \"C\": \"Annual Review of Plant Biology\", \"D\": \"Nature\", \"E\": \"Autoimmunity Reviews\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4946 tokens (3946 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  24%|▋  | 446/1840 [54:23<2:42:36,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4373 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which scientific journal published a study on the role of carrion-frequenting arthropods in the decay process?\", \"answer\": \"C\", \"A\": \"Forensic Science International\", \"B\": \"Ecological Entomology\", \"C\": \"Forensic Science International\", \"D\": \"Journal of Medical Entomology\", \"E\": \"Forensic Science International\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4373 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  25%|▊  | 467/1840 [57:12<3:14:41,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "{\"prompt\": \"Which of the following statements accurately describes cocrystals?\", \"answer\": \"Cocrystals consist of two or more components that form a unique crystalline structure having unique properties.\", \"A\": \"Cocrystals are composed of atoms, ions, or molecules and must be solid in their pure forms at ambient conditions.\", \"B\": \"Cocrystals are structures that may or may not include solvates and clathrates.\", \"C\": \"Cocrystals are crystalline salts that have completed the transfer of a proton.\", \"D\": \"Cocrystals are formed through non-covalent interactions such as hydrogen bonding, ionic interactions, van der Waals interactions, and Π-interactions.\", \"E\": \"Cocrystals have the same physical and chemical properties as the individual components.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia_fixed/c.parquet:  26%|▊  | 470/1840 [57:32<2:35:26,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 15569 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Who set out to create a more ambitious version of Haros' table by tabulating the decimal values for all irreducible fractions with denominators less than or equal to 1,024?\", \"answer\": \"B\", \"A\": \"Charles Haros\", \"B\": \"Henry Goodwyn\", \"C\": \"John Farey\", \"D\": \"Augustin Cauchy\", \"E\": \"Gaspard De Prony\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 15569 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  26%|▊  | 479/1840 [58:47<3:54:08, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 7076 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"According to the provided text, which source should be consulted for information on the Blackdown Nappe and the Crackington Formation in the Dartmoor area?\", \"answer\": \"C\", \"A\": \"Hesketh, Robert (2006). Devon's Geology, an introduction. Bosiney Books. pp. 10–12. ISBN 978-1-899383894.\", \"B\": \"Page, K.N. (2006). \\\"Information Sheet 1D: Blackdown Nappe: Late Lower to Upper Carboniferous, Bealsmill Formation ('allochthon')\\\" (PDF). Meldon Geology & Geomorphology Case Study. Dartmoor National Park Authority. Retrieved 17 January 2011.\", \"C\": \"Page, K.N. (2006). \\\"Information Sheet 1B: Late Lower to Upper Carboniferous: Crackington Formation (Culm Basin 'autochthon' / 'parautochthon')\\\" (PDF). Meldon Geology & Geomorphology Case Study. Dartmoor National Park Authority.\", \"D\": \"Dangerfield, J.; Hawkes J.R. (1969). \\\"Unroofing of the Dartmoor granite and possible consequences with regard to mineralization\\\" (PDF). Proceedings of the Ussher Society. 2 (2): 122–131.\", \"E\": \"Chen, Y.; Clark A.H.; Farrar E.; Wasteneys H.A.H.P.; Hodgson M.J.; Bromley A.V. (1993). \\\"Diachronous and independent histories of plutonism and mineralization in the Cornubian Batholith, southwest England\\\". Journal of the Geological Society. 150 (6): 1183–1191. doi:10.1144/gsjgs.150.6.1183. Chesley, J.T.; Halliday A.N.; Snee L.W.; Mezger K\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 7076 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  34%|▎| 629/1840 [1:15:55<2:23:53,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which publication provides information on the characteristics, depositional environment, and tectonic interpretations of the Proterozoic Cardenas Lavas in the eastern Grand Canyon, Arizona?\", \"answer\": \"C\", \"A\": \"Grand Canyon Geology, 2nd ed.\", \"B\": \"Age and correlation of the late Proterozoic Grand Canyon disturbance, northern Arizona.\", \"C\": \"Geology.\", \"D\": \"Vishnu Basement Rocks of the Upper Granite Gorge: Continent formation 1.84 to 1.66 billion years ago.\", \"E\": \"Tectonic inferences from the ca. 1254–1100 Ma Unkar Group and Nankoweap Formation, Grand Canyon: Intracratonic deformation and basin formation during protracted Grenville orogenesis.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  34%|▎| 630/1840 [1:21:16<34:02:55, 101.30s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which publication provides information on the characteristics, depositional environment, and tectonic interpretations of the Proterozoic Cardenas Lavas in the eastern Grand Canyon, Arizona?\", \"answer\": \"C\", \"A\": \"Grand Canyon Geology, 2nd ed.\", \"B\": \"Age and correlation of the late Proterozoic Grand Canyon disturbance, northern Arizona.\", \"C\": \"Geology.\", \"D\": \"Vishnu Basement Rocks of the Upper Granite Gorge: Continent formation 1.84 to 1.66 billion years ago.\", \"E\": \"Tectonic inferences from the ca. 1254–1100 Ma Unkar Group and Nankoweap Formation, Grand Canyon: Intracratonic deformation and basin formation during protracted Grenville orogenesis.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  35%|▎| 638/1840 [1:27:24<6:06:20, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4689 tokens (3689 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of the CellCognition framework?\", \"answer\": \"C\", \"A\": \"To analyze high-throughput fluorescence microscopy images\", \"B\": \"To develop machine learning algorithms for single-cell tracking\", \"C\": \"To quantitatively analyze cell morphologies and generate phenotype maps\", \"D\": \"To correct classification errors on class labels\", \"E\": \"To develop software for basic cell cycle study\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4689 tokens (3689 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  37%|▎| 674/1840 [1:31:05<2:03:22,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5065 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the findings of the research articles cited in the provided text?\", \"answer\": \"C\", \"A\": \"The research articles discuss the role of succinate in inhibiting HIF-alpha prolyl hydroxylase, linking TCA cycle dysfunction to oncogenesis.\", \"B\": \"The research articles investigate the common feature of leukemia-associated IDH1 and IDH2 mutations, which is the conversion of alpha-ketoglutarate to 2-hydroxyglutarate.\", \"C\": \"The research articles demonstrate that IDH mutations impair histone demethylation, leading to a block in cell differentiation.\", \"D\": \"The research articles focus on the hypermethylation phenotype resulting from leukemic IDH1 and IDH2 mutations, which disrupt TET2 function and impair hematopoietic differentiation.\", \"E\": \"The research articles highlight the role of succinate in disrupting TET2 function and impairing hematopoietic differentiation.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5065 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  40%|▍| 731/1840 [1:36:52<1:49:17,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the purpose of the woodhenge at Cahokia?\", \"answer\": \"C\", \"A\": \"To mark the equinox and solstice sunrises and sunsets for the timing of the agricultural cycle and religious observances.\", \"B\": \"To observe other celestial events, such as lunar cycles, the motion of the Pleiades, or other stars and planets.\", \"C\": \"Both A and B.\", \"D\": \"To align mound and causeway construction projects.\", \"E\": \"To symbolize the rays of the sun.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  40%|▍| 734/1840 [1:42:25<15:56:33, 51.89s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server is overloaded or not ready yet.\n",
      "{\"prompt\": \"When did the International Commission on Atomic Weights decide to use the oxygen scale as the international standard?\", \"answer\": \"C\", \"A\": \"1803\", \"B\": \"1899\", \"C\": \"End of the 19th century\", \"D\": \"1920\", \"E\": \"1957\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 745, in _interpret_response_line\n",
      "    raise error.ServiceUnavailableError(\n",
      "openai.error.ServiceUnavailableError: The server is overloaded or not ready yet.\n",
      "../data/wikipedia_fixed/c.parquet:  40%|▍| 741/1840 [1:43:30<3:30:10, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4352 tokens (3352 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the conclusion drawn from the experiment conducted by Steinbüchel and Wiefel in 2014 regarding the solubility of cyanophycin?\", \"answer\": \"C\", \"A\": \"Insoluble and soluble CGP are distinct polymers originating from different polymer mixtures.\", \"B\": \"Higher levels of lysine positively correlate to the temperature needed to make the polymer soluble with aqueous solvents.\", \"C\": \"Insoluble and soluble CGP are not distinct polymers, but rather mixes of cyanophycin mixtures with varying concentrations of lysine residues.\", \"D\": \"The introduction of a citrulline-producing strain can only result in the production of citrulline-rich cyanophycin.\", \"E\": \"Insoluble CGP exhibits higher concentrations of citrulline compared to soluble CGP.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4352 tokens (3352 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  42%|▍| 777/1840 [1:47:47<2:12:42,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the purpose of using a clocked (or dynamic) comparator structure, also known as a latched comparator, in certain applications?\", \"answer\": \"C\", \"A\": \"To output either a '1' or a '0' any time a high or low signal is applied to its input\", \"B\": \"To achieve higher accuracy and lower power consumption compared to a continuous comparator\", \"C\": \"To strobe the comparator at certain intervals and employ strong positive feedback during a 'regeneration phase'\", \"D\": \"To only employ weak positive feedback and have a 'reset phase' during a clock cycle\", \"E\": \"To identify when a given value is zero and perform null detection comparison measurements\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  44%|▍| 815/1840 [1:57:37<1:51:42,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra data: line 1 column 202 (char 201)\n",
      "{\"prompt\": \"Which mechanism can reverse DNA methylation?\", \"answer\": \"C\", \"A\": \"DNA de-methylases\", \"B\": \"Histone modifications\", \"C\": \"DNA de-methylases\", \"D\": \"Histone acetyl groups\", \"E\": \"Enzymes\"},\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 340, in decode\n",
      "    raise JSONDecodeError(\"Extra data\", s, end)\n",
      "json.decoder.JSONDecodeError: Extra data: line 1 column 202 (char 201)\n",
      "../data/wikipedia_fixed/c.parquet:  45%|▍| 827/1840 [1:59:04<1:53:58,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4128 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What is Charles John Read best known for in the field of operator theory?\", \"answer\": \"B\", \"A\": \"His work on Banach algebras and hypercyclicity\", \"B\": \"His work on the invariant subspace problem\", \"C\": \"His construction of the first example of an amenable, commutative, radical Banach algebra\", \"D\": \"His research on the geometry of Banach spaces\", \"E\": \"His contributions to functional analysis\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4128 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  45%|▍| 833/1840 [1:59:58<3:01:47, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 6489 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which publication discusses the origin of high-frequency hearing in whales?\", \"answer\": \"B\", \"A\": \"Nature. 508 (7496): 383–386. Bibcode:2014Natur.508..383G. doi:10.1038/nature13086. ISSN 1476-4687. PMID 24670659. S2CID 4457391.\", \"B\": \"Churchill, Morgan; Martinez-Caceres, Manuel; de Muizon, Christian; Mnieckowski, Jessica; Geisler, Jonathan H. (2016-08-22). \\\"The Origin of High-Frequency Hearing in Whales\\\". Current Biology. 26 (16): 2144–2149. doi:10.1016/j.cub.2016.06.004. ISSN 0960-9822. PMID 27498568. S2CID 3944589.\", \"C\": \"Sanders, A. E.; Barnes, L. G. (2002-09-14). \\\"Paleontology of the late Oligocene Ashley and Chandler Bridge Formations of South Carolina, 3 Eomysticetidae, a new family of primitive mysticetes\\\". Smithsonian Contributions to. Paleobiology. (93): 313–356.\", \"D\": \"\\\"Late Oligocene sharks and rays from the Chandler Bridge Formation, Dorchester County, South Carolina, USA - Acta Palaeontologica Polonica\\\". www.app.pan.pl. Retrieved 2022-09-06.\", \"E\": \"Domning, Daryl P. (1997-06-19). \\\"Fossil Sirenia of the west Atlantic and Caribbean region. VI. Crenatosiren olseni (Reinhart, 1976)\\\". Journal of Vertebrate Paleontology. 17 (2): 397–412. Bibcode:1997JVPal..17..397D. doi:10.1080/02724634.1997.10010984. ISSN 0272-4634. VÉLEZ-JUARBE, JORGE; DOMNING, DARYL P. (2014). \\\"Fossil Sirenia of the West Atlantic and Caribbean Region\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 6489 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  50%|▍| 913/1840 [2:09:07<1:31:23,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4750 tokens (3750 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the main goal of the Carl Sagan Institute: Pale Blue Dot and Beyond?\", \"answer\": \"C\", \"A\": \"To catalog the spectral emissions and albedo of Solar System objects\", \"B\": \"To search for signs of life on exoplanets using a color catalog of microorganism species\", \"C\": \"To model atmospheric spectral signatures including biosignatures of known and hypothetical planets and moons\", \"D\": \"To explore the origin of life on Earth through interdisciplinary research\", \"E\": \"To detect the first habitable exoplanet by characterizing exoplanets and their host stars\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4750 tokens (3750 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  55%|▌| 1009/1840 [2:20:25<1:38:18,  7.10s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra data: line 1 column 522 (char 521)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the role of Sar1 in COPII vesicle budding?\", \"answer\": \"C\", \"A\": \"Sar1 is myristoylated or prenylated to insert into membranes\", \"B\": \"Sar1 forms a cuboctahedron with a broader lattice than Clathrin vesicles\", \"C\": \"Sar1-GTP recruits the Sec13/31 complex to detach the COPII vesicle from the ER membrane\", \"D\": \"Sar1 is regulated by Sec16A and Tango1 proteins to activate Sec12\", \"E\": \"Sar1B is required for the formation of large COPII-coated vesicles\"},\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 340, in decode\n",
      "    raise JSONDecodeError(\"Extra data\", s, end)\n",
      "json.decoder.JSONDecodeError: Extra data: line 1 column 522 (char 521)\n",
      "../data/wikipedia_fixed/c.parquet:  64%|▋| 1182/1840 [2:42:51<1:15:15,  6.86s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4346 tokens (3346 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Who conducted an interview with Carl Djerassi at Stanford University on July 31, 1985?\", \"answer\": \"B\", \"A\": \"Jeffrey L. Sturchio and Arnold Thackray\", \"B\": \"Arnold Thackray and Jeffrey L. Sturchio\", \"C\": \"Carl Djerassi and Arnold Thackray\", \"D\": \"Arnold Beckman and Jeffrey L. Sturchio\", \"E\": \"Suzie Hayman and Laurence Arnold\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4346 tokens (3346 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  65%|▋| 1190/1840 [2:43:51<1:05:21,  6.03s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4173 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes Chen's theorem?\", \"answer\": \"C\", \"A\": \"Chen's theorem proves the Goldbach's conjecture.\", \"B\": \"Chen's theorem is a result of the sieve methods.\", \"C\": \"Chen's theorem states that any even number can be written as the sum of a prime number and the product of at most two primes.\", \"D\": \"Chen's theorem is a result on the twin prime conjecture.\", \"E\": \"Chen's theorem states that there are infinitely many primes p such that p+h is either prime or the product of two primes.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4173 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  66%|▋| 1206/1840 [2:45:51<1:12:32,  6.87s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 196 (char 195)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the causal structure of a spacetime?\", \"answer\": \"C\", \"A\": \"A spacetime is strongly causal and every set J + ( x ) ∩ J − ( y ) {\\displaystyle J^{+}(x)\\cap J^{-}(y)} (for points x , y ∈ M {\\displaystyle x,y\\in M} ) is compact.\", \"B\": \"A spacetime is globally hyperbolic if and only if there exists a Cauchy surface for M {\\displaystyle M} .\", \"C\": \"A spacetime is stably causal if it cannot be made to contain closed causal curves by arbitrarily small perturbations of the metric.\", \"D\": \"A spacetime is globally hyperbolic if it satisfies the Alexandrov topology.\", \"E\": \"A spacetime is stably causal if it has a global time function on M {\\displaystyle M} whose gradient ∇ a t {\\displaystyle \\nabla ^{a}t} is everywhere timelike and future-directed.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 196 (char 195)\n",
      "../data/wikipedia_fixed/c.parquet:  67%|▋| 1229/1840 [2:48:21<1:08:17,  6.71s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4379 tokens (3379 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the main focus of the article 'Cerebellar Abiotrophy' by Lisa Goodwin-Campiglio?\", \"answer\": \"B\", \"A\": \"The clinical and neuropathological features of cerebellar hypoplasia and degeneration in young Arab horses.\", \"B\": \"The identification and progress towards finding the gene responsible for equine cerebellar abiotrophy.\", \"C\": \"The differential diagnoses for the wobbly horse.\", \"D\": \"The use of a test to scan for an inherited neurologic disorder in Arabian horses.\", \"E\": \"The neurologic disorders of neonatal foals.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4379 tokens (3379 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  68%|▋| 1252/1840 [2:50:54<1:05:03,  6.64s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 191 (char 190)\n",
      "{\"prompt\": \"Which of the following awards did C.M. Duarte receive?\", \"answer\": \"C\", \"A\": \"Ramon Margalef Prize in Ecology\", \"B\": \"Vladimir Ivanovich Vernadsky Medal\", \"C\": \"BBVA Foundation \"Frontiers of Knowledge Award 2021\"\", \"D\": \"Honorari Doctorate, Utrecht University\", \"E\": \"Prix d'Excellence of the International Council\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 191 (char 190)\n",
      "../data/wikipedia_fixed/c.parquet:  71%|▋| 1308/1840 [2:57:47<1:01:34,  6.94s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the main difference between a conjecture and a theorem?\", \"answer\": \"C\", \"A\": \"A conjecture is a proven statement, while a theorem is an unproven statement.\", \"B\": \"A conjecture is a statement that has been proven false, while a theorem is a statement that has been proven true.\", \"C\": \"A conjecture is an unproven statement, while a theorem is a proven statement.\", \"D\": \"A conjecture is a statement that is widely accepted but not proven, while a theorem is a statement that is widely accepted and proven.\", \"E\": \"A conjecture is a statement that is widely accepted and proven, while a theorem is a statement that is widely accepted but not proven.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  71%|▋| 1312/1840 [3:03:45<6:18:02, 42.96s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4666 tokens (3666 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the historical origin and significance of the dish 'cacasse à cul nu'?\", \"answer\": \"Cacasse à cul nu originated in the Meuse valley and was a fricassee of potatoes and roux cooked in a Dutch oven, traditionally flavored with bacon but served without meat. It was a dish associated with a self-sufficient economy and consumed by the most modest people when meat was unaffordable. The dish is mentioned in various works, including Gérard Gayot's 'La Révolution en Ardenne' and Françoise Branget's 'La Cuisine de la République'. The dish has historical significance as a symbol of Ardennaise cuisine. Since 2001, the 'Confrérie de la Cacasse à cul nu' has updated the recipe by adding meat, and it is now commonly served with smoked sausage or bacon slices.\", \"A\": \"Cacasse à cul nu originated in the Meuse valley and was a fricassee of potatoes and roux cooked in a Dutch oven, traditionally flavored with bacon but served without meat.\", \"B\": \"Cacasse à cul nu originated in the Meuse valley and was a dish associated with a self-sufficient economy, consumed by the most modest people when meat was unaffordable.\", \"C\": \"Cacasse à cul nu is mentioned in various works, including Gérard Gayot's 'La Révolution en Ardenne' and Françoise Branget's 'La Cuisine de la République'.\", \"D\": \"Cacasse à cul nu has historical significance as a symbol of Ardennaise cuisine.\", \"E\": \"Since 2001, the 'Confrérie de la Cacasse à cul nu' has updated the recipe by adding meat, and it is now commonly served with smoked sausage or bacon slices.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4666 tokens (3666 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  77%|█▌| 1419/1840 [3:16:21<43:28,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4352 tokens (3352 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"According to the research conducted by Garzione et al. (2006), what is the main evidence for the rapid rise of the Bolivian Altiplano during the late Miocene?\", \"answer\": \"C\", \"A\": \"The discovery of new fossil species in the Bolivian Altiplano.\", \"B\": \"The analysis of stable isotopes in sedimentary rocks from the Bolivian Altiplano.\", \"C\": \"The removal of mantle lithosphere beneath the Bolivian Altiplano.\", \"D\": \"The tectonic activity in the Thakkhola Graben.\", \"E\": \"The larger size of the Tibetan Plateau than previously thought.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4352 tokens (3352 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  77%|█▌| 1421/1840 [3:16:37<47:12,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Who is Catherine Constable married to?\", \"answer\": \"B\", \"A\": \"Catherine Constable is a geophysicist.\", \"B\": \"Catherine Constable is married to geophysicist Steven Constable.\", \"C\": \"Catherine Constable is a professor at a science university.\", \"D\": \"Catherine Constable received the 2013 William Gilbert Award.\", \"E\": \"Catherine Constable's research focuses on the Earth's magnetic field.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18466/1077163345.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_18466/2719080132.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/c.parquet:  81%|█▌| 1485/1840 [3:28:52<49:56,  8.44s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback \n",
    "batch_size = 1\n",
    "\n",
    "def make_prompt(series):\n",
    "    prompt = f\"\"\"\n",
    "You are a professor at a science university and are creating a test for your students.\n",
    "Please create one exam based on the provided text, where you choose the most accurately statement from five options for the question.\n",
    "The output should json format below:\n",
    "{{\"prompt\": <the question text>, \"answer\" <answer(one of A through E)>, \"A\": <option A>, \"B\": <option B>, \"C\": <option C>, \"D\": <option D>, \"E\": <option E>}}\n",
    "\n",
    "Context:\n",
    "{series['text']}\n",
    "\n",
    "Attention:\n",
    "- The question should be LONG sentences.\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def f(series):\n",
    "    try:\n",
    "        if series[\"A\"] != series[\"A\"]:\n",
    "            if type(series[\"answer\"]) == dict:\n",
    "                for key in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "                    series[key] = series[\"choices\"][key]\n",
    "            elif type(series[\"answer\"] == list):\n",
    "                for i, key in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\"]):\n",
    "                    series[key] = series[\"choices\"][i]\n",
    "    except:\n",
    "        return series\n",
    "    return series\n",
    "\n",
    "now_date = dt.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "first = True\n",
    "for file in files:\n",
    "    if os.path.basename(file) in [\"all.parquet\"]:\n",
    "        print(f\"pass: {file}\")\n",
    "        continue\n",
    "    df_science = get_df(file)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(df_science)), desc=file):\n",
    "        try:\n",
    "            series = df_science.iloc[i]\n",
    "            prompt = make_prompt(series)\n",
    "            text = query_prompt(prompt)\n",
    "            texts_json = json.loads(text)\n",
    "            if first:\n",
    "                print(texts_json)\n",
    "                first = False\n",
    "            if type(texts_json) == dict:\n",
    "                texts_json[\"wiki_id\"] = series[\"id\"]\n",
    "                texts_json[\"original_text\"] = series[\"text\"]\n",
    "                texts.append(texts_json)\n",
    "                for col in [\"A\", \"B\", \"C\", \"D\", \"E\", \"answer\", \"prompt\"]:\n",
    "                    if col not in texts_json:\n",
    "                        print(f\"{col} not existed: {texts_json}\")\n",
    "            else:\n",
    "                for text_json in texts_json:\n",
    "                    text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                    text_json[\"original_text\"] = series[\"text\"]\n",
    "                    texts.append(text_json)\n",
    "                    if col not in text_json:\n",
    "                        print(f\"{col} not existed: {texts_json}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "            print(text)\n",
    "            time.sleep(10)\n",
    "        if i % 20 == 0:\n",
    "            df_texts = pd.DataFrame(texts)\n",
    "            df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "            df_texts.to_parquet(f\"output_gpt3.5_generate/{now_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.DataFrame(texts)\n",
    "df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "df_texts.to_parquet(f\"output_gpt3.5_generate/{now_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
