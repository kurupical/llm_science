{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff8d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import json\n",
    "import re\n",
    "from html2text import html2text as htt\n",
    "import wikitextparser as wtp\n",
    "\n",
    "\n",
    "def dewiki(text):\n",
    "    text = wtp.parse(text).plain_text()  # wiki to plaintext \n",
    "    text = htt(text)  # remove any HTML\n",
    "    text = text.replace('\\\\n',' ')  # replace newlines\n",
    "    text = re.sub('\\s+', ' ', text)  # replace excess whitespace\n",
    "    return text\n",
    "\n",
    "\n",
    "def analyze_chunk(text):\n",
    "    try:\n",
    "        if '<redirect title=\"' in text:  # this is not the main article\n",
    "            return None\n",
    "        if '(disambiguation)' in text:  # this is not an article\n",
    "            return None\n",
    "        else:\n",
    "            title = text.split('<title>')[1].split('</title>')[0]\n",
    "            title = htt(title)\n",
    "            if ':' in title:  # most articles with : in them are not articles we care about\n",
    "                return None\n",
    "        serial = text.split('<id>')[1].split('</id>')[0]\n",
    "        content = text.split('</text')[0].split('<text')[1].split('>', maxsplit=1)[1]\n",
    "        content = dewiki(content)\n",
    "        return {'title': title.strip(), 'text': content.strip(), 'id': serial.strip()}\n",
    "    except Exception as oops:\n",
    "        print(oops)\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_article(article, savedir):\n",
    "    doc = analyze_chunk(article)\n",
    "    if doc:\n",
    "        # print('SAVING:', doc['title'])\n",
    "#         filename = doc['id'] + '.json'\n",
    "#         with open(savedir + filename, 'w', encoding='utf-8') as outfile:\n",
    "#             json.dump(doc, outfile, sort_keys=True, indent=1, ensure_ascii=False)\n",
    "        return doc\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "import pandas as pd\n",
    "def process_file_text(filename, savedir, batch_size=10000):\n",
    "    article = ''\n",
    "    batch_count = 1\n",
    "    with open(filename, 'r', encoding='utf-8') as infile:\n",
    "        article_batch = []\n",
    "        for i, line in enumerate(infile):\n",
    "            if '<page>' in line:\n",
    "                article = ''\n",
    "            elif '</page>' in line:  # end of article\n",
    "                doc = save_article(article, savedir)\n",
    "                if doc is not None:\n",
    "                    article_batch.append(doc)\n",
    "                if len(article_batch) > batch_size:\n",
    "                    print(f\"save {batch_count * batch_size}\")\n",
    "                    pd.DataFrame(article_batch).to_parquet(f\"{savedir}/{batch_count}.parquet\")\n",
    "                    batch_count += 1\n",
    "                    article_batch = []\n",
    "            else:\n",
    "                article += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382709e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 10\n",
      "save 20\n",
      "save 30\n",
      "save 40\n",
      "save 50\n",
      "save 60\n",
      "save 70\n",
      "save 80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m json_save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_parquet/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mprocess_file_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwiki_xml_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_save_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 57\u001b[0m, in \u001b[0;36mprocess_file_text\u001b[0;34m(filename, savedir, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m     article \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</page>\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:  \u001b[38;5;66;03m# end of article\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43msave_article\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavedir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         article_batch\u001b[38;5;241m.\u001b[39mappend(doc)\n",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36msave_article\u001b[0;34m(article, savedir)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_article\u001b[39m(article, savedir):\n\u001b[0;32m---> 37\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m doc:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;66;03m# print('SAVING:', doc['title'])\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#         filename = doc['id'] + '.json'\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#         with open(savedir + filename, 'w', encoding='utf-8') as outfile:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#             json.dump(doc, outfile, sort_keys=True, indent=1, ensure_ascii=False)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36manalyze_chunk\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     27\u001b[0m     serial \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<id>\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</id>\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m     content \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</text\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<text\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mdewiki\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: title\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: content\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: serial\u001b[38;5;241m.\u001b[39mstrip()}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m oops:\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mdewiki\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdewiki\u001b[39m(text):\n\u001b[0;32m----> 9\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mwtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# wiki to plaintext \u001b[39;00m\n\u001b[1;32m     10\u001b[0m     text \u001b[38;5;241m=\u001b[39m htt(text)  \u001b[38;5;66;03m# remove any HTML\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# replace newlines\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wikitextparser/_wikitext.py:689\u001b[0m, in \u001b[0;36mWikiText.plain_text\u001b[0;34m(self, replace_templates, replace_parser_functions, replace_parameters, replace_tags, replace_external_links, replace_wikilinks, unescape_html_entities, replace_bolds_and_italics, replace_tables, _is_root_node)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# replacing bold and italics should be done before wikilinks and tags\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# because removing tags and wikilinks creates invalid spans, and\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# get_bolds() will try to look into wikilinks for bold parts.\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace_bolds_and_italics:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparsed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bolds_and_italics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    690\u001b[0m         b, e \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39mspan\n\u001b[1;32m    691\u001b[0m         ib, ie \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39m_match\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# noqa, text span\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wikitextparser/_wikitext.py:1107\u001b[0m, in \u001b[0;36mWikiText.get_bolds_and_italics\u001b[0;34m(self, recursive, filter_cls)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     append(Bold(_lststr, type_to_spans, span, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBold\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recursive:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bolds_italics_recurse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filter_cls \u001b[38;5;129;01mis\u001b[39;00m Bold:\n\u001b[1;32m   1109\u001b[0m         result\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39mattrgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_span_data\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wikitextparser/_wikitext.py:1053\u001b[0m, in \u001b[0;36mWikiText._bolds_italics_recurse\u001b[0;34m(self, result, filter_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bolds_italics_recurse\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: \u001b[38;5;28mlist\u001b[39m, filter_cls: Optional[\u001b[38;5;28mtype\u001b[39m]):\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1049\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparser_functions\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1051\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwikilinks\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1052\u001b[0m     ):\n\u001b[0;32m-> 1053\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, prop):\n\u001b[1;32m   1054\u001b[0m             result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mget_bolds_and_italics(\n\u001b[1;32m   1055\u001b[0m                 filter_cls\u001b[38;5;241m=\u001b[39mfilter_cls, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m             )\n\u001b[1;32m   1057\u001b[0m     extension_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extension_tags\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#wiki_xml_file = 'F:/simplewiki-20210401/simplewiki-20210401.xml'  # update this\n",
    "wiki_xml_file = 'enwiki-20230901-pages-articles-multistream.xml'  # update this\n",
    "json_save_dir = 'parse_parquet/'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_file_text(wiki_xml_file, json_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b054b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
