{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c80db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeedd14",
   "metadata": {},
   "source": [
    "# scienceQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee3184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_paqruet(f):\n",
    "    df = pd.read_parquet(f)\n",
    "    df[\"source\"] = f\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67567659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    read_paqruet(f) for f in glob.glob(\"additional_data/ScienceQA/*\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d308702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    11045\n",
       "3     5078\n",
       "4     4893\n",
       "5      192\n",
       "Name: choices, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"choices\"].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeb4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"choices\"].apply(len) > 2) & (df[\"image\"].isnull())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168c84d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca39fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_choice(ary, i):\n",
    "    try:\n",
    "        return ary[i]\n",
    "    except:\n",
    "        return None\n",
    "df[\"A\"] = df[\"choices\"].apply(get_choice, i=0)\n",
    "df[\"B\"] = df[\"choices\"].apply(get_choice, i=1)\n",
    "df[\"C\"] = df[\"choices\"].apply(get_choice, i=2)\n",
    "df[\"D\"] = df[\"choices\"].apply(get_choice, i=3)\n",
    "df[\"E\"] = df[\"choices\"].apply(get_choice, i=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f261d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt\"] = df[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3370bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"answer\"] = df[\"answer\"].map({0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\", 4: \"E\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac394831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3291.000000\n",
       "mean       81.677606\n",
       "std        76.353925\n",
       "min        15.000000\n",
       "25%        34.000000\n",
       "50%        74.000000\n",
       "75%        94.000000\n",
       "max       862.000000\n",
       "Name: prompt, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb91742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\", \"answer\", \"source\"]].to_csv(\"../data/gpt_generated_data/science_qa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45416e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77fb3bee",
   "metadata": {},
   "source": [
    "# OpenBOok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1aafe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(f):\n",
    "    df = pd.read_csv(f, sep=\"\\t\")\n",
    "    df[\"source\"] = f\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f69cb31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    read_csv(f) for f in glob.glob(\"additional_data/OpenBookQA-V1-Sep2018/OpenBookQA-V1-Sep2018/Data/Main/*.tsv\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40f0daad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5957"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f367aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"Complete Question\"].str.contains(\"\\?\")].reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f0227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a(s):\n",
    "    return s.split(\"(A) \")[1].split(\" (B)\")[0]\n",
    "def get_b(s):\n",
    "    return s.split(\"(B) \")[1].split(\" (C)\")[0]\n",
    "def get_c(s):\n",
    "    return s.split(\"(C) \")[1].split(\" (D)\")[0]\n",
    "def get_d(s):\n",
    "    return s.split(\"(D) \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41d72085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Question Stem', 'Choices', 'Complete Question', 'Answer Key',\n",
       "       'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b631952",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt\"]  = df[\"Question Stem\"]\n",
    "df[\"A\"] = df[\"Choices\"].apply(get_a)\n",
    "df[\"B\"] = df[\"Choices\"].apply(get_b)\n",
    "df[\"C\"] = df[\"Choices\"].apply(get_c)\n",
    "df[\"D\"] = df[\"Choices\"].apply(get_d)\n",
    "df[\"E\"] = None\n",
    "df[\"answer\"] = df[\"Answer Key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fa1adf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2115.000000\n",
       "mean       56.840662\n",
       "std        24.898577\n",
       "min        14.000000\n",
       "25%        39.000000\n",
       "50%        53.000000\n",
       "75%        70.000000\n",
       "max       197.000000\n",
       "Name: prompt, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5793a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\", \"answer\", \"source\"]].to_csv(\"../data/gpt_generated_data/openbook.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd3834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e83936b",
   "metadata": {},
   "source": [
    "# MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28f5c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(f):\n",
    "    df = pd.read_csv(f)\n",
    "    df[\"source\"] = f\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74dbf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    read_csv(f) for f in glob.glob(\"additional_data/MMLU/*.csv\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "908651d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113884"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a8f3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"prompt\"].str.contains(\"\\?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f35568d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    74972.000000\n",
       "mean      1363.507243\n",
       "std        774.422673\n",
       "min         13.000000\n",
       "25%        828.000000\n",
       "50%       1490.000000\n",
       "75%       1873.000000\n",
       "max       6527.000000\n",
       "Name: prompt, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1f633da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10915"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"prompt\"].apply(len) < 300]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9d396d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10915.000000\n",
       "mean       107.954283\n",
       "std         67.283250\n",
       "min         13.000000\n",
       "25%         59.000000\n",
       "50%         86.000000\n",
       "75%        139.000000\n",
       "max        299.000000\n",
       "Name: prompt, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prompt\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3026be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"E\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b1b7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"prompt\", \"A\", \"B\", \"C\", \"D\", \"E\", \"answer\", \"source\"]].to_csv(\"../data/gpt_generated_data/mmlu.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131f47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc990df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
