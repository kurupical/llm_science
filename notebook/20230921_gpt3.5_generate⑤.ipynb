{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../apikey/apikey.txt\", \"r\") as f:\n",
    "    openai.api_key = f.readline().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_prompt(prompt, max_tokens=1000):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(fname):\n",
    "    def f(categories):\n",
    "        for cat in categories:\n",
    "            for word in [\n",
    "                \"geology\",\n",
    "                \"physics\",\n",
    "                \"chemistry\",\n",
    "                \"mathematical\",\n",
    "                \"biology\",\n",
    "                \"astronomy\",\n",
    "                \"ecology\",\n",
    "                \"genetics\",\n",
    "                \"statistics\",\n",
    "                \"theoretical\"\n",
    "            ]:\n",
    "                if word.lower() in cat.lower():\n",
    "                    return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def text_preprocess(text):\n",
    "        return text.replace(\"====\", \"\\n\\n\").replace(\"===\", \"\\n\\n\").replace(\"==\", \"\\n\\n\")\n",
    "\n",
    "    def sep_n(text, n=40):\n",
    "        try:\n",
    "            text = text.split(\".\")\n",
    "            start_index = random.randint(0, len(text) - n)\n",
    "            return \".\".join(text[start_index:start_index+n])\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    df = pd.read_parquet(fname)\n",
    "    df_science = df[df[\"category\"].apply(f)]\n",
    "    df_science[\"text\"] = df_science[\"text\"].apply(text_preprocess)\n",
    "    df_science[\"text\"] = df_science[\"text\"].apply(sep_n)\n",
    "    df_science = df_science[df_science[\"text\"].notnull()]\n",
    "    return df_science.sample(len(df_science)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../data/wikipedia_fixed/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/a.parquet:   0%|▏                                                                                 | 1/388 [00:05<35:05,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': \"What is the title of Alan Tutton Johns' PhD thesis?\", 'answer': 'C', 'A': 'The mechanism of propionic acid formation in fermentation', 'B': 'Advanced study in U.S.', 'C': 'The mechanism of propionic acid formation in fermentation with special reference to the rumen of the sheep', 'D': 'Honorary doctorate citation, Alan Johns, 1985', 'E': 'No. 47237'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/a.parquet:   4%|███▌                                                                             | 17/388 [02:34<54:38,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 72 (char 71)\n",
      "{\"prompt\": \"Which of the following statements is true about the Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets?\", \n",
      "\"answer\": \"C\", \n",
      "\"A\": \"Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets are closed sets in the usual topology on Baire space or Cantor space.\", \n",
      "\"B\": \"Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets are effectively open sets in the usual topology on Baire space or Cantor space.\", \n",
      "\"C\": \"Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets can be defined in the language of Peano arithmetic by a Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} formula.\", \n",
      "\"D\": \"Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets are subsets of Baire space or Cantor space that are computably enumerable.\", \n",
      "\"E\": \"Σ 1 0 {\\displaystyle \\Sigma _{1}^{0}} sets are sometimes called effectively closed sets.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 72 (char 71)\n",
      "../data/wikipedia_fixed/a.parquet:  10%|████████▎                                                                        | 40/388 [05:59<50:43,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra data: line 1 column 677 (char 676)\n",
      "{\"prompt\": \"What is the Shuey equation used for?\", \"answer\": \"C\", \"A\": \"To determine the amplitudes of reflected and refracted waves at a planar interface for an incident P-wave\", \"B\": \"To calculate the reflection coefficient at normal incidence and describe the variation of reflection amplitudes at intermediate offsets\", \"C\": \"To describe the behavior of reflection amplitudes at large angles/far offsets and the variation of reflection amplitudes with offset\", \"D\": \"To determine the effects of density and P- or S-wave velocity variations on the reflection amplitudes\", \"E\": \"To calculate the intersect and gradient for every time sample in every Common Midpoint Gather\"},\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 340, in decode\n",
      "    raise JSONDecodeError(\"Extra data\", s, end)\n",
      "json.decoder.JSONDecodeError: Extra data: line 1 column 677 (char 676)\n",
      "../data/wikipedia_fixed/a.parquet:  25%|████████████████████▍                                                            | 98/388 [15:21<37:53,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which statement accurately describes the conservation of angular momentum?\", \"answer\": \"C\", \"A\": \"The conservation of angular momentum is only applicable to planetary systems.\", \"B\": \"The conservation of angular momentum is a result of Noether's theorem.\", \"C\": \"The conservation of angular momentum is associated with rotational invariance.\", \"D\": \"The conservation of angular momentum is a direct consequence of Newton's second law.\", \"E\": \"The conservation of angular momentum is not applicable in quantum mechanics due to particle spin.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  26%|████████████████████                                                          | 100/388 [21:05<6:08:36, 76.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which statement accurately describes the role of tRNA synthetases?\", \"answer\": \"C\", \"A\": \"tRNA synthetases are enzymes that catalyze the attachment of amino acids to tRNA molecules.\", \"B\": \"tRNA synthetases are responsible for the hydrolysis of pyrophosphate during DNA synthesis.\", \"C\": \"Proper balance of tRNA and aminoacyl-tRNA synthetase is crucial for accurate aminoacylation in vivo.\", \"D\": \"tRNA synthetases play a role in prebiotic peptide bond formation through amino acid phosphorylation.\", \"E\": \"tRNA synthetases are involved in the translation process by facilitating the synthesis of tRNA molecules.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/a.parquet:  42%|█████████████████████████████████▍                                              | 162/388 [34:43<34:49,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5641 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What is the typical off-peak service in trains per hour at the station?\", \"answer\": \"A\", \"A\": \"The typical off-peak service at the station consists of 4 trains per hour to Highbury & Islington via Surrey Quays and 4 trains per hour to West Croydon.\", \"B\": \"The typical off-peak service at the station consists of 2 trains per hour to Highbury & Islington via Surrey Quays and 2 trains per hour to West Croydon.\", \"C\": \"The typical off-peak service at the station consists of 1 train per hour to Highbury & Islington via Surrey Quays and 1 train per hour to West Croydon.\", \"D\": \"The typical off-peak service at the station consists of 3 trains per hour to Highbury & Islington via Surrey Quays and 3 trains per hour to West Croydon.\", \"E\": \"The typical off-peak service at the station consists of 5 trains per hour to Highbury & Islington via Surrey Quays and 5 trains per hour to West Croydon.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5641 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/a.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 388/388 [1:05:42<00:00, 10.16s/it]\n",
      "../data/wikipedia_fixed/b.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 271/271 [37:07<00:00,  8.22s/it]\n",
      "../data/wikipedia_fixed/c.parquet:   4%|██▉                                                                            | 17/455 [03:02<1:20:50, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 302 (char 301)\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"The Iwasawa Main Conjectures for GL2 is a paper published in Inventiones Mathematicae in 2014.\", \"B\": \"The Birch and Swinnerton-Dyer conjecture is true for most elliptic curves over $\\mathbb Q$.\", \"C\": \"A majority of elliptic curves over $\\mathbb Q$ satisfy the Birch and Swinnerton-Dyer conjecture.\", \"D\": \"The BSD conjecture is true for most elliptic curves.\", \"E\": \"The Iwasawa Main Conjectures for GL2 is a paper published in 2013.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 302 (char 301)\n",
      "../data/wikipedia_fixed/c.parquet:   6%|████▊                                                                          | 28/455 [04:49<1:05:28,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 15626 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"When were cetaceans first recognized as mammals?\", \"answer\": \"B\", \"A\": \"Cetaceans were recognized as mammals in the 16th century by Rondelet.\", \"B\": \"Cetaceans were recognized as mammals in 1758 by Carl Linnaeus.\", \"C\": \"Cetaceans were recognized as mammals in the 20th century by whalers.\", \"D\": \"Cetaceans were recognized as mammals in the 1980s by the Tethys Institute of Milan.\", \"E\": \"Cetaceans were recognized as mammals in the 1960s by dedicated research institutes.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 15626 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/c.parquet:  35%|████████████████████████████▎                                                   | 161/455 [21:53<32:58,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4242 tokens (3242 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Who served as the editor-in-chief of the journal from 2012 to 2022?\", \"answer\": \"D\", \"A\": \"Josephine A. Morello served as the founding editor of the journal in 1988.\", \"B\": \"Betty Ann Forbes was appointed as the editor-in-chief of the journal in 1997.\", \"C\": \"Irving Nachamkin served as the editor-in-chief of the journal from 2002 to 2012.\", \"D\": \"Jo-Anne H. Young served as the editor-in-chief of the journal from 2012 to 2022.\", \"E\": \"Graeme Forrest is the current editor-in-chief of the journal.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4242 tokens (3242 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet:  95%|███████████████████████████████████████████████████████████████████████████▊    | 431/455 [54:25<02:24,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4894 tokens (3894 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements is true about the class numbers of imaginary quadratic number fields?\", \"answer\": \"C\", \"A\": \"The class numbers of imaginary quadratic number fields are all equal to 1.\", \"B\": \"The class numbers of imaginary quadratic number fields are all equal to 2.\", \"C\": \"The class numbers of imaginary quadratic number fields can vary and are not limited to 1 or 2.\", \"D\": \"The class numbers of imaginary quadratic number fields are all greater than 2.\", \"E\": \"The class numbers of imaginary quadratic number fields are all less than or equal to 1.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4894 tokens (3894 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/c.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 455/455 [57:23<00:00,  7.57s/it]\n",
      "../data/wikipedia_fixed/d.parquet:  15%|████████████▏                                                                    | 39/260 [04:33<23:00,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4734 tokens (3734 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"When was Devil's Slide formed?\", \"answer\": \"C\", \"A\": \"Devil's Slide was formed by a draining sea that poured down the center of the Slide.\", \"B\": \"Devil's Slide was formed by the erosion of limestone layers over millions of years.\", \"C\": \"Utah Geologist believe the Slide was formed 170 to 180 million years ago by a draining sea that poured down the center of the Slide.\", \"D\": \"Devil's Slide was formed during the Great Depression when the mining company shut down operations.\", \"E\": \"Devil's Slide was formed when God threw Lucifer out of heaven and he slid down the mountainside to hell along the route of Devil's Slide.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4734 tokens (3734 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/d.parquet:  27%|██████████████████████                                                           | 71/260 [08:19<18:07,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4703 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which statement accurately describes the relationship between DNA supercoiling and chromosome condensation?\", \"answer\": \"C\", \"A\": \"DNA supercoiling is not involved in chromosome condensation.\", \"B\": \"Chromosome condensation is solely dependent on ATP.\", \"C\": \"DNA supercoiling plays an active role in chromosome condensation.\", \"D\": \"TADs (Topologically Associating Domains) are not affected by DNA supercoiling.\", \"E\": \"Chromosome condensation is primarily regulated by the sequence of DNA.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4703 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/d.parquet:  33%|███████████████████████████                                                      | 87/260 [10:15<19:53,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 5092 tokens (4092 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of Dalton Discussions?\", \"answer\": \"C\", \"A\": \"To publish papers associated with oral presentations at scientific meetings\", \"B\": \"To provide a forum for the exchange of views and newly acquired results in inorganic chemistry\", \"C\": \"To serve as a permanent record of scientific meetings in the form of a special issue of a journal\", \"D\": \"To hold annual meetings for the inorganic chemistry community\", \"E\": \"To discuss important publications in inorganic chemistry\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 5092 tokens (4092 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/d.parquet:  45%|████████████████████████████████████                                            | 117/260 [13:49<17:54,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4109 tokens (3109 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the Dirac operator?\", \"answer\": \"C\", \"A\": \"The Dirac operator is a differential operator that acts on sections of a spinor bundle and is defined locally using a local orthonormal basis for the tangent space of a spin manifold.\", \"B\": \"The Dirac operator is a self-adjoint operator that acts on a four-component wave function in the Sobolev space of smooth, square-integrable functions.\", \"C\": \"The Dirac operator is a differential operator that describes the propagation of a free fermion in three dimensions and is written in the form D = c α → ⋅ ( − i ℏ ∇ x ) + m c 2 β.\", \"D\": \"The Dirac operator is a differential operator that arises in Clifford analysis and is defined as D = ∑ j = 1 n e j ∂ ∂ x j, where {ej: j = 1, ..., n} is an orthonormal basis for euclidean n-space.\", \"E\": \"The Dirac operator is a differential operator that acts on sections of a Clifford bundle and can be restricted to the spinor bundle if the projection operator on the ideal is parallel.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4109 tokens (3109 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/d.parquet:  88%|██████████████████████████████████████████████████████████████████████▍         | 229/260 [27:06<03:34,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 700 (char 699)\n",
      "{\"prompt\": \"Which of the following statements is the most accurate?\", \"answer\": \"C\", \"A\": \"Dialetheism is a philosophical position that allows for true contradictions and challenges the principle of non-contradiction.\", \"B\": \"Logical consequence is the relationship between statements where one statement follows logically from another.\", \"C\": \"The Law of Non-Contradiction is a fundamental principle of classical logic that states that a statement cannot be both true and false at the same time.\", \"D\": \"Paraconsistent set theory is a mathematical framework that allows for contradictions without leading to inconsistency.\", \"E\": \"Nagarjuna was an Indian philosopher who argued for the concept of \"emptiness\" and the idea that all things are ultimately empty of inherent existence.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 700 (char 699)\n",
      "../data/wikipedia_fixed/d.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [30:54<00:00,  7.13s/it]\n",
      "../data/wikipedia_fixed/e.parquet:  10%|████████▏                                                                        | 29/288 [03:49<30:05,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4812 tokens (3812 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the reason behind Erasmus Montanus's arguments with everyone he encounters?\", \"answer\": \"C\", \"A\": \"He wants to prove absurdities and rely on arguments from ignorance.\", \"B\": \"He is jealous of other scholars and wants to assert his superiority.\", \"C\": \"He insists on being referred to by his Latinised name and enjoys disputing.\", \"D\": \"He is trying to impress his fiancée's parents and gain their approval.\", \"E\": \"He is trying to avoid military service by enlisting in the clergy.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4812 tokens (3812 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/e.parquet:  37%|█████████████████████████████▍                                                  | 106/288 [13:19<27:16,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4747 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes Elliott Lieb?\", \"answer\": \"C\", \"A\": \"Elliott Lieb received the ESI Medal in 2022.\", \"B\": \"Elliott Lieb was a recipient of the 2022 APS Medal for Exceptional Achievement in Research.\", \"C\": \"Elliott Lieb is a renowned mathematician and physicist who has received several prestigious awards, including the ESI Medal, the 2022 APS Medal for Exceptional Achievement in Research, and the Gauss Prize.\", \"D\": \"Elliott Lieb was a past president of the International Association of Mathematical Physics.\", \"E\": \"Elliott Lieb is a Fellow of the American Mathematical Society and a member of the Royal Society.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4747 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/e.parquet:  57%|█████████████████████████████████████████████▌                                  | 164/288 [20:58<15:18,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4656 tokens (3656 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which statement accurately describes the history of vaccines?\", \"answer\": \"C\", \"A\": \"Vaccines were first developed in the 21st century by the Committee on Emerging Microbial Threats to Health.\", \"B\": \"The World Economic Forum played a significant role in the development of vaccines.\", \"C\": \"Vaccines have a long history and have played a crucial role in changing the world by preventing and controlling epidemics.\", \"D\": \"The World Health Organization (WHO) has recently published a report on the history of vaccines.\", \"E\": \"The emergence of COVID-19 has led to a decline in the use of vaccines worldwide.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4656 tokens (3656 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/e.parquet:  60%|███████████████████████████████████████████████▊                                | 172/288 [22:01<14:07,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 339 (char 338)\n",
      "{\"prompt\": \"Which of the following statements accurately describes the research conducted by Emil J. Straube?\", \"answer\": \"C\", \"A\": \"Emil J. Straube's research focuses on Sobolev estimates for the complex Green operator on weakly pseudoconvex boundaries.\", \"B\": \"Emil J. Straube's research primarily deals with the regularity of the ∂ ¯ {\\displaystyle {\\overline {\\partial }}} -Neumann problem.\", \"C\": \"Emil J. Straube has conducted research on various topics including Sobolev estimates, regularity of the ∂ ¯ {\\displaystyle {\\overline {\\partial }}} -Neumann problem, and semi-classical analysis of Schrödinger operators.\", \"D\": \"Emil J. Straube's research is mainly centered around Levi foliations in pseudoconvex boundaries and vector fields that commute approximately with ∂ ¯ {\\displaystyle {\\overline {\\partial }}} .\", \"E\": \"Emil J. Straube's research primarily focuses on a sufficient condition for global regularity of the ∂ ¯ {\\displaystyle {\\overline {\\partial }}} -Neumann operator.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 339 (char 338)\n",
      "../data/wikipedia_fixed/e.parquet:  68%|██████████████████████████████████████████████████████▋                         | 197/288 [25:25<11:35,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4511 tokens (3511 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"Chess ratings are solely determined by a player's performance in official tournaments.\", \"B\": \"The Nunn Plan is a strategy developed by Viswanathan Anand for the World Chess Championship.\", \"C\": \"Rating inflation in chess is a recognized issue that has been discussed and analyzed by experts.\", \"D\": \"Planeswalker Points is a system introduced to track and reward players' performance in chess tournaments.\", \"E\": \"Intrinsic chess ratings are a new concept proposed in a research paper published in the AAAI Conference on Artificial Intelligence.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4511 tokens (3511 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/e.parquet:  79%|███████████████████████████████████████████████████████████████▎                | 228/288 [29:33<06:33,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4703 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes coevolution?\", \"answer\": \"C\", \"A\": \"Coevolution is the process by which two or more species reciprocally affect each other's evolution through natural selection.\", \"B\": \"Coevolution occurs when two species have a mutualistic relationship and both benefit from each other's presence.\", \"C\": \"Coevolution is a dynamic process in which the interactions between species lead to reciprocal evolutionary changes.\", \"D\": \"Coevolution is a rare phenomenon that only occurs in highly specialized ecological niches.\", \"E\": \"Coevolution is a static process in which species remain unchanged over time.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4703 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/e.parquet:  82%|█████████████████████████████████████████████████████████████████▊              | 237/288 [30:40<05:56,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements accurately describes the central limit theorem?\", \"answer\": \"C\", \"A\": \"The central limit theorem states that the sum of a large number of independent and identically distributed random variables will be approximately normally distributed.\", \"B\": \"The central limit theorem states that the mean of a large number of independent and identically distributed random variables will be approximately normally distributed.\", \"C\": \"The central limit theorem states that the distribution of the sum (or average) of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the shape of the original distribution.\", \"D\": \"The central limit theorem states that the distribution of the maximum or minimum of a large number of independent and identically distributed random variables will be approximately normally distributed.\", \"E\": \"The central limit theorem states that the distribution of the product or quotient of a large number of independent and identically distributed random variables will be approximately normally distributed.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/e.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [42:02<00:00,  8.76s/it]\n",
      "../data/wikipedia_fixed/f.parquet:  18%|██████████████▍                                                                  | 32/179 [03:52<21:52,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4247 tokens (3247 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the use of high performance liquid chromatography (HPLC) in pharmaceutical analyses?\", \"answer\": \"C\", \"A\": \"High performance liquid chromatography (HPLC) is a widely used technique in pharmaceutical analyses due to its ability to separate and quantify complex mixtures of compounds.\", \"B\": \"HPLC is a technique that is primarily used in forensic toxicology for the analysis of drugs and their metabolites.\", \"C\": \"HPLC is a powerful analytical technique used in pharmaceutical analyses to separate, identify, and quantify drug compounds in complex mixtures.\", \"D\": \"HPLC is a relatively new technique that has limited applications in pharmaceutical analyses.\", \"E\": \"HPLC is a low sensitivity technique that is not suitable for the analysis of difficult analytes in pharmaceutical samples.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4247 tokens (3247 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/f.parquet:  68%|██████████████████████████████████████████████████████▌                         | 122/179 [14:56<07:20,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What was one of the main focuses of the professor's studies?\", \"answer\": \"C\", \"A\": \"He was primarily focused on the synthesis of cluster compounds with bonds between different transition elements.\", \"B\": \"His main area of research was the study of boron hydrides.\", \"C\": \"Among the many foci of his studies were complexes of fluorocarbon, isocyanide, polyolefin, alkylidene and alkylidyne ligands.\", \"D\": \"He dedicated his research to the discovery of versatile reagents for the synthesis of organometallic compounds.\", \"E\": \"His research primarily revolved around the investigation of carbon-metal and metal-metal multiple bonds.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/f.parquet:  93%|██████████████████████████████████████████████████████████████████████████▏     | 166/179 [26:08<01:34,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4102 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What was the purpose of Carl Linnaeus's book Fundamenta Botanica?\", \"answer\": \"C\", \"A\": \"Fundamenta Botanica was a book dedicated to famous botanists and aimed to honor their contributions to the field.\", \"B\": \"Fundamenta Botanica was a book that outlined Linnaeus's ideas for the reformation of botanical taxonomy.\", \"C\": \"Fundamenta Botanica laid the foundations for Linnaeus's system of nomenclature, classification, and botanical terminology.\", \"D\": \"Fundamenta Botanica was a book that focused on the description and classification of different plant species.\", \"E\": \"Fundamenta Botanica was a book that discussed the forces and variations within the plant kingdom.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4102 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/f.parquet:  94%|███████████████████████████████████████████████████████████████████████████     | 168/179 [26:27<01:33,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 129 (char 128)\n",
      "{\"prompt\": \"Which of the following statements accurately reflects the content of the provided text?\", \"answer\": \"C\", \"A\": \"The \"One Health\" initiative focuses on the relationship between chronic infection and autoimmune diseases.\", \"B\": \"The study discussed in the text examines the link between Mycobacterium avium subspecies paratuberculosis and type-1 diabetes mellitus.\", \"C\": \"The text discusses the importance of research on zoonoses in the context of the \"One Health\" initiative.\", \"D\": \"The study mentioned in the text argues against the need for more microbial genomes.\", \"E\": \"The text provides an overview of the Functional Molecular Infection Epidemiology research program.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 129 (char 128)\n",
      "../data/wikipedia_fixed/f.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 179/179 [27:57<00:00,  9.37s/it]\n",
      "../data/wikipedia_fixed/g.parquet:   9%|███████▎                                                                         | 30/330 [04:10<38:40,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 193 (char 192)\n",
      "{\"prompt\": \"Which source provides information on station usage statistics for London?\", \"answer\": \"C\", \"A\": \"Archived from the original on 9 November 2020. Retrieved 9 November 2020.\", \"B\": \"\"Station Usage Data\" (XLSX). Usage Statistics for London Stations, 2020. Transport for London. 16 April 2021. Retrieved 1 January 2022.\", \"C\": \"\"Station Usage Data\" (XLSX). Usage Statistics for London Stations, 2021. Transport for London. 12 July 2022. Retrieved 7 September 2022.\", \"D\": \"\"Estimates of station usage\". Rail statistics. Office of Rail Regulation.\", \"E\": \"Chronology of London Railways by H.V.Borley\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 193 (char 192)\n",
      "../data/wikipedia_fixed/g.parquet:   9%|███████▌                                                                         | 31/330 [04:29<54:28, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4977 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which source provides information on station usage statistics for London?\", \"answer\": \"C\", \"A\": \"Archived from the original on 9 November 2020. Retrieved 9 November 2020.\", \"B\": \"\"Station Usage Data\" (XLSX). Usage Statistics for London Stations, 2020. Transport for London. 16 April 2021. Retrieved 1 January 2022.\", \"C\": \"\"Station Usage Data\" (XLSX). Usage Statistics for London Stations, 2021. Transport for London. 12 July 2022. Retrieved 7 September 2022.\", \"D\": \"\"Estimates of station usage\". Rail statistics. Office of Rail Regulation.\", \"E\": \"Chronology of London Railways by H.V.Borley\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4977 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/g.parquet:  14%|███████████▌                                                                     | 47/330 [07:00<38:08,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4127 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \n",
      "\"answer\": \"C\", \n",
      "\"A\": \"The Equivalence Principle was first introduced in a paper published in 1961 by L.\", \n",
      "\"B\": \"CP violation is a phenomenon that is related to the concept of gravity.\", \n",
      "\"C\": \"'t Hooft's book, Spookrijders in de wetenschap, discusses the topic of CP violation and its connection to gravity.\", \n",
      "\"D\": \"The paper by Kowitt in 1996 explores the concept of gravitational repulsion and its relationship to Dirac antimatter.\", \n",
      "\"E\": \"The article by Chardin and Rax in 1992 presents evidence supporting the idea that CP violation is influenced by gravity.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4127 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/g.parquet:  88%|██████████████████████████████████████████████████████████████████████          | 289/330 [41:33<06:00,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 569 (char 568)\n",
      "{\"prompt\": \"What did Darwin comment about writing a book?\", \"answer\": \"C\", \"A\": \"Darwin believed that writing a book was a waste of time and effort.\", \"B\": \"Darwin believed that writing a book was the best way to prove one's intelligence.\", \"C\": \"Darwin sardonically commented that writing a book is a proof of earnestness and that you do not form your opinions without undergoing labor of some kind.\", \"D\": \"Darwin believed that writing a book was a way to gain recognition from other geologists.\", \"E\": \"Darwin believed that writing a book was a way to promote the \"crater of elevation\" theory.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 569 (char 568)\n",
      "../data/wikipedia_fixed/g.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 330/330 [47:42<00:00,  8.67s/it]\n",
      "../data/wikipedia_fixed/h.parquet:  76%|█████████████████████████████████████████████████████████████                   | 194/254 [26:14<07:45,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4965 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"What is the interpretation of the steep north-dipping Haukå Fault?\", \"answer\": \"C\", \"A\": \"The Haukå Fault is a post-Devonian brittle structure that formed close to the original basin edge.\", \"B\": \"The Haukå Fault is a low-angle extensional fault known as the Hornelen Detachment.\", \"C\": \"The Haukå Fault is interpreted to increase in displacement westwards, locally cutting out the alluvial fan deposits.\", \"D\": \"The Haukå Fault is a west–southwest trending anticline and syncline parallel to the faulted margin.\", \"E\": \"The Haukå Fault is a major extensional structure with tens of km of displacement.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4965 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/h.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 254/254 [33:50<00:00,  8.00s/it]\n",
      "../data/wikipedia_fixed/i.parquet:  89%|███████████████████████████████████████████████████████████████████████▎        | 172/193 [23:12<02:40,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the term coined by Jan Kaiser and Thomas Röckmann in 2008?\", \"answer\": \"B\", \"A\": \"Isotopocule analysis of biologically produced nitrous oxide in various environments\", \"B\": \"Isotopologue\", \"C\": \"Correction of mass spectrometric isotope ratio measurements for isobaric isotopologues of O2, CO, CO2, N2O and SO2\", \"D\": \"Stable Isotopes in Tree Rings\", \"E\": \"Terminology, Definitions and Properties\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/i.parquet:  90%|████████████████████████████████████████████████████████████████████████        | 174/193 [28:30<22:30, 71.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 5050 tokens (4050 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of using an internal standard in analytical techniques?\", \"answer\": \"C\", \"A\": \"An internal standard is used to determine the concentration of other analytes by calculating response factor.\", \"B\": \"An internal standard is used to create calibration curves that ignore the uncertainty between measurements.\", \"C\": \"An internal standard is used to mitigate uncertainty in preparatory steps and ensure accurate measurement of the analyte.\", \"D\": \"An internal standard is used to select the appropriate ionization method in liquid chromatography-mass spectrometry.\", \"E\": \"An internal standard is used to observe how the analyte and internal standard signals change with varying experimental conditions in ICP-OES.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 5050 tokens (4050 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/i.parquet:  91%|████████████████████████████████████████████████████████████████████████▉       | 176/193 [28:49<11:11, 39.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4188 tokens (3188 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the purpose of the Impact Field Studies Group (IFSG)?\", \"answer\": \"C\", \"A\": \"The IFSG is a scientific organization that conducts research on impact craters and impact structures.\", \"B\": \"The IFSG is a group of researchers, professionals, and students who study impact sites and maintain the Impact Database.\", \"C\": \"The IFSG is a scientific organization that emphasizes geologic field research of suspected and confirmed impact craters and impact structures.\", \"D\": \"The IFSG is a group of researchers, professionals, and students who organize field trips to impact-related sites.\", \"E\": \"The IFSG is a scientific organization that accepts submissions of proposed new impact sites and requires submitters to do significant homework before submitting.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4188 tokens (3188 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/i.parquet:  93%|██████████████████████████████████████████████████████████████████████████▏     | 179/193 [29:13<04:21, 18.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements accurately describes the Integrated Biosphere Simulator Model (IBIS)?\", \"answer\": \"C\", \"A\": \"The IBIS model was developed by Colin, Ramankutty, Levis, Pollard, Sitch, and Haxeltine.\", \"B\": \"The IBIS model is a land surface process model that does not consider vegetation dynamics.\", \"C\": \"The IBIS model is an integrated biosphere model that simulates land surface processes, terrestrial carbon balance, and vegetation dynamics.\", \"D\": \"The IBIS model is only available as Version 2.5 and cannot be accessed online.\", \"E\": \"The IBIS model was developed by Foley, Kucharik, and Polzin in 2005.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/i.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 193/193 [36:40<00:00, 11.40s/it]\n",
      "../data/wikipedia_fixed/j.parquet:  16%|████████████▌                                                                    | 25/161 [03:33<20:59,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements accurately describes Joel L. Lebowitz?\", \"answer\": \"C\", \"A\": \"Joel L. Lebowitz is a renowned physicist who has made significant contributions to the field of statistical mechanics, particularly in the study of large deviations in nonequilibrium steady states and the rigorous analysis of Gibbs equilibrium ensembles.\", \"B\": \"Joel L. Lebowitz has been the editor-in-chief of the Journal of Statistical Physics since 1975, a prestigious position that he held until September 2018.\", \"C\": \"Joel L. Lebowitz has received numerous honors and awards for his contributions to both equilibrium and non-equilibrium statistical mechanics, including the Boltzmann Medal, the Nicholson Medal, the Delmer S. Fahrney Medal, the Henri Poincaré Prize, the Volterra Award, the Heineman Prize for Mathematical Physics, the Max Planck Medal, the Grande Médaille of the French Academy of Sciences, and the Dirac Medal of the ICTP.\", \"D\": \"Joel L. Lebowitz is a member of the United States National Academy of Sciences and has been recognized as a fellow of both the American Physical Society and the American Mathematical Society.\", \"E\": \"Joel L. Lebowitz hosts a biannual series of conferences on statistical mechanics, which have been running for 60 years and are held at Yeshiva University and Rutgers University.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/j.parquet:  39%|███████████████████████████████▋                                                 | 63/161 [13:26<11:10,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following journals contains an article co-authored by Jack Thorne?\", \"answer\": \"C\", \"A\": \"The Journal of the Institute of Mathematics of Jussieu contains an article co-authored by Jack Thorne.\", \"B\": \"The Journal of the American Mathematical Society contains an article co-authored by Jack Thorne.\", \"C\": \"The Research in the Mathematical Sciences contains an article co-authored by Jack Thorne.\", \"D\": \"The American Journal of Mathematics contains an article co-authored by Jack Thorne.\", \"E\": \"The Journal of the Institute of Mathematics of Jussieu and the Journal of the American Mathematical Society both contain articles co-authored by Jack Thorne.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/j.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 161/161 [30:50<00:00, 11.49s/it]\n",
      "../data/wikipedia_fixed/k.parquet:  17%|█████████████▋                                                                   | 17/101 [02:07<09:59,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4424 tokens (3424 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements is true about the approximate limit of a Lebesgue-measurable function?\", \"answer\": \"C\", \"A\": \"The approximate limit of a Lebesgue-measurable function is always unique.\", \"B\": \"A Lebesgue-measurable function has an approximate limit at every point of density of its domain.\", \"C\": \"A Lebesgue-measurable function has an approximate limit at a point of density if and only if there exists a measurable subset of its domain where the restriction of the function has a limit equal to the approximate limit.\", \"D\": \"The approximate limit of a Lebesgue-measurable function is always equal to the function's value at that point of density.\", \"E\": \"A Lebesgue-measurable function is approximately continuous at every point of density of its domain.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4424 tokens (3424 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/k.parquet:  21%|████████████████▊                                                                | 21/101 [02:39<09:52,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4614 tokens (3614 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Who were some of Constantine Posse's students?\", \"answer\": \"A\", \"A\": \"Veniamin Kagan and D. D. Morduhai-Boltovskoi were among his students.\", \"B\": \"Constantine Posse had no students.\", \"C\": \"Constantine Posse's students are unknown.\", \"D\": \"Constantine Posse's students were not mentioned in the text.\", \"E\": \"Constantine Posse's students were not important.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4614 tokens (3614 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/k.parquet:  53%|███████████████████████████████████████████▎                                     | 54/101 [07:23<06:03,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 420 (char 419)\n",
      "{\"prompt\": \"What is one of the key aspects of the Kumeyaay civilization's cosmological belief system?\", \"answer\": \"C\", \"A\": \"The Kumeyaay civilization developed a complex system for tracking time based on astronomical observations and visual registration.\", \"B\": \"The Kumeyaay people created sand paintings and rock art to depict the movement of celestial bodies such as the sun, moon, and constellations.\", \"C\": \"The \"Men in a square\" rupestric painting at El Vallecito aligns with sunlight on the Fall equinox, indicating the Kumeyaay's knowledge of astronomical events.\", \"D\": \"Observation areas were constructed by the Kumeyaay to observe and record astronomical events, although many were destroyed before protective measures were implemented.\", \"E\": \"The Milky Way constellations, known as Hatotkeur or the Spine of the Sky, held cultural significance in Kumeyaay astronomy.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 420 (char 419)\n",
      "../data/wikipedia_fixed/k.parquet:  89%|████████████████████████████████████████████████████████████████████████▏        | 90/101 [11:52<01:35,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 903 (char 902)\n",
      "{\"prompt\": \"What was Kurt Otto Friedrichs' greatest contribution to applied mathematics?\", \"answer\": \"A\", \"A\": \"Kurt Otto Friedrichs' greatest contribution to applied mathematics was his work on partial differential equations, which has had a significant impact on various fields such as physics, fluid dynamics, and elasticity.\", \"B\": \"Kurt Otto Friedrichs' greatest contribution to applied mathematics was his research and writings on existence theory, numerical methods, differential operators in Hilbert space, non-linear buckling of plates, flows past wings, solitary waves, shock waves, combustion, magneto-fluid dynamical shock waves, relativistic flows, quantum field theory, perturbation of the continuous spectrum, scattering theory, and symmetric hyperbolic equations.\", \"C\": \"Kurt Otto Friedrichs' greatest contribution to applied mathematics was his collaboration with Cartan in giving a \"geometrized\" formulation of Newtonian gravitation theory, which has been further developed by other mathematicians.\", \"D\": \"Kurt Otto Friedrichs' greatest contribution to applied mathematics was his instrumental role in the development of the Courant Institute of Mathematical Sciences, which has become one of the most distinguished research institutes for applied mathematics in the world.\", \"E\": \"Kurt Otto Friedrichs' greatest contribution to applied mathematics was his extensive research and writings on various topics such as fluid dynamics, perturbation of spectra in Hilbert space, mathematical aspects of quantum theory of fields, and spectral theory of operators in Hilbert space.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 903 (char 902)\n",
      "../data/wikipedia_fixed/k.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 101/101 [13:50<00:00,  8.22s/it]\n",
      "../data/wikipedia_fixed/l.parquet:  29%|███████████████████████▏                                                        | 124/427 [16:06<35:40,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is one of the features of LIONsolver?\", \"answer\": \"C\", \"A\": \"LIONsolver is a software architecture that allows for problem-specific extensions and can be used as a post-processing tool for all optimization schemes.\", \"B\": \"LIONsolver won the first prize of the Michael J. Fox Foundation – Kaggle Parkinson's Data Challenge in 2013.\", \"C\": \"LIONsolver permits interactive multi-objective optimization and has a user interface for visualizing results and facilitating decision making.\", \"D\": \"LIONsolver is a reactive search and intelligent optimization tool that leverages the wisdom of the crowd.\", \"E\": \"LIONsolver is a programming by optimization tool that can be used for autonomous search.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/l.parquet:  49%|███████████████████████████████████████▏                                        | 209/427 [31:55<24:47,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \n",
      " \"answer\": \"C\", \n",
      " \"A\": \"Sherrardspark Wood is a Local Nature Reserve according to Natural England.\", \n",
      " \"B\": \"Tewinbury is a Site of Special Scientific Interest according to Natural England.\", \n",
      " \"C\": \"Therfield Heath is both a Local Nature Reserve and a Site of Special Scientific Interest according to Natural England.\", \n",
      " \"D\": \"Thorley Wash is a Local Nature Reserve according to the Herts and Middlesex Wildlife Trust.\", \n",
      " \"E\": \"Tring Reservoirs is a Site of Special Scientific Interest according to Natural England.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/l.parquet:  63%|██████████████████████████████████████████████████                              | 267/427 [43:49<17:45,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unterminated string starting at: line 1 column 5023 (char 5022)\n",
      "{\"prompt\": \"Who is a professor at a science university?\", \"answer\": \"E\", \"A\": \"com Ebony O'Dea at AustralianFootball.com Caitlin Gould at AustralianFootball.com Isabella Shannon at AustralianFootball.com Tamara Luke at AustralianFootball.com Brooke Vernon at AustralianFootball.com Emily Bonser at AustralianFootball.com EllaWood at AustralianFootball.com Jacqueline Parry at AustralianFootball.com Mia King at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Hannay Munyard at AustralianFootball.com Poppy Kelly at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Emma O'Driscoll at AustralianFootball.com Montana McKinnon at AustralianFootball.com Sarah Halvorsen at AustralianFootball.com Kate Dempsey at AustralianFootball.com Samantha Johnson at AustralianFootball.com Brenna Tarrant at AustralianFootball.com Lucy Bellinger at AustralianFootball.com Nekaela Butler at AustralianFootball.com Ciara Fitzgerald at AustralianFootball.com Nell Morris-Dalton at AustralianFootball.com Sarah Garstone at AustralianFootball.com Emily Goodsir at AustralianFootball.com Mhicca Carter at AustralianFootball.com Taylor Smith at AustralianFootball.com Krstel Petrevski at AustralianFootball.com Tahlia Hickie at AustralianFootball.com Laura Bailey at AustralianFootball.com Christina Bernardi at AustralianFootball.com Katie Brennan at AustralianFootball.com Hannah Burchell at AustralianFootball.com Monique Conti at AustralianFootball.com Sabrina Frederick at AustralianFootball.com Akec Makur Chuot at AustralianFootball.com Phoebe Monahan at AustralianFootball.com Lauren Tesoriero at AustralianFootball.com Holly Whitford at AustralianFootball.com Holly Whitford at AustralianFootball\", \"B\": \"com Ebony O'Dea at AustralianFootball.com Caitlin Gould at AustralianFootball.com Isabella Shannon at AustralianFootball.com Tamara Luke at AustralianFootball.com Brooke Vernon at AustralianFootball.com Emily Bonser at AustralianFootball.com EllaWood at AustralianFootball.com Jacqueline Parry at AustralianFootball.com Mia King at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Hannay Munyard at AustralianFootball.com Poppy Kelly at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Emma O'Driscoll at AustralianFootball.com Montana McKinnon at AustralianFootball.com Sarah Halvorsen at AustralianFootball.com Kate Dempsey at AustralianFootball.com Samantha Johnson at AustralianFootball.com Brenna Tarrant at AustralianFootball.com Lucy Bellinger at AustralianFootball.com Nekaela Butler at AustralianFootball.com Ciara Fitzgerald at AustralianFootball.com Nell Morris-Dalton at AustralianFootball.com Sarah Garstone at AustralianFootball.com Emily Goodsir at AustralianFootball.com Mhicca Carter at AustralianFootball.com Taylor Smith at AustralianFootball.com Krstel Petrevski at AustralianFootball.com Tahlia Hickie at AustralianFootball.com Laura Bailey at AustralianFootball.com Christina Bernardi at AustralianFootball.com Katie Brennan at AustralianFootball.com Hannah Burchell at AustralianFootball.com Monique Conti at AustralianFootball.com Sabrina Frederick at AustralianFootball.com Akec Makur Chuot at AustralianFootball.com Phoebe Monahan at AustralianFootball.com Lauren Tesoriero at AustralianFootball.com Holly Whitford at AustralianFootball.com Holly Whitford at AustralianFootball\", \"C\": \"com Ebony O'Dea at AustralianFootball.com Caitlin Gould at AustralianFootball.com Isabella Shannon at AustralianFootball.com Tamara Luke at AustralianFootball.com Brooke Vernon at AustralianFootball.com Emily Bonser at AustralianFootball.com EllaWood at AustralianFootball.com Jacqueline Parry at AustralianFootball.com Mia King at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Hannay Munyard at AustralianFootball.com Poppy Kelly at AustralianFootball.com Britney Gutknecht at AustralianFootball.com Emma O'Driscoll at AustralianFootball.com Montana McKinnon at AustralianFootball.com Sarah Halvorsen at AustralianFootball.com Kate Dempsey at AustralianFootball.com Samantha Johnson at AustralianFootball.com Brenna Tarrant at AustralianFootball.com Lucy Bellinger at AustralianFootball.com Nekaela Butler at AustralianFootball.com Ciara Fitzgerald at AustralianFootball.com Nell Morris-Dalton at AustralianFootball.com Sarah Garstone at AustralianFootball.com Emily Goodsir at AustralianFootball.com Mhicca Carter at AustralianFootball.com Taylor Smith at AustralianFootball.com Krstel Petrevski at AustralianFootball.com Tahlia Hickie at AustralianFootball.com Laura Bailey at AustralianFootball.com Christina Bernardi at AustralianFootball.com Katie Brennan at AustralianFootball.com Hannah Burchell at AustralianFootball.com Monique Conti at AustralianFootball.com Sabrina Frederick at AustralianFootball.com Akec Makur Chuot at AustralianFootball.com Phoebe Monahan at AustralianFootball.com Lauren Tesoriero at AustralianFootball.com Holly Whitford at AustralianFootball.com Holly Whitford at AustralianFootball\", \"D\": \"com Ebony O'Dea at AustralianFootball.com Caitlin Gould at AustralianFootball.com Isabella Shannon at AustralianFootball.com Tamara Luke at AustralianFootball.com Brooke Vernon at AustralianFootball.com Emily Bon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Unterminated string starting at: line 1 column 5023 (char 5022)\n",
      "../data/wikipedia_fixed/l.parquet:  63%|██████████████████████████████████████████████████▌                             | 270/427 [44:56<35:00, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4853 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which player has the most international appearances?\", \"answer\": \"C\", \"A\": \"Emmanuel Okwi has played for the national football team.\", \"B\": \"Kasun Nadika Jayasuriya is a well-known football player.\", \"C\": \"Seydou Keïta has the most international appearances.\", \"D\": \"Vedat Muriqi is a talented football player.\", \"E\": \"Jason Cunliffe has represented his country in international matches.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4853 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/l.parquet:  79%|███████████████████████████████████████████████████████████████▏                | 337/427 [52:53<11:17,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4645 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Who holds the record for the most games played for Adelaide in the AFL Women's (AFLW)?\", \"answer\": \"A\", \"A\": \"The player who holds the record for the most games played for Adelaide in the AFL Women's (AFLW) is yet to be updated as of the end of round 3, 2023.\", \"B\": \"The player who holds the record for the most games played for Adelaide in the AFL Women's (AFLW) is currently unknown.\", \"C\": \"The player who holds the record for the most games played for Adelaide in the AFL Women's (AFLW) is listed on the Australian Football website.\", \"D\": \"The player who holds the record for the most games played for Adelaide in the AFL Women's (AFLW) is expected to be announced soon.\", \"E\": \"The player who holds the record for the most games played for Adelaide in the AFL Women's (AFLW) is not mentioned in the provided text.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4645 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/l.parquet:  93%|██████████████████████████████████████████████████████████████████████████▏     | 396/427 [59:57<04:00,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5873 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"When was the transfer of Darwin Nunez communicated to CMVM?\", \"answer\": \"D\", \"A\": \"The transfer of Darwin Nunez was communicated to CMVM on 19 August 2020.\", \"B\": \"The transfer of Darwin Nunez was communicated to CMVM on 1 September 2016.\", \"C\": \"The transfer of Darwin Nunez was communicated to CMVM on 3 July 2019.\", \"D\": \"The transfer of Darwin Nunez was communicated to CMVM on 1 February 2023.\", \"E\": \"The transfer of Darwin Nunez was communicated to CMVM on 13 June 2022.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5873 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/l.parquet:  95%|██████████████████████████████████████████████████████████████████████████▎   | 407/427 [1:01:28<02:31,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4444 tokens (3444 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the Prix Lalande?\", \"answer\": \"C\", \"A\": \"The Prix Lalande was established in 1714 by the Paris Academy of Sciences.\", \"B\": \"The Prix Lalande was awarded for achievements in the field of héliographie.\", \"C\": \"The Prix Lalande was awarded by the Paris Academy of Sciences from 1881 to 1915.\", \"D\": \"The Prix Lalande was mentioned in the journal La Lumière.\", \"E\": \"The Prix Lalande was awarded for achievements in the field of beaux-arts.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4444 tokens (3444 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/l.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 427/427 [1:04:11<00:00,  9.02s/it]\n",
      "../data/wikipedia_fixed/m.parquet:  28%|██████████████████████▏                                                         | 122/439 [15:16<46:38,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"According to the text, what is Maurice Pirenne's stance on the use of curves in perspective?\", \"answer\": \"D\", \"A\": \"Pirenne believes that a truly 'physiological' perspective should consist of some kind of pseudo-development upon the picture plane of an image curved in shape like the retinal image.\", \"B\": \"Pirenne argues that due to the curvature of the retina, the geometrical construction of perspective should also use curves, leading to systems of 'curvilinear perspective'.\", \"C\": \"Pirenne suggests that the retinal image is what we see, and therefore a truly 'physiological' perspective should be based on the curved shape of the retinal image.\", \"D\": \"Pirenne refutes the idea that a truly 'physiological' perspective should consist of curves, stating that the retinal image is not what we see and that central, 'rectilinear', perspective is the only method capable of producing a retinal image with the same shape as the actual objects depicted.\", \"E\": \"Pirenne argues that the geometrical construction of perspective should be based on curves, as this would accurately represent the shape of the retinal image.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/m.parquet:  32%|█████████████████████████▋                                                      | 141/439 [23:13<36:55,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 6240 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes Marcela Carena's research focus?\", \"answer\": \"C\", \"A\": \"Marcela Carena's research primarily focuses on the study of quantum mechanics and its applications in technology.\", \"B\": \"Marcela Carena's research is centered around the exploration of the origins and evolution of the universe.\", \"C\": \"Carena's research is focused on models of new physics beyond the Standard Model and their manifestations in particle physics experiments.\", \"D\": \"Marcela Carena's research primarily focuses on the development of renewable energy sources and sustainable technologies.\", \"E\": \"Carena's research primarily focuses on the study of biological systems and their applications in medicine.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 6240 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/m.parquet:  96%|████████████████████████████████████████████████████████████████████████████▉   | 422/439 [58:13<02:04,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which of the following statements accurately describes the Modular Chemical Descriptor Language (MCDL)?\", \"answer\": \"C\", \"A\": \"The Modular Chemical Descriptor Language (MCDL) was first introduced in a paper published in 2001 by Gakh, Burnett, and colleagues.\", \"B\": \"MCDL is a Java-based chemical structure editor that supports the creation and manipulation of modular chemical descriptors.\", \"C\": \"The Modular Chemical Descriptor Language (MCDL) is a language used to represent stereochemical modules and has been the subject of multiple research papers.\", \"D\": \"Open Babel is a chemical toolbox that incorporates the Modular Chemical Descriptor Language (MCDL) as one of its features.\", \"E\": \"The availability, reliability, and security of information systems and human-computer interaction are topics discussed in a book that mentions the Modular Chemical Descriptor Language (MCDL).\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/m.parquet:  97%|███████████████████████████████████████████████████████████████████████████▊  | 427/439 [1:03:54<05:50, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5282 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which statement accurately describes the research mentioned in the provided text?\", \"answer\": \"C\", \"A\": \"The research discussed in the text primarily focuses on the physical properties of biological membranes and their role in ion and nonelectrolyte selectivity.\", \"B\": \"The research mentioned in the text investigates the regulation of a-type potassium current and its multiple modes of regulation.\", \"C\": \"The research mentioned in the text includes studies on specific ion permeation, the physical basis of ion and nonelectrolyte selectivity, and neuronal channels and receptors.\", \"D\": \"The research discussed in the text primarily focuses on the physiological effects of ion permeation and the regulation of a-type potassium current.\", \"E\": \"The research mentioned in the text primarily focuses on the molecular neurology of neuronal channels and receptors.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5282 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/m.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 439/439 [1:05:29<00:00,  8.95s/it]\n",
      "../data/wikipedia_fixed/n.parquet:  58%|██████████████████████████████████████████████▏                                 | 112/194 [13:35<09:15,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 295 (char 294)\n",
      "{\"prompt\": \"Which method was used by Borexino to detect geo-neutrinos?\", \"answer\": \"C\", \"A\": \"Borexino used seismic data to detect geo-neutrinos.\", \"B\": \"Borexino used neutrino tomography to detect geo-neutrinos.\", \"C\": \"Borexino detected geo-neutrinos through the process ν ¯ + p + ⟶ e + + n {\\displaystyle {\\ce {{\\bar {\\nu }}+p^{+}\\longrightarrow e^{+}{+n}}}} .\", \"D\": \"Borexino used IceCube data to detect geo-neutrinos.\", \"E\": \"Borexino used KM3NeT data to detect geo-neutrinos.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 295 (char 294)\n",
      "../data/wikipedia_fixed/n.parquet:  71%|████████████████████████████████████████████████████████▉                       | 138/194 [16:48<06:27,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the main focus of Nikolaus Rajewsky's research?\", \"answer\": \"C\", \"A\": \"BIMSB integrates experimental and computational methods to understand disease progressions.\", \"B\": \"Nikolaus Rajewsky is the head of BIMSB and has secured permanent funding for the project.\", \"C\": \"Nikolaus Rajewsky's research focuses on understanding the role of RNA in gene regulation.\", \"D\": \"The BMBF provided additional funding for the new building of BIMSB.\", \"E\": \"LifeTime is a pan-European consortium chaired by Nikolaus Rajewsky that aims to revolutionize healthcare.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/n.parquet:  76%|████████████████████████████████████████████████████████████▌                   | 147/194 [23:14<09:55, 12.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which statement accurately describes the importance of calculating natality rate?\", \"answer\": \"C\", \"A\": \"Calculating natality rate is only relevant for animal species, not plants or humans.\", \"B\": \"Calculating natality rate is important for wildlife management, but not for making government policies or conducting research on species preservation.\", \"C\": \"Calculating natality rate is crucial for understanding the reproductive ability of a population and making informed decisions for species preservation and population growth policies.\", \"D\": \"Calculating natality rate is primarily used to determine the effects of environmental chemicals/toxins on women of childbearing age.\", \"E\": \"Calculating natality rate is only relevant for studying the polar bear population in Svalbard, Norway.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/n.parquet:  80%|███████████████████████████████████████████████████████████████▉                | 155/194 [29:40<11:18, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which article discusses the challenges and strategies of antisense oligonucleotide drug delivery?\", \"answer\": \"B\", \"A\": \"The article 'Enhanced Antisense Oligonucleotide Delivery Using Cationic Liposomes Grafted with Trastuzumab: A Proof-of-Concept Study in Prostate Cancer' explores the use of cationic liposomes and trastuzumab to enhance the delivery of antisense oligonucleotides in prostate cancer.\", \"B\": \"The article 'The Challenges and Strategies of Antisense Oligonucleotide Drug Delivery' specifically focuses on the challenges and strategies associated with delivering antisense oligonucleotide drugs.\", \"C\": \"The article 'A morphological distinction between neurones of the male and female, and the behaviour of the nucleolar satellite during accelerated nucleoprotein synthesis' discusses the morphological differences between male and female neurons and the behavior of nucleolar satellites during nucleoprotein synthesis.\", \"D\": \"The article 'Structure and RNA recognition by the snRNA and snoRNA transport factor PHAX' explores the structure and RNA recognition mechanisms of the snRNA and snoRNA transport factor PHAX.\", \"E\": \"The article 'Antisense Oligonucleotide Therapy for Neurodevelopmental Disorders' discusses the potential use of antisense oligonucleotide therapy for treating neurodevelopmental disorders.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/n.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 194/194 [40:03<00:00, 12.39s/it]\n",
      "../data/wikipedia_fixed/o.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [15:04<00:00,  8.08s/it]\n",
      "../data/wikipedia_fixed/other.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 46/46 [05:56<00:00,  7.74s/it]\n",
      "../data/wikipedia_fixed/p.parquet:   3%|██▎                                                                              | 11/394 [01:23<45:14,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4157 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the role of the protein Prp24 in U6 snRNA?\", \"answer\": \"C\", \"A\": \"Prp24 is responsible for the structural rearrangements of U6 RNA in Saccharomyces cerevisiae.\", \"B\": \"Prp24 is a binding site in U6 snRNA and plays a role in the annealing of U6 and U4 snRNAs.\", \"C\": \"Prp24 is involved in multiple functions in U6 RNA structural rearrangements in Saccharomyces cerevisiae.\", \"D\": \"Prp24 is a component of the LSm complex in yeast U6 snRNPs.\", \"E\": \"Prp24 is a protein that interacts with U6 snRNA and plays a role in its characterization.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4157 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/p.parquet:  10%|████████▍                                                                        | 41/394 [05:11<55:36,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"What is the significance of the Puente Hills Fault in the Los Angeles area?\", \"answer\": \"C\", \"A\": \"The Puente Hills Fault is a transform fault that has a high frequency of major ruptures, posing a significant risk to the Los Angeles area.\", \"B\": \"The Puente Hills Fault is responsible for the 1987 Whittier Narrows earthquake and the 2010 light event, both of which caused damage and deaths in the Los Angeles area.\", \"C\": \"The Puente Hills Fault is a blind thrust fault that runs through the Los Angeles Basin and has the potential to cause a major earthquake with substantial impact in the Los Angeles area.\", \"D\": \"The Puente Hills Fault is responsible for the shortening of the northern Los Angeles Basin, with geodetic studies showing a rate of 4.5-5 millimeters per year.\", \"E\": \"The Puente Hills Fault was discovered in 1999 and is visually distinct with north dipping reflections, comprising three sections known as the Los Angeles, Santa Fe, and Coyote Hills segments.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/p.parquet:  29%|███████████████████████▌                                                        | 116/394 [20:51<37:09,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which book is being reviewed in the text?\", \"answer\": \"C\", \"A\": \"The Religious Worlds of Isaac Newton by Rob Iliffe is a comprehensive exploration of the religious beliefs and practices of the famous scientist.\", \"B\": \"Priest of Nature: The Religious Worlds of Isaac Newton is a groundbreaking book that delves into the religious aspects of Isaac Newton's life and work.\", \"C\": \"The book being reviewed in the text is Priest of Nature: The Religious Worlds of Isaac Newton by Rob Iliffe.\", \"D\": \"Isaac Newton's religious beliefs and their influence on his scientific work are examined in the book Priest of Nature: The Religious Worlds of Isaac Newton.\", \"E\": \"Rob Iliffe's book, Priest of Nature: The Religious Worlds of Isaac Newton, provides a detailed analysis of the religious dimensions of Isaac Newton's life and scientific contributions.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/p.parquet:  54%|██████████████████████████████████████████▊                                     | 211/394 [38:21<26:05,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"When was the initial formation of the Facho-Pico Alto Volcanic Complex?\", \"answer\": \"C\", \"A\": \"The initial formation of the Facho-Pico Alto Volcanic Complex occurred between 2 and 5 million years ago.\", \"B\": \"The initial formation of the Facho-Pico Alto Volcanic Complex occurred between 3 and 5 million years ago.\", \"C\": \"The initial formation of the Facho-Pico Alto Volcanic Complex was a phase of intense volcanism, resulting from submarine eruptions as early as 5 million years ago.\", \"D\": \"The initial formation of the Facho-Pico Alto Volcanic Complex occurred between 4 and 6 million years ago.\", \"E\": \"The initial formation of the Facho-Pico Alto Volcanic Complex occurred between 1 and 3 million years ago.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/p.parquet:  58%|██████████████████████████████████████████████▎                                 | 228/394 [45:36<17:42,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Who is the author of the book 'Other Minds: The Octopus, the Sea, and the Deep Origins of Consciousness'?\", \"answer\": \"A\", \"A\": \"Peter Godfrey-Smith\", \"B\": \"Robert T. Pennock\", \"C\": \"Ken Gewertz\", \"D\": \"The University of Sydney\", \"E\": \"The American Philosophical Society\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/p.parquet:  88%|████████████████████████████████████████████████████████████████████▎         | 345/394 [1:03:53<06:14,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4796 tokens (3796 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the cyclooxygenase reaction mechanism?\", \"answer\": \"C\", \"A\": \"The cyclooxygenase reaction mechanism involves the fragmentation of prostaglandin endoperoxides in aqueous solution.\", \"B\": \"The cyclooxygenase reaction mechanism is mediated by the enzyme cyclooxygenase-2.\", \"C\": \"The cyclooxygenase reaction mechanism is described in the article 'The cyclooxygenase reaction mechanism' by van der Donk et al.\", \"D\": \"The cyclooxygenase reaction mechanism results in the formation of aldehyde products from PGH2.\", \"E\": \"The cyclooxygenase reaction mechanism is classified by the International Union of Basic and Clinical Pharmacology as a prostanoid receptor.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4796 tokens (3796 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/p.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 394/394 [1:09:21<00:00, 10.56s/it]\n",
      "../data/wikipedia_fixed/q.parquet:   6%|████▌                                                                              | 2/36 [00:14<03:57,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 194 (char 193)\n",
      "{\"prompt\": \"What is the definition of a K-quasiregular map?\", \"answer\": \"C\", \"A\": \"A K-quasiregular map is a differentiable map that satisfies the inequality ‖ D f ( x ) ‖ n ≤ K | J f ( x ) | {\\displaystyle \\|Df(x)\\|^{n}\\leq K|J_{f}(x)|} at all points in the region D in Rn to Rn.\", \"B\": \"A K-quasiregular map is a continuous map in the Sobolev space W1,n loc whose partial derivatives in the sense of distributions have locally summable n-th power, and satisfies the inequality ‖ D f ( x ) ‖ n ≤ K | J f ( x ) | {\\displaystyle \\|Df(x)\\|^{n}\\leq K|J_{f}(x)|} almost everywhere.\", \"C\": \"A K-quasiregular map is a differentiable map that satisfies the inequality ‖ D f ( x ) ‖ n ≤ K | J f ( x ) | {\\displaystyle \\|Df(x)\\|^{n}\\leq K|J_{f}(x)|} at all points in the region D in Rn to Rn.\", \"D\": \"A K-quasiregular map is a map that is K-quasiregular with some K, and excludes constant maps from the class of quasiregular maps.\", \"E\": \"A K-quasiregular map is a map that is open and discrete, meaning that the images of open sets are open and the preimages of points consist of isolated points.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 194 (char 193)\n",
      "../data/wikipedia_fixed/q.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [04:45<00:00,  7.94s/it]\n",
      "../data/wikipedia_fixed/r.parquet:  23%|██████████████████▌                                                              | 60/262 [06:29<24:25,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4954 tokens (3954 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What was Robert A. Frosch's role at the United Nations Environmental Program?\", \"answer\": \"C\", \"A\": \"Robert A. Frosch served as the assistant executive director of the United Nations Environmental Program from January 1973 to July 1975.\", \"B\": \"Robert A. Frosch was responsible for overseeing the continuation of the development effort on the Space Shuttle program at the United Nations Environmental Program.\", \"C\": \"Robert A. Frosch, with the rank of assistant secretary general of the United Nations, was responsible for substantive global program activities of the United Nations system and other international activities related to environment matters at the United Nations Environmental Program.\", \"D\": \"Robert A. Frosch worked as a research scientist and director of research programs for Hudson Laboratories of Columbia University in Dobbs Ferry, New York, an organization under contract to the Office of Naval Research at the United Nations Environmental Program.\", \"E\": \"Robert A. Frosch served as the director for nuclear test detection (Project VELA) at the United Nations Environmental Program.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4954 tokens (3954 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/r.parquet:  48%|██████████████████████████████████████▍                                         | 126/262 [13:43<14:00,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4314 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Who wrote the book 'Descartes: a biography'?\", \"answer\": \"C\", \"A\": \"The Cambridge Companion to Descartes was edited by John Cottingham.\", \"B\": \"The book 'Math and Mathematicians: The History of Math Discoveries Around the World; Vol. 1' was written by Leonard C. Bruno.\", \"C\": \"Desmond M. Clarke wrote the book 'Descartes: a biography'.\", \"D\": \"The book 'Descartes' Life and the Development of His Philosophy' was written by Geneviève Rodis-Lewis.\", \"E\": \"The book 'Descartes, Rene | Internet Encyclopedia of Philosophy' was written by an unknown author.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4314 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/r.parquet:  49%|███████████████████████████████████████                                         | 128/262 [13:59<15:02,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4199 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which website provides information on the most individual penalty goals in a match?\", \"answer\": \"D\", \"A\": \"Rugbyworldcup.com provides information on the most individual penalty goals in a tournament/season.\", \"B\": \"Espnscrum.com provides information on the most individual drop goals.\", \"C\": \"Espnscrum.com provides information on the most individual penalty goals.\", \"D\": \"Espnscrum.com provides information on the most individual penalty goals in a match.\", \"E\": \"Rugbyworldcup.com provides information on the most drop goals.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4199 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/r.parquet:  70%|████████████████████████████████████████████████████████▏                       | 184/262 [20:05<07:47,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (3125 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate about Professor Ruth King?\", \"answer\": \"C\", \"A\": \"She graduated with a BSc in Mathematics with Statistics in 1998 from the University of Bristol.\", \"B\": \"She has been the Thomas Bayes' Chair of Statistics at the University of Edinburgh since 2010.\", \"C\": \"She has 69 publications on 'Google Scholar' since 2001, with a total of 1370 citations since 2014.\", \"D\": \"She co-organised the ICMS workshop on 'Addressing Statistical Challenges of Modern Technological Advances' in 2019.\", \"E\": \"She worked as a research associate at the University of Cambridge from 2001 to 2003.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4125 tokens (3125 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/r.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 262/262 [28:54<00:00,  6.62s/it]\n",
      "../data/wikipedia_fixed/s.parquet:   2%|█▍                                                                                | 9/502 [01:04<59:38,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 5519 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Who is Sylvain Garel?\", \"answer\": \"C\", \"A\": \"Sylvain Garel is a specialist in Canadian cinema.\", \"B\": \"Sylvain Garel is a professor at a science university.\", \"C\": \"Sylvain Garel is a specialist in Canadian cinema and has been featured in various publications.\", \"D\": \"Sylvain Garel is a filmmaker known for his work in French cinema.\", \"E\": \"Sylvain Garel is a renowned scientist in the field of cinema studies.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 5519 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/s.parquet:  30%|███████████████████████▉                                                        | 150/502 [16:33<34:39,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4533 tokens (3533 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"What is the general rule for the shear velocity in relation to the mean flow velocity?\", \"answer\": \"B\", \"A\": \"The shear velocity is always equal to the mean flow velocity.\", \"B\": \"The shear velocity is typically between 5% and 10% of the mean flow velocity.\", \"C\": \"The shear velocity is always greater than the mean flow velocity.\", \"D\": \"The shear velocity is always less than the mean flow velocity.\", \"E\": \"The shear velocity is unrelated to the mean flow velocity.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4533 tokens (3533 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/s.parquet:  66%|████████████████████████████████████████████████████▋                           | 331/502 [37:10<16:09,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting ',' delimiter: line 1 column 1264 (char 1263)\n",
      "{\"prompt\": \"What is the significance of the Republic upland lacustrine fossil beds?\", \"answer\": \"C. The Republic upland lacustrine fossil beds are significant as they represent the earliest known records of the Rosaceae (rose family) and Aceraceae (maple family), and have yielded over 200 species in fossilized form.\", \"A\": \"A. The Republic upland lacustrine fossil beds are significant because they are located in the city of Republic, which has a rich history of fossil discoveries.\", \"B\": \"B. The Republic upland lacustrine fossil beds are significant because they are part of a series of Eocene lake beds with abundant fossil plants, insects, fish, and other ancient life.\", \"C\": \"C. The Republic upland lacustrine fossil beds are significant as they represent the earliest known records of the Rosaceae (rose family) and Aceraceae (maple family), and have yielded over 200 species in fossilized form.\", \"D\": \"D. The Republic upland lacustrine fossil beds are significant because they are owned and operated by the Friends of Stonerose Fossils, a renowned organization in the field of paleontology.\", \"E\": \"E. The Republic upland lacustrine fossil beds are significant because they have been featured in the National Geographic Magazine and are part of the \"Cruisin’ the Fossil Coastline\" exhibit, showcasing the fossil history of the west coast.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1264 (char 1263)\n",
      "../data/wikipedia_fixed/s.parquet:  85%|███████████████████████████████████████████████████████████████████▉            | 426/502 [48:12<08:03,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "{\"prompt\": \"Which statement accurately describes the distribution of Sporothrix globosa?\", \"answer\": \"C\", \"A\": \"Sporothrix globosa is primarily found in Europe and North America.\", \"B\": \"Sporothrix globosa is a common pathogen in animals but rarely affects humans.\", \"C\": \"Sporothrix globosa is known to cause sapronoses in Asia.\", \"D\": \"Sporothrix globosa is exclusively found in soil and does not infect living organisms.\", \"E\": \"Sporothrix globosa is a newly discovered species and its distribution is still unknown.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/packages/six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 1375, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/opt/conda/lib/python3.10/http/client.py\", line 287, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 596, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/requests/adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 288, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 609, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "../data/wikipedia_fixed/s.parquet:  95%|████████████████████████████████████████████████████████████████████████████    | 477/502 [58:26<02:45,  6.64s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 755, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 757, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP code 502 from API (<html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body>\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>cloudflare</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      ")\n",
      "{\"prompt\": \"Which of the following books is not mentioned in the provided text?\", \"answer\": \"E\", \"A\": \"Fundamental processes in ecology: an earth systems approach by David M. Wilkinson\", \"B\": \"Systems ecology: an introduction to ecological modelling by R. L. Kitching\", \"C\": \"Steps to an Ecology of Mind by Gregory Bateson\", \"D\": \"Systems Analysis in Ecology by Kenneth Edmund Ferguson\", \"E\": \"Modeling Biological Systems: Principles and Applications by J. W. Haefner\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/s.parquet: 100%|██████████████████████████████████████████████████████████████████████████████| 502/502 [1:01:11<00:00,  7.31s/it]\n",
      "../data/wikipedia_fixed/t.parquet:  20%|████████████████▏                                                                | 57/286 [05:59<22:43,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unterminated string starting at: line 1 column 4844 (char 4843)\n",
      "{\"prompt\": \"What is the purpose of the tonograph device?\", \"answer\": \"Cagnazzi's tonograph device is designed to help store and preserve the tones and inflections of the human voice, allowing for precise measurement and transcription of vocal intonation. It provides a way to accurately represent the tone and intensity of the human voice, which the diatonic and chromatic scales of music cannot capture. The device consists of a hollow brass cylindrical section with a piston and a graduated scale, allowing for adjustments in the length of the cylinder and generating different sounds. By matching one's voice with the sound produced by the device, the tonograph can measure the intonation and inflection of the human voice. Additionally, the tonograph serves as a means to store and preserve vocal information by transcribing the measured values above or below a text. It is a valuable tool for declamation schools and acting schools, enabling the precise and successful storage of the tone and intensity of human voice. While some objections were raised regarding the ability of a mechanical device to replicate the sound of the human voice, Professor Majocchi explained that sound is described by tone, intensity, and timbre, with the latter being the distinguishing factor between different sounds. The tonograph, therefore, focuses on capturing meaningful aspects of sound, such as tone and intensity, which are employed in acting schools. Overall, the tonograph device serves as a revolutionary tool for accurately measuring, storing, and preserving the features of human voice, including its tones and music.\", \"A\": \"Cagnazzi's tonograph device is a simple mechanism that allows for the measurement of vocal intonation and inflection. It consists of a hollow brass cylindrical section with a piston and a graduated scale, which can be adjusted to change the length of the cylinder and produce different sounds. By matching one's voice with the sound produced by the device, the tonograph can provide a rough estimation of vocal intonation. However, it does not have the ability to accurately represent the tone and intensity of the human voice, as the diatonic and chromatic scales of music are limited in their notches. The tonograph's primary purpose is to measure vocal intonation, rather than store or preserve the features of human voice.\", \"B\": \"The tonograph device invented by Cagnazzi is primarily used for musical purposes. It allows musicians to measure and reproduce the tones and inflections of the human voice, providing a way to accurately represent vocal intonation. The device consists of a hollow brass cylindrical section with a piston and a graduated scale, which can be adjusted to change the length of the cylinder and generate different sounds. By matching one's voice with the sound produced by the device, musicians can measure the intonation and inflection of the human voice and incorporate it into their musical compositions. The tonograph serves as a valuable tool for composers and performers, enabling them to capture the unique qualities of the human voice and integrate them into their music.\", \"C\": \"Cagnazzi's tonograph device is a complex invention that aims to replicate the sound of the human voice using mechanical means. It consists of a hollow brass cylindrical section with a piston and a graduated scale, which can be adjusted to change the length of the cylinder and produce different sounds. By operating the bellows with one's feet, air flows through the cylindrical tube, creating a sound that can be modulated by adjusting the position of the piston. The tonograph device is designed to closely imitate the tones and inflections of the human voice, allowing for precise measurement and reproduction. It provides a way to accurately represent the tone and intensity of the human voice, surpassing the limitations of the diatonic and chromatic scales of music. The tonograph's primary purpose is to replicate the sound of the human voice, making it a groundbreaking invention in the field of vocal reproduction.\", \"D\": \"The tonograph device invented by Cagnazzi is a revolutionary tool for the measurement and analysis of vocal intonation. It consists of a hollow brass cylindrical section with a piston and a graduated scale, which can be adjusted to change the length of the cylinder and generate different sounds. By matching one's voice with the sound produced by the device, the tonograph allows for the precise measurement of vocal intonation and inflection. It provides a way to accurately represent the tone and intensity of the human voice, surpassing the limitations of the diatonic and chromatic scales of music. The tonograph's primary purpose is to measure and analyze vocal intonation, making it an invaluable tool for linguists, phoneticians, and speech therapists.\", \"E\": \"Cagnazzi's tonograph device is a mechanical apparatus that aims to replicate the sound of the human voice. It consists of a hollow brass cylindrical section with a piston and a graduated scale, which can be adjusted to change the length of the cylinder and produce different sounds. By operating the bellows with one's feet,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Unterminated string starting at: line 1 column 4844 (char 4843)\n",
      "../data/wikipedia_fixed/t.parquet:  35%|███████████████████████████▉                                                    | 100/286 [11:30<19:16,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, you requested 4720 tokens (3720 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "{\"prompt\": \"Which of the following articles discusses the association between regular exercise and symptoms of anxiety and depression?\", \"answer\": \"C\", \"A\": \"The article by Boker et al. (2011) introduces OpenMx, an open-source extended structural equation modeling framework.\", \"B\": \"The article by De Moor et al. (2008) tests causality in the association between regular exercise and symptoms of anxiety and depression.\", \"C\": \"The article by De Moor et al. (2008) tests causality in the association between regular exercise and symptoms of anxiety and depression.\", \"D\": \"The article by Burt et al. (2009) discusses nonshared environmental mediation of the association between deviant peer affiliation and adolescent externalizing behaviors over time.\", \"E\": \"The article by Boker et al. (2011) introduces OpenMx, an open-source extended structural equation modeling framework.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, you requested 4720 tokens (3720 in the messages, 1000 in the completion). Please reduce the length of the messages or completion.\n",
      "../data/wikipedia_fixed/t.parquet:  47%|█████████████████████████████████████▍                                          | 134/286 [15:19<15:23,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4647 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which statement accurately reflects the content of the provided text?\", \"answer\": \"C\", \"A\": \"Chemists from the Czech Republic are among the world's leading experts in the development of a drug against the coronavirus.\", \"B\": \"The United States reported the first case of the novel coronavirus in a publication from The New England Journal of Medicine.\", \"C\": \"The Czech government has ordered a drug for the coronavirus from a Czech specialist.\", \"D\": \"Gilead Sciences has offered an experimental drug for the treatment of coronavirus.\", \"E\": \"The FDA will authorize the use of remdesivir for Covid-19 after a trial showed a positive effect on recovery time.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4647 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/t.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 286/286 [33:32<00:00,  7.04s/it]\n",
      "../data/wikipedia_fixed/u.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 56/56 [05:36<00:00,  6.00s/it]\n",
      "../data/wikipedia_fixed/v.parquet:  38%|███████████████████████████████                                                   | 36/95 [03:44<05:23,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4163 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which statement accurately describes the relationship between volatility and the tendency to condense?\", \"answer\": \"C\", \"A\": \"Substances with low volatility will condense more readily than highly volatile ones.\", \"B\": \"Solids are generally more volatile than liquids, except for some exceptions like dry ice and iodine.\", \"C\": \"Differences in volatility can be observed by comparing the rate of evaporation or sublimation of substances when exposed to the atmosphere.\", \"D\": \"Vapor pressures and boiling points are numerical values used to describe volatility.\", \"E\": \"Volatility is solely determined by the strength of the interactions between molecules.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4163 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/v.parquet:  54%|████████████████████████████████████████████                                      | 51/95 [05:20<04:42,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4445 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements accurately describes the leaf flush regime?\", \"answer\": \"C\", \"A\": \"The leaf flush regime is determined by the climatic regime and refers to the timing and duration of leaf growth and shedding in plant communities.\", \"B\": \"The leaf flush regime is influenced by the elevation range and refers to the types of leaves found in different vegetation types.\", \"C\": \"The leaf flush regime can be categorized as evergreen, semideciduous, deciduous, alternate, or ephemeral based on the timing and duration of leaf growth and shedding.\", \"D\": \"The leaf flush regime is determined by the thermal realm and refers to the temperature requirements for leaf growth and shedding in plant communities.\", \"E\": \"The leaf flush regime is influenced by the substrate and refers to the types of leaves found in different soil types.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4445 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/v.parquet:  77%|███████████████████████████████████████████████████████████████                   | 73/95 [07:40<02:27,  6.71s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 755, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 757, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP code 502 from API (<html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body>\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>cloudflare</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      ")\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"Alcohol and benzene can be mixed together without any adverse effects on human health.\", \"B\": \"The untargeted in vivo microbial metabolite profiling via the SPME/GC × GC-QTOFMS approach is a novel method for recognizing pathogens in food matrixes.\", \"C\": \"Direct-injection mass spectrometry adds the time dimension to (B)VOC analysis.\", \"D\": \"Proton Transfer Reaction Mass Spectrometry (PTR-MS) is a high-speed mass spectrometry technique.\", \"E\": \"The PTR-QiTOF mass spectrometer is known for its extreme sensitivity and high speed.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "../data/wikipedia_fixed/v.parquet:  78%|███████████████████████████████████████████████████████████████▊                  | 74/95 [07:50<02:41,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model's maximum context length is 4097 tokens. However, your messages resulted in 4721 tokens. Please reduce the length of the messages.\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"Alcohol and benzene can be mixed together without any adverse effects on human health.\", \"B\": \"The untargeted in vivo microbial metabolite profiling via the SPME/GC × GC-QTOFMS approach is a novel method for recognizing pathogens in food matrixes.\", \"C\": \"Direct-injection mass spectrometry adds the time dimension to (B)VOC analysis.\", \"D\": \"Proton Transfer Reaction Mass Spectrometry (PTR-MS) is a high-speed mass spectrometry technique.\", \"E\": \"The PTR-QiTOF mass spectrometer is known for its extreme sensitivity and high speed.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4721 tokens. Please reduce the length of the messages.\n",
      "../data/wikipedia_fixed/v.parquet:  85%|█████████████████████████████████████████████████████████████████████▉            | 81/95 [08:50<01:51,  7.94s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 755, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 757, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP code 502 from API (<html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body>\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>cloudflare</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      ")\n",
      "{\"prompt\": \"Which statement accurately describes the use of oxygen and carbon isotopes of foraminifera in paleoceanography?\", \"answer\": \"C\", \"A\": \"Oxygen and carbon isotopes of foraminifera are used to determine the age of sedimentary rocks.\", \"B\": \"Oxygen and carbon isotopes of foraminifera are used to study the effects of climate change on marine ecosystems.\", \"C\": \"Oxygen and carbon isotopes of foraminifera are used to reconstruct past ocean temperatures and carbon dioxide levels.\", \"D\": \"Oxygen and carbon isotopes of foraminifera are used to analyze the composition of seawater.\", \"E\": \"Oxygen and carbon isotopes of foraminifera are used to study the migration patterns of marine species.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/v.parquet:  86%|██████████████████████████████████████████████████████████████████████▊           | 82/95 [09:00<01:51,  8.57s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 755, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 757, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP code 502 from API (<html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body>\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>cloudflare</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      ")\n",
      "{\"prompt\": \"Which statement accurately describes the use of oxygen and carbon isotopes of foraminifera in paleoceanography?\", \"answer\": \"C\", \"A\": \"Oxygen and carbon isotopes of foraminifera are used to determine the age of sedimentary rocks.\", \"B\": \"Oxygen and carbon isotopes of foraminifera are used to study the effects of climate change on marine ecosystems.\", \"C\": \"Oxygen and carbon isotopes of foraminifera are used to reconstruct past ocean temperatures and carbon dioxide levels.\", \"D\": \"Oxygen and carbon isotopes of foraminifera are used to analyze the composition of seawater.\", \"E\": \"Oxygen and carbon isotopes of foraminifera are used to study the migration patterns of marine species.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/v.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [10:25<00:00,  6.58s/it]\n",
      "../data/wikipedia_fixed/w.parquet:  12%|█████████▎                                                                       | 14/121 [01:30<13:23,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid \\escape: line 1 column 159 (char 158)\n",
      "{\"prompt\": \"What is the basis of Tajima's D?\", \"answer\": \"C\", \"A\": \"Watterson's estimator is commonly used for its simplicity.\", \"B\": \"The estimate of θ ^ w {\\displaystyle {\\widehat {\\theta \\,}}_{w}} , often denoted as θ ^ w {\\displaystyle {\\widehat {\\theta \\,}}_{w}} , is θ ^ w = K a n , {\\displaystyle {\\widehat {\\theta \\,}}_{w}={K \\over a_{n}},} where K {\\displaystyle K} is the number of segregating sites (an example of a segregating site would be a single-nucleotide polymorphism) in the sample and a n = ∑ i = 1 n − 1 1 i {\\displaystyle a_{n}=\\sum _{i=1}^{n-1}{1 \\over i}} is the ( n − 1 ) {\\displaystyle (n-1)} th harmonic number.\", \"C\": \"Comparing the value of the Watterson's estimator, to nucleotide diversity is the basis of Tajima's D which allows inference of the evolutionary regime of a given locus.\", \"D\": \"The assumptions made are that there is a sample of n {\\displaystyle n} haploid individuals from the population of interest, that there are infinitely many sites capable of varying (so that mutations never overlay or reverse one another), and that n ≪ N e {\\displaystyle n\\ll N_{e}} .\", \"E\": \"It is estimated by counting the number of polymorphic sites.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 47, in <module>\n",
      "    texts_json = json.loads(text)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 353, in raw_decode\n",
      "    obj, end = self.scan_once(s, idx)\n",
      "json.decoder.JSONDecodeError: Invalid \\escape: line 1 column 159 (char 158)\n",
      "../data/wikipedia_fixed/w.parquet:  74%|████████████████████████████████████████████████████████████▏                    | 90/121 [09:29<03:14,  6.27s/it]Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 755, in _interpret_response_line\n",
      "    data = json.loads(rbody)\n",
      "  File \"/opt/conda/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/opt/conda/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_15213/3124827155.py\", line 46, in <module>\n",
      "    text = query_prompt(prompt)\n",
      "  File \"/tmp/ipykernel_15213/72703211.py\", line 2, in query_prompt\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py\", line 757, in _interpret_response_line\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP code 502 from API (<html>\r\n",
      "<head><title>502 Bad Gateway</title></head>\r\n",
      "<body>\r\n",
      "<center><h1>502 Bad Gateway</h1></center>\r\n",
      "<hr><center>cloudflare</center>\r\n",
      "</body>\r\n",
      "</html>\r\n",
      ")\n",
      "{\"prompt\": \"Which of the following statements is the most accurate based on the provided text?\", \"answer\": \"C\", \"A\": \"The Pittsburgh Post-Gazette published an article titled 'Prince of Puzzles' on October 25, 1999.\", \"B\": \"The Philadelphia Inquirer reported on the 2009 Inquirer Sudoku National Championship.\", \"C\": \"The MIT Mystery Hunt 2019 Wrapup video can be found on YouTube.\", \"D\": \"BoardGameGeek features information about the game 'Roll for the Galaxy'.\", \"E\": \"The Washington Post published an article on March 9, 1993, about the top 10 finalists in Westinghouse's competition.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../data/wikipedia_fixed/w.parquet: 100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [13:00<00:00,  6.45s/it]\n",
      "../data/wikipedia_fixed/x.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [01:23<00:00,  6.43s/it]\n",
      "../data/wikipedia_fixed/y.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [03:09<00:00,  6.76s/it]\n",
      "../data/wikipedia_fixed/z.parquet: 100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [02:32<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "import traceback \n",
    "batch_size = 1\n",
    "\n",
    "def make_prompt(series):\n",
    "    prompt = f\"\"\"\n",
    "You are a professor at a science university and are creating a test for your students.\n",
    "Please create one exam based on the provided text, where you choose the most accurately statement from five options for the question.\n",
    "The output should json format below:\n",
    "{{\"prompt\": <the question text>, \"answer\" <answer(one of A through E)>, \"A\": <option A>, \"B\": <option B>, \"C\": <option C>, \"D\": <option D>, \"E\": <option E>}}\n",
    "\n",
    "Context:\n",
    "{series['text']}\n",
    "\n",
    "Attention:\n",
    "- The five opinions should be LONG sentences.\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def f(series):\n",
    "    try:\n",
    "        if series[\"A\"] != series[\"A\"]:\n",
    "            if type(series[\"answer\"]) == dict:\n",
    "                for key in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n",
    "                    series[key] = series[\"choices\"][key]\n",
    "            elif type(series[\"answer\"] == list):\n",
    "                for i, key in enumerate([\"A\", \"B\", \"C\", \"D\", \"E\"]):\n",
    "                    series[key] = series[\"choices\"][i]\n",
    "    except:\n",
    "        return series\n",
    "    return series\n",
    "\n",
    "now_date = dt.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "first = True\n",
    "for file in files:\n",
    "    if os.path.basename(file) in [\"all.parquet\"]:\n",
    "        print(f\"pass: {file}\")\n",
    "        continue\n",
    "    df_science = get_df(file)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(len(df_science)), desc=file):\n",
    "        try:\n",
    "            series = df_science.iloc[i]\n",
    "            prompt = make_prompt(series)\n",
    "            text = query_prompt(prompt)\n",
    "            texts_json = json.loads(text)\n",
    "            if first:\n",
    "                print(texts_json)\n",
    "                first = False\n",
    "            if type(texts_json) == dict:\n",
    "                texts_json[\"wiki_id\"] = series[\"id\"]\n",
    "                texts_json[\"original_text\"] = series[\"text\"]\n",
    "                texts.append(texts_json)\n",
    "                for col in [\"A\", \"B\", \"C\", \"D\", \"E\", \"answer\", \"prompt\"]:\n",
    "                    if col not in texts_json:\n",
    "                        print(f\"{col} not existed: {texts_json}\")\n",
    "            else:\n",
    "                for text_json in texts_json:\n",
    "                    text_json[\"wiki_id\"] = series[\"id\"]\n",
    "                    text_json[\"original_text\"] = series[\"text\"]\n",
    "                    texts.append(text_json)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            traceback.print_exc()\n",
    "            print(text)\n",
    "            time.sleep(10)\n",
    "        if i % 20 == 0:\n",
    "            df_texts = pd.DataFrame(texts)\n",
    "            df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "            df_texts.to_parquet(f\"output_gpt3.5_generate/{now_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.DataFrame(texts)\n",
    "df_texts = df_texts.apply(f, axis=1)\n",
    "\n",
    "df_texts.to_parquet(f\"output_gpt3.5_generate/{now_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5839"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
